

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="peiwithhao">
  <meta name="keywords" content="">
  
    <meta name="description" content="çœ‹å¥½äº†ï¼Œæ ¼é‡Œæ²™ï¼Œç‰©ç†å†…å­˜æ˜¯è¿™æ ·ç”¨çš„ï¼">
<meta property="og:type" content="article">
<meta property="og:title" content="Linux_memory_manegement">
<meta property="og:url" content="https://peiandhao.github.io/2023/06/17/Linux-memory-manegement/index.html">
<meta property="og:site_name" content="peiwithhao&#39;s Valhalla">
<meta property="og:description" content="çœ‹å¥½äº†ï¼Œæ ¼é‡Œæ²™ï¼Œç‰©ç†å†…å­˜æ˜¯è¿™æ ·ç”¨çš„ï¼">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://peiandhao.github.io/img/linuxmm.jpg">
<meta property="article:published_time" content="2023-06-17T09:08:00.000Z">
<meta property="article:modified_time" content="2023-06-17T09:16:17.464Z">
<meta property="article:author" content="peiwithhao">
<meta property="article:tag" content="Linux">
<meta property="article:tag" content="kernel">
<meta property="article:tag" content="source">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://peiandhao.github.io/img/linuxmm.jpg">
  
  
  
  <title>Linux_memory_manegement - peiwithhao&#39;s Valhalla</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"peiandhao.github.io","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"text"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"Afm6UeM0VL6RfMOLAgwtyxs8-gzGzoHsz","app_key":"Vr60qrZIptqhJaXqWvDEknkH","server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>p3ivv1+h@0</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>é¦–é¡µ</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>å½’æ¡£</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>åˆ†ç±»</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>æ ‡ç­¾</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>å…³äº</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                <span>å‹é“¾</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/linuxmm.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Linux_memory_manegement"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        peiwithhao
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-06-17 17:08" pubdate>
          2023å¹´6æœˆ17æ—¥ ä¸‹åˆ
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          41k å­—
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          340 åˆ†é’Ÿ
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> æ¬¡
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Linux_memory_manegement</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="Linuxå†…å­˜ç®¡ç†æºç åˆ†æ"><a href="#Linuxå†…å­˜ç®¡ç†æºç åˆ†æ" class="headerlink" title="Linuxå†…å­˜ç®¡ç†æºç åˆ†æ"></a>Linuxå†…å­˜ç®¡ç†æºç åˆ†æ</h1><p>å†…æ ¸pwnå­¦åˆ°UAFï¼Œå‘ç°åˆä¸å¤ªè¡Œäº†ï¼Œè™½è¯´ä¹‹å‰æ“ä½œç³»ç»Ÿçš„çŸ¥è¯†æ²¡å•¥é—®é¢˜äº†ï¼Œä½†æ˜¯è¿™é‡Œå¯¹äºç›®å‰å¸‚é¢ä¸Šçš„å†…å­˜ç®¡ç†è¿˜æ˜¯ä¸äº†è§£ï¼Œå› æ­¤åœ¨è¿™é‡Œå†æ¥æµ…æµ…åˆ†æä¸€ä¸‹ï¼Œæ•´ä½“çš„æ•°æ®éƒ¨åˆ†ï¼ŒLinuxé‡‡ç”¨<code>node</code>ã€<code>zone</code>ã€<code>page</code>ä¸‰çº§è¡¨ç¤ºï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ¥åˆ†åˆ«å™è¿°ï¼Œè¿™é‡Œè‹¥æ¶‰åŠåˆ°æºç å¤§å®¶å¯ä»¥ç‚¹å‡»ä¸‹é¢é“¾æ¥æŸ¥çœ‹Linuxå†…æ ¸ç›¸åº”ç‰ˆæœ¬æŸ¥çœ‹</p>
<p><a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v5.11.22/source">Linux å†…æ ¸æºç </a></p>
<p>æœ¬ç¯‡ä¸»è¦æ˜¯ä¸ªäººè·Ÿéšç€arttnba3å¸ˆå‚…ï¼š</p>
<p><a target="_blank" rel="noopener" href="https://arttnba3.cn/2021/11/28/OS-0X02-LINUX-KERNEL-MEMORY-5.11-PART-I/">arttnba3</a></p>
<p>å’Œcft56200_lnå¸ˆå‚…ï¼š</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/caofengtao1314/article/details/117321692?spm=1001.2014.3001.5502">cft56200_ln</a></p>
<h2 id="1-æ•°æ®ç»“æ„éƒ¨åˆ†"><a href="#1-æ•°æ®ç»“æ„éƒ¨åˆ†" class="headerlink" title="1. æ•°æ®ç»“æ„éƒ¨åˆ†"></a>1. æ•°æ®ç»“æ„éƒ¨åˆ†</h2><h3 id="nodeèŠ‚ç‚¹"><a href="#nodeèŠ‚ç‚¹" class="headerlink" title="nodeèŠ‚ç‚¹"></a>nodeèŠ‚ç‚¹</h3><p>æˆ‘ä»¬é¦–å…ˆéœ€è¦çŸ¥é“ï¼Œå¯¹äºå†…å­˜è®¿é—®æ¶æ„æ¥è®²ï¼Œä¸€èˆ¬CPUéƒ½å¯ä»¥åˆ†ä¸ºä»¥ä¸‹ä¸¤ç§æ–¹å¼ï¼š</p>
<ul>
<li>UMA(ä¸€è‡´æ€§å†…å­˜è®¿é—®ï¼ŒUniform Memory Access)ï¼Œè¡¨ç¤ºå…¨å±€å°±ä¸€ä¸ª<code>node</code>ï¼Œä¸”å¤šä¸ªCPUé€šè¿‡1è·Ÿæ€»çº¿è®¿é—®å†…å­˜ï¼Œä¸”è®¿é—®æ—¶é—´ä¸€è‡´ï¼Œç±»ä¼¼SMP</li>
<li>NUMA(éä¸€è‡´æ€§å†…å­˜è®¿é—®ï¼ŒNot-Uniform Memory Access)ï¼Œæ¯ä¸ªCPUåˆ†é…ä¸€å—å†…å­˜ï¼Œå­˜åœ¨å¤šä¸ª<code>node</code>ï¼Œä¸”å†ä¸åŒæƒ…å†µä¸‹ä½¿ç”¨è®¿é—®æ—¶é—´æœ‰æ‰€åŒºåˆ«ã€‚</li>
</ul>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/fc1f4134970a304e84a7453394c8a786c8175c76.jpg" srcset="/img/loading.gif" lazyload></p>
<p>è€Œ<code>node</code>çš„ç»“æ„ä½“æ˜¯é‡‡ç”¨<code>pglist_data</code>ç»“æ„è¿›è¡Œæè¿°ï¼Œå®šä¹‰åœ¨<code>/include/linux/mmzone.h</code>,å¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">/*
 * On NUMA machines, each NUMA node would have a pg_data_t to describe
 * it&#39;s memory layout. On UMA machines there is a single pglist_data which
 * describes the whole memory.ï¼ˆNUMAæ¶æ„æ¯ä¸ªnodeéƒ½æœ‰ä¸ªæ­¤ç»“æ„æ¥æè¿°å†…å­˜å¸ƒå±€ï¼Œè€ŒUMAå°±ä¸€ä¸ªï¼‰
 *
 * Memory statistics and page replacement data structures are maintained on a
 * per-zone basis.
 */
typedef struct pglist_data &#123;
    /*
     * node_zones contains just the zones for THIS node. Not all of the
     * zones may be populated, but it is the full list. It is referenced by
     * this node&#39;s node_zonelists as well as other node&#39;s node_zonelists.
     */
    struct zone node_zones[MAX_NR_ZONES];

    /*
     * node_zonelists contains references to all zones in all nodes.
     * Generally the first zones will be references to this node&#39;s
     * node_zones.
     */
    struct zonelist node_zonelists[MAX_ZONELISTS];

    int nr_zones; /* number of populated zones in this node */
#ifdef CONFIG_FLAT_NODE_MEM_MAP	/* means !SPARSEMEM */
    struct page *node_mem_map;
#ifdef CONFIG_PAGE_EXTENSION
    struct page_ext *node_page_ext;
#endif
#endif
#if defined(CONFIG_MEMORY_HOTPLUG) || defined(CONFIG_DEFERRED_STRUCT_PAGE_INIT)
    /*
     * Must be held any time you expect node_start_pfn,
     * node_present_pages, node_spanned_pages or nr_zones to stay constant.
     * Also synchronizes pgdat-&gt;first_deferred_pfn during deferred page
     * init.
     *
     * pgdat_resize_lock() and pgdat_resize_unlock() are provided to
     * manipulate node_size_lock without checking for CONFIG_MEMORY_HOTPLUG
     * or CONFIG_DEFERRED_STRUCT_PAGE_INIT.
     *
     * Nests above zone-&gt;lock and zone-&gt;span_seqlock
     */
    spinlock_t node_size_lock;
#endif
    unsigned long node_start_pfn;
    unsigned long node_present_pages; /* total number of physical pages */
    unsigned long node_spanned_pages; /* total size of physical page
                         range, including holes */
    int node_id;
    wait_queue_head_t kswapd_wait;
    wait_queue_head_t pfmemalloc_wait;
    struct task_struct *kswapd;	/* Protected by
                       mem_hotplug_begin/end() */
    int kswapd_order;
    enum zone_type kswapd_highest_zoneidx;

    int kswapd_failures;		/* Number of &#39;reclaimed == 0&#39; runs */

#ifdef CONFIG_COMPACTION
    int kcompactd_max_order;
    enum zone_type kcompactd_highest_zoneidx;
    wait_queue_head_t kcompactd_wait;
    struct task_struct *kcompactd;
#endif
    /*
     * This is a per-node reserve of pages that are not available
     * to userspace allocations.
     */
    unsigned long		totalreserve_pages;

#ifdef CONFIG_NUMA
    /*
     * node reclaim becomes active if more unmapped pages exist.
     */
    unsigned long		min_unmapped_pages;
    unsigned long		min_slab_pages;
#endif /* CONFIG_NUMA */

    /* Write-intensive fields used by page reclaim */
    ZONE_PADDING(_pad1_)
    spinlock_t		lru_lock;

#ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT
    /*
     * If memory initialisation on large machines is deferred then this
     * is the first PFN that needs to be initialised.
     */
    unsigned long first_deferred_pfn;
#endif /* CONFIG_DEFERRED_STRUCT_PAGE_INIT */

#ifdef CONFIG_TRANSPARENT_HUGEPAGE
    struct deferred_split deferred_split_queue;
#endif

    /* Fields commonly accessed by the page reclaim scanner */

    /*
     * NOTE: THIS IS UNUSED IF MEMCG IS ENABLED.
     *
     * Use mem_cgroup_lruvec() to look up lruvecs.
     */
    struct lruvec		__lruvec;

    unsigned long		flags;

    ZONE_PADDING(_pad2_)

    /* Per-node vmstats */
    struct per_cpu_nodestat __percpu *per_cpu_nodestats;
    atomic_long_t		vm_stat[NR_VM_NODE_STAT_ITEMS];
&#125; pg_data_t;
</code></pre>
<p>ä¸‹é¢å•ç‹¬æŒ‡å‡ºä¸€äº›é‡è¦å­—æ®µï¼š</p>
<ul>
<li><strong>node_zones</strong>:node_zones contains just the zones for THIS node. Not all of the zones may be populated, but it is the full list. It is referenced by this nodeâ€™s node_zonelists as well as other nodeâ€™s node_zonelists.è¯´äººè¯ï¼Œä»–æ˜¯ä¸€ä¸ª<code>struct zone</code>ç±»å‹çš„æ•°ç»„ï¼ŒåŒ…å«äº†ä»…ä»…è¿™ä¸ª<code>node</code>ä¸‹çš„æ‰€æœ‰çš„<code>zone</code>,è¿™é‡Œæ³¨æ„å¹¶éæ‰€æœ‰<code>zone</code>éƒ½è¢«å¡«å……ï¼Œä½†æ˜¯ä»–æ˜¯å·²ç»è¢«å……æ»¡äº†ï¼Œä»–è¢«ä¸‹é¢å³å°†è®²åˆ°çš„ä¸€ä¸ªé“¾è¡¨èŠ‚ç‚¹<code>node_zonelists</code>å’Œå…¶ä»–<code>node</code>çš„<code>node_zonelists</code>å¼•ç”¨ï¼›</li>
<li><strong>node_zonelists</strong>:ä¸æ ‡è‹±è¯­äº†ï¼Œçœ‹ç€çƒ¦äººï¼Œè¿™é‡Œæˆ‘ç›´æ¥å†™ä»–çš„å«ä¹‰ï¼Œä»–çš„å®šä¹‰æ˜¯ä¸ºäº†ç¡®å®šå†…å­˜åˆ†é…çš„æ—¶å€™å¯¹å¤‡ç”¨<code>zone</code>çš„æœç´¢é¡ºåºï¼Œä»–åŒæ—¶å¯ä»¥åŒ…å«éæœ¬<code>node</code>çš„<code>zone</code>ï¼Œæ™®éä»–çš„ç¬¬ä¸€ä¸ª<code>zone</code>é“¾æ¥çš„æ˜¯æœ¬<code>node</code>ä¸‹çš„<code>zone</code>æ•°ç»„ç¬¬ä¸€ä¸ªï¼Œå…¶å®è¿™ä¸ª<code>struct zonelist</code>å°±æ˜¯ä¸€ä¸ªæŒ‡å‘<code>zone</code>çš„æŒ‡é’ˆåŠ ä¸Šå…¶ä»–å…ƒç´ ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹çœ‹ä»–çš„æ•°æ®ç»“æ„ï¼Œè¿™é‡Œç›´æ¥å¼•ç”¨<code>arttnba3</code>å¸ˆå‚…çš„ç¬”è®°ï¼Œ</li>
</ul>
<p>å¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">/*
 * å•æ¬¡åˆ†é…è¯·æ±‚åœ¨ä¸€ä¸ª zonelist ä¸Šæ“ä½œ. ä¸€ä¸ª zonelist ä¾¿æ˜¯ä¸€ç»„ zone çš„åˆ—è¡¨ï¼Œ
 * å…¶ä¸­ç¬¬ä¸€ä¸ª zone ä¸ºåˆ†é…çš„â€œç›®æ ‡â€ï¼Œè€Œå…¶ä»–çš„ zone ä¸ºåå¤‡çš„zoneï¼Œä¼˜å…ˆçº§é™ä½ã€‚
 *
 * ä¸ºäº†æé«˜ zonelist çš„è¯»å–é€Ÿåº¦, åœ¨ zonerefs ä¸­åŒ…å«æ­£åœ¨è¢«è¯»å–çš„ entry çš„ zone indexã€‚
 * ç”¨æ¥è®¿é—®æ‰€ç»™çš„ zoneref ç»“æ„ä½“ä¿¡æ¯çš„å¸®åŠ©å‡½æ•°æœ‰ï¼š
 *
 * zonelist_zone()	- è¿”å›ä¸€ä¸ª struct zone çš„æŒ‡é’ˆä½œä¸º _zonerefs ä¸­çš„ä¸€ä¸ª entry
 * zonelist_zone_idx()	- è¿”å›ä½œä¸º entry çš„ zone çš„ index
 * zonelist_node_idx()	- è¿”å›ä½œä¸º entry çš„ node çš„ index
 */
struct zonelist &#123;
    struct zoneref _zonerefs[MAX_ZONES_PER_ZONELIST + 1];
&#125;;
</code></pre>
<p>   å…¶ä¸­æ˜¯ä¸€ä¸ª<code>struct zoneref</code>æ•°ç»„ï¼Œæ¥ä¸‹æ¥å†çœ‹çœ‹å…¶ä¸­çš„ç»“æ„</p>
<pre><code class="hljs">/*
 * è¯¥ç»“æ„åŒ…å«äº† zonelist ä¸­ä¸€ä¸ª zone çš„ä¿¡æ¯ã€‚ 
 * å…¶è¢«å‚¨å­˜åœ¨è¿™é‡Œä»¥é¢„é˜²å¯¹å¤§ç»“æ„ä½“çš„è§£å¼•ç”¨ä¸å¯¹è¡¨çš„æŸ¥è¯¢ã€‚
 */
struct zoneref &#123;
    struct zone *zone;	/* æŒ‡å‘å®é™…ä¸Šçš„ zone çš„æŒ‡é’ˆ */
    int zone_idx;		/* zone_idx(zoneref-&gt;zone) */
&#125;;
</code></pre>
<p>   å¯ä»¥çœ‹åˆ°å…¶å°±æ˜¯ä¸€ä¸ªæŒ‡é’ˆè€Œå·²</p>
<ul>
<li><strong>nr_zones</strong>:è®°å½•äº†è¯¥<code>node</code>ä¸­æ‰€æœ‰å¯ç”¨çš„<code>zone</code>æ•°é‡</li>
<li><strong>node_start_pfn</strong>ï¼š<code>node</code>èµ·å§‹é¡µçš„é¡µæ¡†æ ‡å·ï¼Œè¿™é‡Œçš„<code>pfn</code>æˆ‘ä»¬åœ¨ä¹‹åè®²è§£ï¼Œè¿™é‡Œå¯ä»¥ç†è§£ä¸ºè¯¥<code>node</code>æ‰€åœ¨çš„ç‰©ç†åœ°å€</li>
<li><strong>node_present_pages</strong>ï¼š<code>node</code>ä¸­ç‰©ç†é¡µçš„æ€»æ•°é‡</li>
<li><strong>unsighnd long node_spanned_pages</strong>:<code>node</code>ä¸­ç‰©ç†é¡µçš„æ€»å¤§å°</li>
<li><strong>node_id</strong>ï¼šè®°å½•è¯¥<code>node</code>åœ¨ç³»ç»Ÿä¸­çš„æ ‡å·ï¼Œä»0å¼€å§‹</li>
</ul>
<p>çŸ¥é“äº†å…¶ä¸­çš„ä¸€äº›æ•°æ®ç»“æ„ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬äº†è§£ä¸€ä¸‹<code>node</code>çš„å­˜å‚¨æ–¹å¼ï¼šæˆ‘ä»¬å¯ä»¥åœ¨ä¸Šé¢çš„ç½‘ç«™ä¸­æŸ¥æ‰¾æºç ï¼Œåœ¨<code>/arch/x86/mm/numa.c</code>ä¸­çœ‹åˆ°å…¶ä¸­å®šä¹‰äº†ä¸€ä¸ª<code>pglist_data</code>çš„å…¨å±€æ•°ç»„<code>node_data[]</code></p>
<pre><code class="hljs">struct pglist_data *node_data[MAX_NUMNODES] __read_mostly;
EXPORT_SYMBOL(node_data);
</code></pre>
<p>å…¶ä¸­åŒ…å«æˆ‘ä»¬çš„æ‰€æœ‰<code>node</code>,ä¸‹é¢æ¥ä¸€ä¸ªå¥½å›¾ï¼Œä¸ºå•¥å¤§ä¼™ç”»å›¾éƒ½è¿™ä¹ˆä¸“ä¸šæ<br><img src="http://imgsrc.baidu.com/forum/pic/item/279759ee3d6d55fbada192ef28224f4a21a4dd90.jpg" srcset="/img/loading.gif" lazyload></p>
<p>å½“æˆ‘ä»¬çŸ¥æ™“äº†<code>node</code>èŠ‚ç‚¹çš„å­˜å‚¨æ–¹å¼ï¼Œæˆ‘ä»¬éœ€è¦å¦ä¸€ä¸ªæ•°ç»„<code>node_status</code>æ¥æè¿°å¯¹åº”<code>node</code>èŠ‚ç‚¹çš„çŠ¶æ€ï¼Œä»–å®šä¹‰åœ¨<code>/mm/page_alloc.c</code>å½“ä¸­ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå…¨å±€æ•°ç»„ï¼ˆæˆ‘æ˜¯çœŸä½©æœå†™Linuxçš„è¿™ä¸€ç¾¤å¤§ä½¬ï¼Œè¿™æ–‡ä»¶çš„åˆ†å¸ƒæƒ…å†µè·Ÿæˆ‘è‡ªå·±å†™çš„é‚£ä¸ªæ“ä½œç³»ç»Ÿç›¸æ¯”ç®€ç›´å¤©å£¤ä¹‹åˆ«é˜¿ï¼‰</p>
<pre><code class="hljs">/*
 * Array of node states.
 */
nodemask_t node_states[NR_NODE_STATES] __read_mostly = &#123;
    [N_POSSIBLE] = NODE_MASK_ALL,
    [N_ONLINE] = &#123; &#123; [0] = 1UL &#125; &#125;,
#ifndef CONFIG_NUMA
    [N_NORMAL_MEMORY] = &#123; &#123; [0] = 1UL &#125; &#125;,
#ifdef CONFIG_HIGHMEM
    [N_HIGH_MEMORY] = &#123; &#123; [0] = 1UL &#125; &#125;,
#endif
    [N_MEMORY] = &#123; &#123; [0] = 1UL &#125; &#125;,
    [N_CPU] = &#123; &#123; [0] = 1UL &#125; &#125;,
#endif	/* NUMA */
&#125;;
EXPORT_SYMBOL(node_states);
</code></pre>
<p>è€Œæˆ‘ä»¬çš„<code>node_states</code>ç±»å‹ä¿å­˜åœ¨<code>/include/linux/nodemask.h</code>,è¿™é‡Œä»ç„¶ç›´æ¥å¼•ç”¨<code>arttnba3</code>å¸ˆå‚…</p>
<pre><code class="hljs">/*
 * ä½æ©ç å°†ä¸ºæ‰€æœ‰èŠ‚ç‚¹ä¿å­˜
 */
enum node_states &#123;
    N_POSSIBLE,        /* èŠ‚ç‚¹åœ¨æŸä¸ªæ—¶åˆ»æ˜¯è”æœºçš„ */
    N_ONLINE,        /* èŠ‚ç‚¹æ˜¯è”æœºçš„ */
    N_NORMAL_MEMORY,    /* èŠ‚ç‚¹æœ‰ç€æ™®é€šçš„å†…å­˜ */
#ifdef CONFIG_HIGHMEM
    N_HIGH_MEMORY,        /* èŠ‚ç‚¹æœ‰ç€æ™®é€šæˆ–é«˜ç«¯å†…å­˜ */
#else
    N_HIGH_MEMORY = N_NORMAL_MEMORY,
#endif
    N_MEMORY,        /* èŠ‚ç‚¹æœ‰ç€å†…å­˜(æ™®é€šï¼Œé«˜ç«¯ï¼Œå¯ç§»åŠ¨) */
    N_CPU,        /* èŠ‚ç‚¹æœ‰ç€ä¸€ä¸ªæˆ–å¤šä¸ª cpu */
    N_GENERIC_INITIATOR,    /* èŠ‚ç‚¹æœ‰ä¸€ä¸ªæˆ–å¤šä¸ª Generic Initiators */
    NR_NODE_STATES
&#125;;
</code></pre>
<p>è¯´å®Œnodeï¼Œæˆ‘æ¥ç»˜ä¸ªå›¾å§ï¼Œè¿™é‡Œè€æŠ„ä½œä¸šå¥½åƒä½“ç°ä¸å‡ºè‡ªå·±çœŸæ­£å­¦åˆ°äº†ä¸œè¥¿<br><img src="http://imgsrc.baidu.com/forum/pic/item/4d086e061d950a7b0985aa0d4fd162d9f3d3c943.jpg" srcset="/img/loading.gif" lazyload></p>
<p>æˆ‘ä»¬å°†åœ¨ä¹‹åä¸€æ­¥ä¸€æ­¥æ…¢æ…¢å®Œå–„è¿™ä¸ªå›¾ç‰‡</p>
<h3 id="zoneåŒºåŸŸ"><a href="#zoneåŒºåŸŸ" class="headerlink" title="zoneåŒºåŸŸ"></a>zoneåŒºåŸŸ</h3><p>åŒæ ·çš„ï¼Œå…ˆè¯´å…¶æ•°æ®ç»“æ„<code>struct zone</code>ï¼Œä»–ä½äº<code>/include/linux/mmzone.h</code></p>
<pre><code class="hljs">struct zone &#123;
    /* Read-mostly fields */

    /* zone watermarks, access with *_wmark_pages(zone) macros */
    unsigned long _watermark[NR_WMARK];
    unsigned long watermark_boost;

    unsigned long nr_reserved_highatomic;

    /*
     * We don&#39;t know if the memory that we&#39;re going to allocate will be
     * freeable or/and it will be released eventually, so to avoid totally
     * wasting several GB of ram we must reserve some of the lower zone
     * memory (otherwise we risk to run OOM on the lower zones despite
     * there being tons of freeable ram on the higher zones).  This array is
     * recalculated at runtime if the sysctl_lowmem_reserve_ratio sysctl
     * changes.
     */
    long lowmem_reserve[MAX_NR_ZONES];

#ifdef CONFIG_NUMA
    int node;
#endif
    struct pglist_data	*zone_pgdat;
    struct per_cpu_pageset __percpu *pageset;
    /*
     * the high and batch values are copied to individual pagesets for
     * faster access
     */
    int pageset_high;
    int pageset_batch;

#ifndef CONFIG_SPARSEMEM
    /*
     * Flags for a pageblock_nr_pages block. See pageblock-flags.h.
     * In SPARSEMEM, this map is stored in struct mem_section
     */
    unsigned long		*pageblock_flags;
#endif /* CONFIG_SPARSEMEM */

    /* zone_start_pfn == zone_start_paddr &gt;&gt; PAGE_SHIFT */
    unsigned long		zone_start_pfn;

    /*
     * spanned_pages is the total pages spanned by the zone, including
     * holes, which is calculated as:
     * 	spanned_pages = zone_end_pfn - zone_start_pfn;
     *
     * present_pages is physical pages existing within the zone, which
     * is calculated as:
     *	present_pages = spanned_pages - absent_pages(pages in holes);
     *
     * managed_pages is present pages managed by the buddy system, which
     * is calculated as (reserved_pages includes pages allocated by the
     * bootmem allocator):
     *	managed_pages = present_pages - reserved_pages;
     *
     * So present_pages may be used by memory hotplug or memory power
     * management logic to figure out unmanaged pages by checking
     * (present_pages - managed_pages). And managed_pages should be used
     * by page allocator and vm scanner to calculate all kinds of watermarks
     * and thresholds.
     *
     * Locking rules:
     *
     * zone_start_pfn and spanned_pages are protected by span_seqlock.
     * It is a seqlock because it has to be read outside of zone-&gt;lock,
     * and it is done in the main allocator path.  But, it is written
     * quite infrequently.
     *
     * The span_seq lock is declared along with zone-&gt;lock because it is
     * frequently read in proximity to zone-&gt;lock.  It&#39;s good to
     * give them a chance of being in the same cacheline.
     *
     * Write access to present_pages at runtime should be protected by
     * mem_hotplug_begin/end(). Any reader who can&#39;t tolerant drift of
     * present_pages should get_online_mems() to get a stable value.
     */
    atomic_long_t		managed_pages;
    unsigned long		spanned_pages;
    unsigned long		present_pages;

    const char		*name;

#ifdef CONFIG_MEMORY_ISOLATION
    /*
     * Number of isolated pageblock. It is used to solve incorrect
     * freepage counting problem due to racy retrieving migratetype
     * of pageblock. Protected by zone-&gt;lock.
     */
    unsigned long		nr_isolate_pageblock;
#endif

#ifdef CONFIG_MEMORY_HOTPLUG
    /* see spanned/present_pages for more description */
    seqlock_t		span_seqlock;
#endif

    int initialized;

    /* Write-intensive fields used from the page allocator */
    ZONE_PADDING(_pad1_)

    /* free areas of different sizes */
    struct free_area	free_area[MAX_ORDER];

    /* zone flags, see below */
    unsigned long		flags;

    /* Primarily protects free_area */
    spinlock_t		lock;

    /* Write-intensive fields used by compaction and vmstats. */
    ZONE_PADDING(_pad2_)

    /*
     * When free pages are below this point, additional steps are taken
     * when reading the number of free pages to avoid per-cpu counter
     * drift allowing watermarks to be breached
     */
    unsigned long percpu_drift_mark;

#if defined CONFIG_COMPACTION || defined CONFIG_CMA
    /* pfn where compaction free scanner should start */
    unsigned long		compact_cached_free_pfn;
    /* pfn where compaction migration scanner should start */
    unsigned long		compact_cached_migrate_pfn[ASYNC_AND_SYNC];
    unsigned long		compact_init_migrate_pfn;
    unsigned long		compact_init_free_pfn;
#endif

#ifdef CONFIG_COMPACTION
    /*
     * On compaction failure, 1&lt;&lt;compact_defer_shift compactions
     * are skipped before trying again. The number attempted since
     * last failure is tracked with compact_considered.
     * compact_order_failed is the minimum compaction failed order.
     */
    unsigned int		compact_considered;
    unsigned int		compact_defer_shift;
    int			compact_order_failed;
#endif

#if defined CONFIG_COMPACTION || defined CONFIG_CMA
    /* Set to true when the PG_migrate_skip bits should be cleared */
    bool			compact_blockskip_flush;
#endif

    bool			contiguous;

    ZONE_PADDING(_pad3_)
    /* Zone statistics */
    atomic_long_t		vm_stat[NR_VM_ZONE_STAT_ITEMS];
    atomic_long_t		vm_numa_stat[NR_VM_NUMA_STAT_ITEMS];
&#125; ____cacheline_internodealigned_in_smp;
</code></pre>
<p>åŒæ ·åœ°ï¼Œæˆ‘ä»¬æ¥äº†è§£å…¶ä¸­æ¯”è¾ƒé‡è¦çš„å­—æ®µ</p>
<ul>
<li><strong>_watermark</strong> æ°´ä½çº¿ï¼Œä¸€èˆ¬è¡¨ç¤ºå‰©ä½™ç©ºé—²é¡µæ¡†ï¼Œä»–åˆä¸‰ä¸ªæŒ¡ä½ï¼Œåˆ†åˆ«æ˜¯<code>WMARK_MIN</code>,<code>WMARK_LOW</code>,<code>WMARK_HIGH</code>ï¼Œä»–å­˜æ”¾åœ¨<code>_watermark</code>æ•°ç»„å½“ä¸­ï¼Œè¿›è¡Œå†…å­˜åˆ†é…çš„æ—¶å€™ï¼Œåˆ†é…å™¨ä¼šæ ¹æ®å½“å‰æ°´ä½æ¥é‡‡å–ä¸åŒçš„æªæ–½ï¼Œä¸‹é¢æä¸ªå›¾ï¼š</li>
</ul>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/38dbb6fd5266d016ce8f7ae1d22bd40734fa3561.jpg" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p><strong>lowmem_reserve</strong>:å½“æœ¬<code>zone</code>æ²¡æœ‰ç©ºé—²å—ä¹‹åï¼Œä¼šåˆ°åˆ«çš„<code>zone</code>ä¸­è¿›è¡Œåˆ†é…ï¼Œé¿å…åˆ†é…å†…å­˜å…¨åˆ†é…åœ¨ä½ç«¯<code>zone</code>ï¼Œè€Œæˆ‘ä»¬ä¸èƒ½ä¿è¯è¿™é‡Œåˆ†é…çš„å†…å­˜æ˜¯å¯é‡Šæ”¾ï¼Œæˆ–è€…æœ€ç»ˆä¼šè¢«é‡Šæ”¾çš„ï¼Œå‡ºç°ä½ç«¯<code>zone</code>åŒºåŸŸå†…å­˜æå‰è€—å°½ï¼Œè€Œé«˜ç«¯<code>zone</code>åŒºä¿ç•™å¤§é‡å†…å­˜ï¼Œå› æ­¤å£°åè¯¥å­—æ®µæ¥ä¿ç•™ä¸€æ®µå†…å­˜ï¼Œè€Œè¿™é‡Œçš„<code>zone</code>åŒºå†…å­˜æ˜¯å…¶ä»–<code>zone</code>ä¸èƒ½æ‰“æ‰°çš„</p>
</li>
<li><p><strong>node</strong>:æ ‡è¯†è¯¥<code>zone</code>æ‰€å±<code>node</code>ï¼Œå½“ç„¶ï¼Œè¿™é‡Œåªåœ¨<code>NUMA</code>å¯åŠ¨ï¼Œ<code>UMA</code>ä¸­åªæœ‰ä¸€ä¸ª<code>node</code>ï¼Œä¸éœ€è¦è¿™ä¸ªå­—æ®µ</p>
</li>
<li><p><strong>zone_pgdat</strong>:æ ‡è¯†æ‰€å±çš„<code>pglist_data</code>èŠ‚ç‚¹ï¼ŒåŒä¸Šé¢çš„<code>node</code></p>
</li>
<li><p><strong>pageset</strong>ï¼šç”±äºç›®å‰éƒ½æ˜¯å¤šå¤„ç†å™¨CPUæ¶æ„ï¼Œå› æ­¤å¯¹äºä¸´ç•ŒåŒºçš„åŒæ­¥äº’æ–¥è®¿é—®å°±æ˜¯ä¸€ä¸ªä¸¥é‡çš„é—®é¢˜ï¼Œè€Œé˜²æ­¢å‡ºé”™çš„åŠæ³•ä¹‹ä¸€åŠ é”è§£é”ååˆ†æµªè´¹èµ„æºï¼Œå› æ­¤æ¯ä¸ª<code>zone</code>å½“ä¸­éƒ½ä¸ºæ¯ä¸€ä¸ªCPUå‡†å¤‡ä¸€ä¸ªå•ç‹¬çš„é¡µé¢ä»“åº“ï¼Œæœ€å¼€å§‹<code>buddy system</code>ä¼šé¦–å…ˆå°†é¡µé¢æ”¾ç½®åœ¨å„ä¸ªCPUç‹¬è‡ªçš„é¡µé¢ä»“åº“å½“ä¸­ï¼Œéœ€è¦è¿›è¡Œåˆ†é…çš„æ—¶å€™ä¼˜å…ˆä»å…¶ä¸­åˆ†é…ï¼Œå…¶ç±»å‹ç»“æ„ä½“ä½äº<code>/include/linux/mmzone.h</code></p>
<pre><code class="hljs">  struct per_cpu_pages &#123;
      int count;		/* number of pages in the list */
      int high;		/* high watermark, emptying needed */
      int batch;		/* chunk size for buddy add/remove */
  
      /* Lists of pages, one per migrate type stored on the pcp-lists */
      struct list_head lists[MIGRATE_PCPTYPES]; //åŒé“¾è¡¨æŒ‡é’ˆæ•°ç»„ï¼ŒæŒ‡å‘ç©ºé—²é¡µä»¬
  &#125;;
  struct per_cpu_pageset &#123;
      struct per_cpu_pages pcp;
  #ifdef CONFIG_NUMA
      s8 expire;
      u16 vm_numa_stat_diff[NR_VM_NUMA_STAT_ITEMS];
  #endif
  #ifdef CONFIG_SMP
      s8 stat_threshold;
      s8 vm_stat_diff[NR_VM_ZONE_STAT_ITEMS];
  #endif
  &#125;;
</code></pre>
<p>  æ­¤ç»“æ„æ˜¯ä¸€ä¸ªåŒ…æ‹¬çŠ¶æ€ï¼Œä»–ä¼šè¢«å­˜æ”¾åœ¨æ¯ä¸ªCPUç‹¬ç«‹çš„<code>.data..percpu</code>æ®µå½“ä¸­ï¼Œä¸‹é¢å†å†å†æ¬¡å¼•ç”¨<code>arttnba3</code>å¸ˆå‚…çš„å›¾ï¼ŒçœŸçš„æ€ğŸ‚è¾£</p>
</li>
</ul>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/902397dda144ad340c83614e95a20cf431ad853f.jpg" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p><strong>zone_start_pfn</strong>ï¼šè¯¥<code>zone</code>çš„èµ·å§‹ç‰©ç†åœ°å€ç¼–å·pfn(page frame number)</p>
</li>
<li><p><strong>spanned_pages</strong>ï¼šæœ¬<code>zone</code>åŒºåŸŸä¸­å†…å­˜çš„<code>page</code>æ€»æ•°</p>
</li>
<li><p><strong>present_pages</strong>ï¼šæœ¬<code>zone</code>ä¸­å®é™…å­˜åœ¨çš„ç‰©ç†é¡µæ¡†æ•°</p>
</li>
<li><p><strong>managed_pages</strong>ï¼šæœ¬<code>zone</code>ä¸­<code>buddy system</code>ç®¡ç†çš„é¡µé¢æ•°é‡</p>
</li>
<li><p><strong>free_area</strong>ï¼š<code>buddy_system</code>æŒ‰ç…§<code>order</code>ç®¡ç†çš„é¡µé¢ï¼Œä¸ºä¸€ä¸ª<code>free_area</code>ç»“æ„ä½“æ•°ç»„ï¼Œå…·ä½“å®šä¹‰å¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">  struct free_area &#123;
      struct list_head    free_list[MIGRATE_TYPES];
      unsigned long        nr_free;
  &#125;;
</code></pre>
</li>
</ul>
<p>çœ‹å›¾å¥½å§,è¿™ä¸ª<code>order</code>èµ·å§‹å°±æ˜¯ä¼™ä¼´ç³»ç»Ÿä¸­çš„å¯¹äºä¸åŒå¤§å°é¡µåˆ†é…çš„è¯·æ±‚å¤§å°</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/f3d3572c11dfa9ec9b54b0de27d0f703908fc185.jpg" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p><strong>flags</strong>ï¼šæ ‡è¯†<code>zone</code>çš„çŠ¶æ€</p>
</li>
<li><p><strong>vm_stat</strong>ï¼šç»Ÿè®¡æ•°æ®ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œè€Œæ•°ç»„å¤§å°å–å†³äºå®šä¹‰çš„æšä¸¾ç±»å‹ï¼Œå¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">  enum zone_stat_item &#123;
      /* First 128 byte cacheline (assuming 64 bit words) */
      NR_FREE_PAGES,
      NR_ZONE_LRU_BASE, /* Used only for compaction and reclaim retry */
      NR_ZONE_INACTIVE_ANON = NR_ZONE_LRU_BASE,
      NR_ZONE_ACTIVE_ANON,
      NR_ZONE_INACTIVE_FILE,
      NR_ZONE_ACTIVE_FILE,
      NR_ZONE_UNEVICTABLE,
      NR_ZONE_WRITE_PENDING,	/* Count of dirty, writeback and unstable pages */
      NR_MLOCK,		/* mlock()ed pages found and moved off LRU */
      /* Second 128 byte cacheline */
      NR_BOUNCE,
  #if IS_ENABLED(CONFIG_ZSMALLOC)
      NR_ZSPAGES,		/* allocated in zsmalloc */
  #endif
      NR_FREE_CMA_PAGES,
      NR_VM_ZONE_STAT_ITEMS &#125;;
</code></pre>
</li>
</ul>
<p>è®²å®Œä¸€èˆ¬ç»“æ„ï¼Œè¿™é‡Œéœ€è¦æ³¨æ„ï¼Œè™½è¯´æˆ‘ä»¬çš„<code>node</code>èŠ‚ç‚¹ä¸­ç›´æ¥å°±æ˜¯ä¸€ä¸ª<code>zone</code>æ•°ç»„ï¼Œä½†ä»–ä»¬ä¹‹é—´æ˜¯æœ‰åŒºåˆ«çš„ï¼Œæ­¤åœ¨<code>/include/linux/mmzone.h</code>ä¸­æœ‰å®šä¹‰ï¼š</p>
<pre><code class="hljs">enum zone_type &#123;
    /*
     * ZONE_DMA and ZONE_DMA32 are used when there are peripherals not able
     * to DMA to all of the addressable memory (ZONE_NORMAL).
     * On architectures where this area covers the whole 32 bit address
     * space ZONE_DMA32 is used. ZONE_DMA is left for the ones with smaller
     * DMA addressing constraints. This distinction is important as a 32bit
     * DMA mask is assumed when ZONE_DMA32 is defined. Some 64-bit
     * platforms may need both zones as they support peripherals with
     * different DMA addressing limitations.
     */
#ifdef CONFIG_ZONE_DMA
    ZONE_DMA,
#endif
#ifdef CONFIG_ZONE_DMA32
    ZONE_DMA32,
#endif
    /*
     * Normal addressable memory is in ZONE_NORMAL. DMA operations can be
     * performed on pages in ZONE_NORMAL if the DMA devices support
     * transfers to all addressable memory.
     */
    ZONE_NORMAL,
#ifdef CONFIG_HIGHMEM
    /*
     * A memory area that is only addressable by the kernel through
     * mapping portions into its own address space. This is for example
     * used by i386 to allow the kernel to address the memory beyond
     * 900MB. The kernel will set up special mappings (page
     * table entries on i386) for each page that the kernel needs to
     * access.
     */
    ZONE_HIGHMEM,
#endif
    /*
     * ZONE_MOVABLE is similar to ZONE_NORMAL, except that it contains
     * movable pages with few exceptional cases described below. Main use
     * cases for ZONE_MOVABLE are to make memory offlining/unplug more
     * likely to succeed, and to locally limit unmovable allocations - e.g.,
     * to increase the number of THP/huge pages. Notable special cases are:
     *
     * 1. Pinned pages: (long-term) pinning of movable pages might
     *    essentially turn such pages unmovable. Memory offlining might
     *    retry a long time.
     * 2. memblock allocations: kernelcore/movablecore setups might create
     *    situations where ZONE_MOVABLE contains unmovable allocations
     *    after boot. Memory offlining and allocations fail early.
     * 3. Memory holes: kernelcore/movablecore setups might create very rare
     *    situations where ZONE_MOVABLE contains memory holes after boot,
     *    for example, if we have sections that are only partially
     *    populated. Memory offlining and allocations fail early.
     * 4. PG_hwpoison pages: while poisoned pages can be skipped during
     *    memory offlining, such pages cannot be allocated.
     * 5. Unmovable PG_offline pages: in paravirtualized environments,
     *    hotplugged memory blocks might only partially be managed by the
     *    buddy (e.g., via XEN-balloon, Hyper-V balloon, virtio-mem). The
     *    parts not manged by the buddy are unmovable PG_offline pages. In
     *    some cases (virtio-mem), such pages can be skipped during
     *    memory offlining, however, cannot be moved/allocated. These
     *    techniques might use alloc_contig_range() to hide previously
     *    exposed pages from the buddy again (e.g., to implement some sort
     *    of memory unplug in virtio-mem).
     *
     * In general, no unmovable allocations that degrade memory offlining
     * should end up in ZONE_MOVABLE. Allocators (like alloc_contig_range())
     * have to expect that migrating pages in ZONE_MOVABLE can fail (even
     * if has_unmovable_pages() states that there are no unmovable pages,
     * there can be false negatives).
     */
    ZONE_MOVABLE,
#ifdef CONFIG_ZONE_DEVICE
    ZONE_DEVICE,
#endif
    __MAX_NR_ZONES

&#125;;
</code></pre>
<p>è¿™é‡Œx86åˆ†åˆ«32ä½ä¸64ä½éƒ½ä¼šæœ‰æ‰€åŒºåˆ«ï¼Œå¦‚ä¸‹ï¼š<br>åœ¨32ä½ä¸­ï¼Œ<code>zone</code>å¯ä»¥åˆ†ä¸º<code>ZONE_DMA</code>ã€<code>ZONE_NORMAL</code>ã€<code>ZONE_HIGHMEM</code>ï¼Œä»–ä»¬åˆ†åˆ«å¯¹åº”çš„èµ·å§‹å’Œç»ˆæ­¢åœ°å€ä¸º</p>
<p><code>ZONE_DMA</code>ï¼š0~16MB</p>
<p><code>ZONE_NORMAL</code>ï¼š16~896MB</p>
<p><code>ZONE_HIGHMEM</code>:896~â€¦MB</p>
<p>ä»¥ä¸Šå‰ä¸¤ç§ç±»å‹æ˜¯çº¿æ€§æ˜ å°„ï¼Œä¹Ÿå°±æ˜¯è¿™é‡Œæ˜¯ç›´æ¥æ˜ å°„çš„ï¼Œä¹Ÿå°±æ˜¯è¯´å­˜åœ¨è™šæ‹Ÿåœ°å€å°±æ˜¯ç‰©ç†åœ°å€çš„æƒ…å½¢ï¼Œåé¢çš„é«˜ç«¯å†…å­˜æ˜¯ä¸è¿ç»­çš„</p>
<p>åœ¨64ä½ä¸­æœ‰æ‰€åŒºåˆ«ï¼Œ<code>zone</code>åˆ†ä¸ºå¦‚ä¸‹ä¸‰ç§</p>
<p><code>ZONE_DMA</code>ï¼š0~16MB</p>
<p><code>ZONE_DMA32</code>ï¼š16~4GB</p>
<p><code>ZONE_NORMAL</code>:4GB~â€¦</p>
<p>å†…æ ¸ä¸­å–æ¶ˆäº†é«˜ç«¯å†…å­˜çš„æ¦‚å¿µï¼Œæ¥ç€ä¸Šé¢å’±ä»¬ç”»çš„å›¾ï¼Œè¿™é‡Œæˆ‘ä»¬æŠŠ<code>zone</code>è¡¥ä¸Š</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/35a85edf8db1cb13cef9dada9854564e93584b63.jpg" srcset="/img/loading.gif" lazyload></p>
<h3 id="pageé¡µæ¡†"><a href="#pageé¡µæ¡†" class="headerlink" title="pageé¡µæ¡†"></a>pageé¡µæ¡†</h3><p>ç»ˆäºæ¥åˆ°äº†å’±ä»¬çš„é¡µæ¡†ï¼Œè¿™é‡Œçš„<code>page</code>å¯¹åº”çš„æ˜¯ç‰©ç†é¡µæ¡†è€Œä¸æ˜¯è™šæ‹Ÿé¡µï¼Œæ³¨æ„æ¼ã€‚<br>ä»–å¯¹åº”çš„æ•°æ®ç»“æ„æ˜¯<code>struct page</code>ï¼Œä½äº<code>/include/linux/mm_types.h</code>å¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">struct page &#123;
    unsigned long flags;		/* Atomic flags, some possibly
                     * updated asynchronously */
    /*
     * Five words (20/40 bytes) are available in this union.
     * WARNING: bit 0 of the first word is used for PageTail(). That
     * means the other users of this union MUST NOT use the bit to
     * avoid collision and false-positive PageTail().
     */
    union &#123;
        struct &#123;	/* Page cache and anonymous pages */
            /**
             * @lru: Pageout list, eg. active_list protected by
             * lruvec-&gt;lru_lock.  Sometimes used as a generic list
             * by the page owner.
             */
            struct list_head lru;
            /* See page-flags.h for PAGE_MAPPING_FLAGS */
            struct address_space *mapping;
            pgoff_t index;		/* Our offset within mapping. */
            /**
             * @private: Mapping-private opaque data.
             * Usually used for buffer_heads if PagePrivate.
             * Used for swp_entry_t if PageSwapCache.
             * Indicates order in the buddy system if PageBuddy.
             */
            unsigned long private;
        &#125;;
        struct &#123;	/* page_pool used by netstack */
            /**
             * @dma_addr: might require a 64-bit value on
             * 32-bit architectures.
             */
            unsigned long dma_addr[2];
        &#125;;
        struct &#123;	/* slab, slob and slub */
            union &#123;
                struct list_head slab_list;
                struct &#123;	/* Partial pages */
                    struct page *next;
#ifdef CONFIG_64BIT
                    int pages;	/* Nr of pages left */
                    int pobjects;	/* Approximate count */
#else
                    short int pages;
                    short int pobjects;
#endif
                &#125;;
            &#125;;
            struct kmem_cache *slab_cache; /* not slob */
            /* Double-word boundary */
            void *freelist;		/* first free object */
            union &#123;
                void *s_mem;	/* slab: first object */
                unsigned long counters;		/* SLUB */
                struct &#123;			/* SLUB */
                    unsigned inuse:16;
                    unsigned objects:15;
                    unsigned frozen:1;
                &#125;;
            &#125;;
        &#125;;
        struct &#123;	/* Tail pages of compound page */
            unsigned long compound_head;	/* Bit zero is set */

            /* First tail page only */
            unsigned char compound_dtor;
            unsigned char compound_order;
            atomic_t compound_mapcount;
            unsigned int compound_nr; /* 1 &lt;&lt; compound_order */
        &#125;;
        struct &#123;	/* Second tail page of compound page */
            unsigned long _compound_pad_1;	/* compound_head */
            atomic_t hpage_pinned_refcount;
            /* For both global and memcg */
            struct list_head deferred_list;
        &#125;;
        struct &#123;	/* Page table pages */
            unsigned long _pt_pad_1;	/* compound_head */
            pgtable_t pmd_huge_pte; /* protected by page-&gt;ptl */
            unsigned long _pt_pad_2;	/* mapping */
            union &#123;
                struct mm_struct *pt_mm; /* x86 pgds only */
                atomic_t pt_frag_refcount; /* powerpc */
            &#125;;
#if ALLOC_SPLIT_PTLOCKS
            spinlock_t *ptl;
#else
            spinlock_t ptl;
#endif
        &#125;;
        struct &#123;	/* ZONE_DEVICE pages */
            /** @pgmap: Points to the hosting device page map. */
            struct dev_pagemap *pgmap;
            void *zone_device_data;
            /*
             * ZONE_DEVICE private pages are counted as being
             * mapped so the next 3 words hold the mapping, index,
             * and private fields from the source anonymous or
             * page cache page while the page is migrated to device
             * private memory.
             * ZONE_DEVICE MEMORY_DEVICE_FS_DAX pages also
             * use the mapping, index, and private fields when
             * pmem backed DAX files are mapped.
             */
        &#125;;

        /** @rcu_head: You can use this to free a page by RCU. */
        struct rcu_head rcu_head;
    &#125;;

    union &#123;		/* This union is 4 bytes in size. */
        /*
         * If the page can be mapped to userspace, encodes the number
         * of times this page is referenced by a page table.
         */
        atomic_t _mapcount;

        /*
         * If the page is neither PageSlab nor mappable to userspace,
         * the value stored here may help determine what this page
         * is used for.  See page-flags.h for a list of page types
         * which are currently stored here.
         */
        unsigned int page_type;

        unsigned int active;		/* SLAB */
        int units;			/* SLOB */
    &#125;;

    /* Usage count. *DO NOT USE DIRECTLY*. See page_ref.h */
    atomic_t _refcount;

#ifdef CONFIG_MEMCG
    unsigned long memcg_data;
#endif

    /*
     * On machines where all RAM is mapped into kernel address space,
     * we can simply calculate the virtual address. On machines with
     * highmem some memory is mapped into kernel virtual memory
     * dynamically, so we need a place to store that address.
     * Note that this field could be 16 bits on x86 ... ;)
     *
     * Architectures with slow multiplication can define
     * WANT_PAGE_VIRTUAL in asm/page.h
     */
#if defined(WANT_PAGE_VIRTUAL)
    void *virtual;			/* Kernel virtual address (NULL if
                       not kmapped, ie. highmem) */
#endif /* WANT_PAGE_VIRTUAL */

#ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS
    int _last_cpupid;
#endif
&#125; _struct_page_alignment;
</code></pre>
<p>è€æ ·å­ï¼Œå…ˆè§£é‡Šå…³é”®å­—æ®µ</p>
<ul>
<li><p><strong>lru</strong>ï¼šæœ€è¿‘æœªä½¿ç”¨é¡µè¿™ä¸ªæ¦‚å¿µåœ¨è®¡ç®—æœºç»„æˆåŸç†æˆ–è€…è¯´æ“ä½œç³»ç»Ÿè¯¾ç¨‹é‡Œé¢éƒ½ä¼šè®²è§£ï¼Œè¿™é‡Œä¹Ÿå°±ä¸è¿‡å¤šæè¿°ï¼Œåœ¨linuxå†…æ ¸å½“ä¸­ï¼Œpageé€šè¿‡è¯¥å­—æ®µæ¥ç»„ç»‡æˆé“¾è¡¨</p>
</li>
<li><p><strong>slabç›¸å…³</strong>ï¼šç”¨æ¥å­˜æ”¾<code>slab</code>ç›¸å…³æˆå‘˜</p>
<pre><code class="hljs">  struct &#123;    /* slab, slob and slub */
              union &#123;
                  struct list_head slab_list;
                  struct &#123;    /* Partial pages */
                      struct page *next;
  #ifdef CONFIG_64BIT
                      int pages;  /* Nr of pages left */
                      int pobjects;   /* Approximate count */
  #else
                      short int pages;   	
                      short int pobjects;
  #endif
                  &#125;;
              &#125;;
              struct kmem_cache *slab_cache; /* not slob */
              /* Double-word boundary */
              void *freelist;     /* first free object */
              union &#123;
                  void *s_mem;    /* slab: first object */
                  unsigned long counters;     /* SLUB */
                  struct &#123;            /* SLUB */
                      unsigned inuse:16;
                      unsigned objects:15;
                      unsigned frozen:1;
                  &#125;;
              &#125;;
          &#125;;
</code></pre>
</li>
</ul>
<p>ä¸‹é¢ç»™å‡ºåˆä¸€å¼ ååˆ†è¯¦ç»†çš„å›¾ï¼Œæ˜¯ç”±ç®€Â·æå¥¥å¸ˆå‚…æ‰€ä½œ</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/4ec2d5628535e5dd881a441633c6a7efcf1b62c1.jpg" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p><strong>flags</strong>ï¼šè¡¨ç¤ºè¯¥é¡µæ‰€å¤„åœ¨çš„çŠ¶æ€ï¼Œå®šä¹‰äº<code>include/linux/page-flags.h</code>å½“ä¸­ï¼Œä»–æ˜¯ä¸€ä¸ªæšä¸¾ç±»å‹ï¼Œå¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">  enum pageflags &#123;
      PG_locked,        /* Page is locked. Don&#39;t touch. */
      PG_referenced,
      PG_uptodate,
      PG_dirty,
      PG_lru,
      PG_active,
      PG_workingset,
      PG_waiters,        /* Page has waiters, check its waitqueue. Must be bit #7 and in the same byte as &quot;PG_locked&quot; */
      PG_error,
      PG_slab,
      PG_owner_priv_1,    /* Owner use. If pagecache, fs may use*/
      PG_arch_1,
      PG_reserved,
      PG_private,        /* If pagecache, has fs-private data */
      PG_private_2,        /* If pagecache, has fs aux data */
      PG_writeback,        /* Page is under writeback */
      PG_head,        /* A head page */
      PG_mappedtodisk,    /* Has blocks allocated on-disk */
      PG_reclaim,        /* To be reclaimed asap */
      PG_swapbacked,        /* Page is backed by RAM/swap */
      PG_unevictable,        /* Page is &quot;unevictable&quot;  */
  #ifdef CONFIG_MMU
      PG_mlocked,        /* Page is vma mlocked */
  #endif
  #ifdef CONFIG_ARCH_USES_PG_UNCACHED
      PG_uncached,        /* Page has been mapped as uncached */
  #endif
  #ifdef CONFIG_MEMORY_FAILURE
      PG_hwpoison,        /* hardware poisoned page. Don&#39;t touch */
  #endif
  #if defined(CONFIG_IDLE_PAGE_TRACKING) &amp;&amp; defined(CONFIG_64BIT)
      PG_young,
      PG_idle,
  #endif
  #ifdef CONFIG_64BIT
      PG_arch_2,
  #endif
      __NR_PAGEFLAGS,
  
      /* Filesystems */
      PG_checked = PG_owner_priv_1,
  
      /* SwapBacked */
      PG_swapcache = PG_owner_priv_1,    /* Swap page: swp_entry_t in private */
  
      /* Two page bits are conscripted by FS-Cache to maintain local caching
       * state.  These bits are set on pages belonging to the netfs&#39;s inodes
       * when those inodes are being locally cached.
       */
      PG_fscache = PG_private_2,    /* page backed by cache */
  
      /* XEN */
      /* Pinned in Xen as a read-only pagetable page. */
      PG_pinned = PG_owner_priv_1,
      /* Pinned as part of domain save (see xen_mm_pin_all()). */
      PG_savepinned = PG_dirty,
      /* Has a grant mapping of another (foreign) domain&#39;s page. */
      PG_foreign = PG_owner_priv_1,
      /* Remapped by swiotlb-xen. */
      PG_xen_remapped = PG_owner_priv_1,
  
      /* SLOB */
      PG_slob_free = PG_private,
  
      /* Compound pages. Stored in first tail page&#39;s flags */
      PG_double_map = PG_workingset,
  
      /* non-lru isolated movable page */
      PG_isolated = PG_reclaim,
  
      /* Only valid for buddy pages. Used to track pages that are reported */
      PG_reported = PG_uptodate,
  &#125;;
</code></pre>
<p>  è¿™é‡Œé‡‡ç”¨çš„å¤ç”¨çš„æ‰‹æ³•ï¼Œä¹Ÿå°±æ˜¯è¯´flagså­—æ®µè¿˜å®¹çº³äº†å…¶ä»–å…ƒç´ ï¼Œå¦‚ä¸‹ï¼Œç»“æ„åˆ’åˆ†ä½äº<code>/include/linux/page-flags-layout.h</code>å½“ä¸­</p>
<pre><code class="hljs">  /*
   * page-&gt;flags layout:
   *
   * There are five possibilities for how page-&gt;flags get laid out.  The first
   * pair is for the normal case without sparsemem. The second pair is for
   * sparsemem when there is plenty of space for node and section information.
   * The last is when there is insufficient space in page-&gt;flags and a separate
   * lookup is necessary.
   *
   * No sparsemem or sparsemem vmemmap: |       NODE     | ZONE |             ... | FLAGS |
   *      &quot; plus space for last_cpupid: |       NODE     | ZONE | LAST_CPUPID ... | FLAGS |
   * classic sparse with space for node:| SECTION | NODE | ZONE |             ... | FLAGS |
   *      &quot; plus space for last_cpupid: | SECTION | NODE | ZONE | LAST_CPUPID ... | FLAGS |
   * classic sparse no space for node:  | SECTION |     ZONE    | ... | FLAGS |
   */
</code></pre>
</li>
</ul>
<p> å¯ä»¥çœ‹åˆ°åœ¨ä¸åŒå¸ƒå±€ä¸‹ä»–å…¶å®æ˜¯å¯ä»¥ç”¨ä½œæŒ‡å‘å½’å±çš„<code>zone</code>å’Œ<code>node</code>çš„</p>
<ul>
<li><p><strong>_mapcount</strong>ï¼šè®°å½•è¯¥é¡µè¢«é¡µè¡¨æ˜ å°„çš„æ¬¡æ•°ï¼Œåˆå§‹å€¼ä¸º-1ï¼Œä»–æ˜¯ä¸€ä¸ªæ ¹æ®ä¸åŒæƒ…å†µæ‰€é‡‡ç”¨çš„è”åˆç»“æ„ä½“ï¼Œå¦‚æœè¯´ä»–æ˜¯è¢«ç”¨æˆ·ç©ºé—´æ‰€æ˜ å°„ï¼Œé‚£ä¹ˆä»–ä¼šè®°å½•è¢«æ˜ å°„çš„æ¬¡æ•°ï¼Œä½†è‹¥æ˜¯ä»–æ²¡è¢«æ˜ å°„åˆ°ç”¨æˆ·ç©ºé—´ï¼Œé¡µä¸æ˜¯<code>PageSlab</code>,é‚£ä¹ˆä»–ä¸ºpage_typeå­—æ®µï¼Œå®ƒå®šä¹‰äº<code>/include/linux/page-flags.h</code>å­—æ®µå½“ä¸­ï¼Œå¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">  /*
   * For pages that are never mapped to userspace (and aren&#39;t PageSlab),
   * page_type may be used.  Because it is initialised to -1, we invert the
   * sense of the bit, so __SetPageFoo *clears* the bit used for PageFoo, and
   * __ClearPageFoo *sets* the bit used for PageFoo.  We reserve a few high and
   * low bits so that an underflow or overflow of page_mapcount() won&#39;t be
   * mistaken for a page type value.
   */
  
  #define PAGE_TYPE_BASE    0xf0000000
  /* Reserve        0x0000007f to catch underflows of page_mapcount */
  #define PAGE_MAPCOUNT_RESERVE    -128
  #define PG_buddy    0x00000080
  #define PG_offline    0x00000100
  #define PG_table    0x00000200
  #define PG_guard    0x00000400
</code></pre>
</li>
<li><p><strong>_refcount</strong>ï¼šç”¨ä½œè¯¥é¡µåœ¨å†…æ ¸ä¸­çš„å¼•ç”¨æ¬¡æ•°ï¼Œåˆå€¼ä¸º0ï¼Œè‹¥å¤§äº0è¡¨ç¤ºæ­£åœ¨è¢«ä½¿ç”¨ï¼Œç­‰äº0è¡¨ç¤ºç©ºé—²æˆ–å°†è¦è¢«é‡Šæ”¾ï¼Œå†…æ ¸å‡½æ•°<code>get_page()</code>å’Œ<code>put_page()</code>å‡½æ•°ä¼šæ¥è¿›è¡Œå¼•ç”¨è®¡æ•°çš„å¢å‡ï¼Œåè€…è‹¥å¼•ç”¨è®¡æ•°å™¨ä¸º1åˆ™ä¼šè°ƒç”¨<code>__put_single_page()</code>é‡Šæ”¾è¯¥é¡µé¢</p>
</li>
<li><p><strong>vitrual</strong>ï¼šæŒ‡å‘ç‰©ç†é¡µæ¡†å¯¹åº”è™šæ‹Ÿåœ°å€ï¼ˆè¿™é‡Œæœ‰ç‚¹ç–‘é—®é‚£å°±æ˜¯ä»–è¢«å¤šä¸ªé¡µè¡¨æ˜ å°„å’‹åŠæï¼Œè¿˜æ˜¯è¯´æ¯æ¬¡åˆ‡æ¢è¿›ç¨‹çš„æ—¶å€™ä¼šåˆ·æ–°ä¸€ä¸‹è¿™é‡Œå‘¢ï¼Ÿï¼‰</p>
</li>
</ul>
<p>è¯´å®Œæ•°æ®ç»“æ„ï¼Œè¿˜è®°å¾—ä¸Šé¢<code>flags</code>ä¸åŒå¸ƒå±€ä¸‹å¯¹åº”çš„ç»“æ„å—ï¼Œlinuxä¸€èˆ¬æä¾›äº†ä¸‰ç§å†…å­˜æ¨¡å‹ï¼Œå®šä¹‰åœ¨<code>/include/asm-generic/memory_model.h</code><br><img src="http://imgsrc.baidu.com/forum/pic/item/2fdda3cc7cd98d106098edf8643fb80e7aec90af.jpg" srcset="/img/loading.gif" lazyload></p>
<p>å¸¸ç”¨æ¨¡å‹æ˜¯<code>sparsemem</code>,æ‰€ä»¥æˆ‘ä»¬åªäº†è§£ä»–ï¼Œä¸­æ–‡ç¿»è¯‘è¿‡æ¥å°±æ˜¯ç¦»æ•£å†…å­˜æ¨¡å‹ã€‚åœ¨è¿™ä¸ªæ¨¡å‹ä¸‹ï¼Œå†…å­˜ä¸­ä¼šå­˜åœ¨ä¸€ä¸ª<code>mem_section</code>ç±»å‹çš„æŒ‡é’ˆæ•°ç»„ï¼Œè€Œå…¶ä¸­å…ƒç´ æŒ‡å‘çš„<code>mem_section</code>ç»“æ„ä½“ä¸­çš„<code>section_mem_map</code>æˆå‘˜ä¼šæŒ‡å‘ä¸€ä¸ª<code>struct page</code>ç±»å‹çš„æ•°ç»„ï¼Œå®ƒå¯¹åº”äºä¸€ä¸ªè¿ç»­çš„ç‰©ç†åœ°å€ç©ºé—´ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/962bd40735fae6cdb11e4aa84ab30f2443a70f55.jpg" srcset="/img/loading.gif" lazyload></p>
<p>å…¶ä¸­<code>mem_section</code>ç»“æ„ä½“çš„å®šä¹‰åœ¨<code>/include/linux/mmzone.h</code>å½“ä¸­ï¼Œå¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">struct mem_section &#123;
    /*
     * This is, logically, a pointer to an array of struct
     * pages.  However, it is stored with some other magic.
     * (see sparse.c::sparse_init_one_section())
     *
     * Additionally during early boot we encode node id of
     * the location of the section here to guide allocation.
     * (see sparse.c::memory_present())
     *
     * Making it a UL at least makes someone do a cast
     * before using it wrong.
     */
    unsigned long section_mem_map;

    struct mem_section_usage *usage;
#ifdef CONFIG_PAGE_EXTENSION
    /*
     * If SPARSEMEM, pgdat doesn&#39;t have page_ext pointer. We use
     * section. (see page_ext.h about this.)
     */
    struct page_ext *page_ext;
    unsigned long pad;
#endif
    /*
     * WARNING: mem_section must be a power-of-2 in size for the
     * calculation and use of SECTION_ROOT_MASK to make sense.
     */
&#125;;
</code></pre>
<p>è€Œæˆ‘ä»¬çš„å…¨å±€<code>mem_section</code>æ•°ç»„å­˜æ”¾ç€æŒ‡å‘æ‰€æœ‰<code>struct mem_section</code>ç»“æ„ä½“çš„æŒ‡é’ˆï¼Œå®šä¹‰äº<code>/mm/sparse.c</code>å½“ä¸­ï¼š</p>
<pre><code class="hljs">#ifdef CONFIG_SPARSEMEM_EXTREME
struct mem_section **mem_section;
#else
struct mem_section mem_section[NR_SECTION_ROOTS][SECTIONS_PER_ROOT]
    ____cacheline_internodealigned_in_smp;
#endif
</code></pre>
<p>å’±ä»¬ä¹‹å‰è¯´åˆ°çš„æ•°æ®ç»“æ„éƒ½ä¼šä½¿ç”¨<code>PFN</code>è¿›è¡Œè¡¨ç¤ºç‰©ç†åœ°å€ï¼Œä½†å®é™…ä¸Šä»–å¹¶ä¸æ˜¯ç‰©ç†åœ°å€ï¼Œè€Œæ˜¯å¯¹åº”çš„æŸä¸€ä¸ª<code>page</code>çš„ï¼Œè€Œ<code>pfn</code>çš„å«ä¹‰å°±æ˜¯<code>page frame number</code>ï¼Œä»–ä¸ºæ¯ä¸ªç‰©ç†é¡µæ¡†æ‰€åœ¨ä½ç½®éƒ½ç¼–äº†ä¸ªå·ã€‚è€Œæˆ‘ä»¬è¦é€šè¿‡<code>PFN</code>æ‰¾åˆ°<code>page</code>æˆ–é€šè¿‡<code>page</code>æ‰¾åˆ°<code>PFN</code>éƒ½éœ€è¦è¿™ä¸ª<code>mem_section</code>ç»“æ„ä½“ä¸­çš„<code>section_mem_map</code>æ¥å®ç°ã€‚</p>
<h2 id="2-ä¼™ä¼´ç³»ç»Ÿ"><a href="#2-ä¼™ä¼´ç³»ç»Ÿ" class="headerlink" title="2.ä¼™ä¼´ç³»ç»Ÿ"></a>2.ä¼™ä¼´ç³»ç»Ÿ</h2><p>æˆ‘ä»¬åˆšåˆšå·²ç»çŸ¥é“äº†ï¼Œæ¯ä¸ª<code>zone</code>ä¸­åŒ…å«ä¸€ä¸ª<code>free_area</code>æ•°ç»„ï¼Œå…¶ä¸­å°±æ˜¯ä¸€ä¸ªä¸ªçš„åŒé“¾è¡¨ï¼Œä¸”æŒ‰ç…§äº†<code>buddy system</code>çš„<code>order</code>è¿›è¡Œç®¡ç†ï¼Œ<br><img src="http://imgsrc.baidu.com/forum/pic/item/f3d3572c11dfa9ec9b54b0de27d0f703908fc185.jpg" srcset="/img/loading.gif" lazyload></p>
<p>è€Œæˆ‘ä»¬ä¸€ä¸ª<code>free_area</code>ä¸­å…¶å®å¹¶ä¸åªæœ‰ä¸€ä¸ªåŒå‘é“¾è¡¨ï¼Œä»–æ˜¯æŒ‰ç…§ä¸åŒçš„<code>migrate type</code>ä¹Ÿå°±æ˜¯è¿ç§»ç±»å‹è¿›è¡Œå­˜æ”¾ï¼Œä¸»è¦æ˜¯ä¸ºäº†é¿å…å†…å­˜è¿‡äºç¢ç‰‡åŒ–ï¼Œå¦‚ä¸‹å›¾ï¼š</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/cb8065380cd79123d89a77bde8345982b3b78085.jpg" srcset="/img/loading.gif" lazyload></p>
<p>è€Œè¿™é‡Œçš„é¡µé¢å­˜åœ¨ä¸€ä¸ªè¿ç§»ç±»å‹ï¼Œè¿™å†³å®šäº†è¯¥é¡µæ˜¯å¦å¯ä»¥è¿ç§»ï¼Œå¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">enum migratetype &#123;
    MIGRATE_UNMOVABLE, 			//ä¸å¯ç§»åŠ¨
    MIGRATE_MOVABLE, 			//ä¸å¯ç§»åŠ¨
    MIGRATE_RECLAIMABLE, 		//ä¸èƒ½ç›´æ¥ç§»åŠ¨ï¼Œä½†å¯ä»¥åˆ é™¤ï¼Œä¾‹å¦‚æ–‡ä»¶æ˜ å°„é¡µ
    MIGRATE_PCPTYPES,	/* the number of types on the pcp lists */ //ä»…é™åŒä¸€èŠ‚ç‚¹å†…ç§»åŠ¨
    MIGRATE_HIGHATOMIC = MIGRATE_PCPTYPES,
#ifdef CONFIG_CMA
    /*
     * MIGRATE_CMA migration type is designed to mimic the way
     * ZONE_MOVABLE works.  Only movable pages can be allocated
     * from MIGRATE_CMA pageblocks and page allocator never
     * implicitly change migration type of MIGRATE_CMA pageblock.
     *
     * The way to use it is to change migratetype of a range of
     * pageblocks to MIGRATE_CMA which can be done by
     * __free_pageblock_cma() function.  What is important though
     * is that a range of pageblocks must be aligned to
     * MAX_ORDER_NR_PAGES should biggest page be bigger then
     * a single pageblock.
     */
    MIGRATE_CMA, 				//è¿ç»­çš„ç‰©ç†å†…å­˜
#endif
#ifdef CONFIG_MEMORY_ISOLATION
    MIGRATE_ISOLATE,	/* can&#39;t allocate from here */
#endif
    MIGRATE_TYPES
&#125;;
</code></pre>
<p>ä¸‹é¢ä»ç„¶æ˜¯ä¸€ä¸ª<code>arttnba3</code>å¸ˆå‚…æ‰€åšçš„å›¾</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/adaf2edda3cc7cd9d368d7107c01213fb90e91b6.jpg" srcset="/img/loading.gif" lazyload></p>
<p>è€Œ<code>free_area</code>ä¸­çš„ç»“æ„ä¸­çš„<code>nr_free</code>è¡¨ç¤ºçš„æ˜¯å½“å‰<code>free_area</code>ä¸­ç©ºé—²é¡µé¢å—çš„æ•°é‡</p>
<pre><code class="hljs">struct free_area &#123;
    struct list_head	free_list[MIGRATE_TYPES];
    unsigned long		nr_free;
&#125;;
</code></pre>
<h3 id="1-åˆ†é…é¡µæ¡†"><a href="#1-åˆ†é…é¡µæ¡†" class="headerlink" title="1. åˆ†é…é¡µæ¡†"></a>1. åˆ†é…é¡µæ¡†</h3><p>å†…æ ¸ä¸­å®ç°äº†å‡ ä¸ªå‡½æ•°æ¥å£æ¥è¯·æ±‚é¡µæ¡†ï¼Œæœ€ç»ˆéƒ½ä¼šè°ƒç”¨<code>__alloc_pages_nodemask</code>ï¼Œå¦‚ä¸‹å›¾</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/11385343fbf2b211dbb767878f8065380dd78e5a.jpg" srcset="/img/loading.gif" lazyload></p>
<p>å…¶ä¸­æ ¸å¿ƒçš„å‡½æ•°å°±æ˜¯<code>__alloc_pages_nodemask</code>,è¿™é‡Œæˆ‘ä»¬éœ€è¦å…ˆçŸ¥é“<code>gfp_mask</code>å’Œ<code>alloc_flags</code>è¿™ä¸¤ä¸ªæ ‡å¿—</p>
<p><strong>gfp_flags</strong></p>
<ol>
<li>__GFP_DMAï¼šè¯·æ±‚åœ¨ZONE_DMAåŒºåŸŸä¸­åˆ†é…é¡µé¢ï¼›</li>
<li>__GFP_HIGHMEMï¼šè¯·æ±‚åœ¨ZONE_HIGHMEMåŒºåŸŸä¸­åˆ†é…é¡µé¢ï¼›</li>
<li>__GFP_MOVABLEï¼šZONE_MOVALBEå¯ç”¨æ—¶åœ¨è¯¥åŒºåŸŸåˆ†é…é¡µé¢ï¼ŒåŒæ—¶è¡¨ç¤ºé¡µé¢åˆ†é…åå¯ä»¥åœ¨å†…å­˜å‹ç¼©æ—¶è¿›è¡Œè¿ç§»ï¼Œä¹Ÿèƒ½è¿›è¡Œå›æ”¶ï¼›</li>
<li>__GFP_RECLAIMABLEï¼šè¯·æ±‚åˆ†é…åˆ°å¯æ¢å¤é¡µé¢ï¼›</li>
<li>__GFP_HIGHï¼šé«˜ä¼˜å…ˆçº§å¤„ç†è¯·æ±‚ï¼›</li>
<li>__GFP_IOï¼šè¯·æ±‚åœ¨åˆ†é…æœŸé—´è¿›è¡Œ I&#x2F;O æ“ä½œï¼›</li>
<li>__GFP_FSï¼šè¯·æ±‚åœ¨åˆ†é…æœŸé—´è¿›è¡Œæ–‡ä»¶ç³»ç»Ÿè°ƒç”¨ï¼›</li>
<li>__GFP_ZEROï¼šè¯·æ±‚å°†åˆ†é…çš„åŒºåŸŸåˆå§‹åŒ–ä¸º 0ï¼›</li>
<li>__GFP_NOFAILï¼šä¸å…è®¸è¯·æ±‚å¤±è´¥ï¼Œä¼šæ— é™é‡è¯•ï¼›</li>
<li>__GFP_NORETRYï¼šè¯·æ±‚ä¸é‡è¯•å†…å­˜åˆ†é…è¯·æ±‚ï¼›<br>è¿™é‡Œæˆ‘æ˜¯ç›´æ¥å¼•ç”¨çš„cft56200_lnå¸ˆå‚…çš„å›¾<br><img src="http://imgsrc.baidu.com/forum/pic/item/fc1f4134970a304ebfdb423394c8a786c8175c7a.jpg" srcset="/img/loading.gif" lazyload></li>
</ol>
<p><strong>alloc_flags</strong></p>
<ol>
<li>ALLOC_WMARK_MINï¼šä»…åœ¨æœ€å°æ°´ä½water markåŠä»¥ä¸Šé™åˆ¶é¡µé¢åˆ†é…ï¼›</li>
<li>ALLOC_WMARK_LOWï¼šä»…åœ¨ä½æ°´ä½water markåŠä»¥ä¸Šé™åˆ¶é¡µé¢åˆ†é…ï¼›</li>
<li>ALLOC_WMARK_HIGHï¼šä»…åœ¨é«˜æ°´ä½water markåŠä»¥ä¸Šé™åˆ¶é¡µé¢åˆ†é…ï¼›</li>
<li>ALLOC_HARDERï¼šåŠªåŠ›åˆ†é…ï¼Œä¸€èˆ¬åœ¨gfp_maskè®¾ç½®äº†__GFP_ATOMICæ—¶ä¼šä½¿ç”¨ï¼›</li>
<li>ALLOC_HIGHï¼šé«˜ä¼˜å…ˆçº§åˆ†é…ï¼Œä¸€èˆ¬åœ¨gfp_maskè®¾ç½®äº†__GFP_HIGHæ—¶ä½¿ç”¨ï¼›</li>
<li>ALLOC_CPUSETï¼šæ£€æŸ¥æ˜¯å¦ä¸ºæ­£ç¡®çš„ cpusetï¼›</li>
<li>ALLOC_CMAï¼šå…è®¸ä» CMA åŒºåŸŸè¿›è¡Œåˆ†é…</li>
</ol>
<p>ä¸‹é¢å°±æ˜¯è¯¥æ ¸å¿ƒå‡½æ•°çš„å‡½æ•°ä½“éƒ¨åˆ†ï¼Œä»–ä½äº<code>/mm/page_alloc.c</code>å½“ä¸­ï¼Œå¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">/*
 * This is the &#39;heart&#39; of the zoned buddy allocator.ï¼ˆçœ‹å¥½äº†ï¼Œå…„å¼Ÿç³»ç»Ÿæ˜¯è¿™ä¹ˆç”¨çš„ï¼‰
 */
struct page *
__alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order, int preferred_nid,
                            nodemask_t *nodemask)
&#123;
    struct page *page;
    unsigned int alloc_flags = ALLOC_WMARK_LOW;
    gfp_t alloc_mask; /* The gfp_t that was actually used for allocation */
    struct alloc_context ac = &#123; &#125;;

    /*
     * There are several places where we assume that the order value is sane
     * so bail out early if the request is out of bound.
     */
    if (unlikely(order &gt;= MAX_ORDER)) &#123;
        WARN_ON_ONCE(!(gfp_mask &amp; __GFP_NOWARN));
        return NULL;
    &#125;

    gfp_mask &amp;= gfp_allowed_mask;
    alloc_mask = gfp_mask;
    if (!prepare_alloc_pages(gfp_mask, order, preferred_nid, nodemask, &amp;ac, &amp;alloc_mask, &amp;alloc_flags))
        return NULL;

    /*
     * Forbid the first pass from falling back to types that fragment
     * memory until all local zones are considered.
     */
    alloc_flags |= alloc_flags_nofragment(ac.preferred_zoneref-&gt;zone, gfp_mask);

    /* First allocation attempt */
    page = get_page_from_freelist(alloc_mask, order, alloc_flags, &amp;ac);
    if (likely(page))
        goto out;

    /*
     * Apply scoped allocation constraints. This is mainly about GFP_NOFS
     * resp. GFP_NOIO which has to be inherited for all allocation requests
     * from a particular context which has been marked by
     * memalloc_no&#123;fs,io&#125;_&#123;save,restore&#125;.
     */
    alloc_mask = current_gfp_context(gfp_mask);
    ac.spread_dirty_pages = false;

    /*
     * Restore the original nodemask if it was potentially replaced with
     * &amp;cpuset_current_mems_allowed to optimize the fast-path attempt.
     */
    ac.nodemask = nodemask;

    page = __alloc_pages_slowpath(alloc_mask, order, &amp;ac);

out:
    if (memcg_kmem_enabled() &amp;&amp; (gfp_mask &amp; __GFP_ACCOUNT) &amp;&amp; page &amp;&amp;
        unlikely(__memcg_kmem_charge_page(page, gfp_mask, order) != 0)) &#123;
        __free_pages(page, order);
        page = NULL;
    &#125;

    trace_mm_page_alloc(page, order, alloc_mask, ac.migratetype);

    return page;
&#125;
EXPORT_SYMBOL(__alloc_pages_nodemask);
</code></pre>
<p>ä¸Šé¢å‡½æ•°æ¦‚æ‹¬ä¸ºä¸‹é¢çš„æ­¥éª¤ï¼š</p>
<ol>
<li>æ£€æµ‹ç¯å¢ƒï¼Œå‡†å¤‡åˆ†é…</li>
<li>å¿«é€Ÿåˆ†é…ï¼Œè°ƒç”¨<code>get_page_from_freelist()</code></li>
<li>æ…¢é€Ÿåˆ†é…ï¼Œè°ƒç”¨<code>__alloc_pages_slowpath()</code></li>
<li>å¿«æ…¢å‡å¤±è´¥ï¼Œè€ƒè™‘é¡µé¢å›æ”¶ï¼Œæ€æ­»è¿›ç¨‹åå†æ¬¡å°è¯•</li>
</ol>
<p>å…¶ä¸­å‡†å¤‡å‡½æ•°<code>prepare_alloc_pages()</code>æ˜¯è®¾å®šä¸€ä¸‹ç¯å¢ƒå€¼ä¸”ä»æŒ‡å®šå‚æ•°<code>node</code>ä¸­è·å–ä¸€ä¸ª<code>zonelist</code>ï¼Œè¿™é‡Œå°±ä¸å¤šè®²äº†ï¼Œç›´æ¥æ¥è®²è§£å¿«é€Ÿåˆ†é…å‡½æ•°<code>get_page_from_freelist()</code>,ä»–ä½äº<code>/mm/page_alloc.c</code></p>
<pre><code class="hljs">static struct page *
get_page_from_freelist(gfp_t gfp_mask, unsigned int order, int alloc_flags,
                        const struct alloc_context *ac)
&#123;
    struct zoneref *z;
    struct zone *zone;
    struct pglist_data *last_pgdat_dirty_limit = NULL;
    bool no_fallback;

retry:
    /*
     * æ‰«æ zonelist, å¯»æ‰¾æœ‰ç€è¶³å¤Ÿç©ºé—²å—çš„zone
     * See also __cpuset_node_allowed() comment in kernel/cpuset.c.
     */
    no_fallback = alloc_flags &amp; ALLOC_NOFRAGMENT;
    z = ac-&gt;preferred_zoneref;
    for_next_zone_zonelist_nodemask(zone, z, ac-&gt;highest_zoneidx,
                    ac-&gt;nodemask) &#123;
        struct page *page;
        unsigned long mark;

        if (cpusets_enabled() &amp;&amp;
            (alloc_flags &amp; ALLOC_CPUSET) &amp;&amp;
            !__cpuset_zone_allowed(zone, gfp_mask))
                continue;
        /*
         * When allocating a page cache page for writing, we
         * want to get it from a node that is within its dirty
         * limit, such that no single node holds more than its
         * proportional share of globally allowed dirty pages.
         * The dirty limits take into account the node&#39;s
         * lowmem reserves and high watermark so that kswapd
         * should be able to balance it without having to
         * write pages from its LRU list.
         *
         * XXX: For now, allow allocations to potentially
         * exceed the per-node dirty limit in the slowpath
         * (spread_dirty_pages unset) before going into reclaim,
         * which is important when on a NUMA setup the allowed
         * nodes are together not big enough to reach the
         * global limit.  The proper fix for these situations
         * will require awareness of nodes in the
         * dirty-throttling and the flusher threads.
         */
        if (ac-&gt;spread_dirty_pages) &#123;
            if (last_pgdat_dirty_limit == zone-&gt;zone_pgdat)
                continue;

            if (!node_dirty_ok(zone-&gt;zone_pgdat)) &#123;
                last_pgdat_dirty_limit = zone-&gt;zone_pgdat;
                continue;
            &#125;
        &#125;

        if (no_fallback &amp;&amp; nr_online_nodes &gt; 1 &amp;&amp;
            zone != ac-&gt;preferred_zoneref-&gt;zone) &#123;
            int local_nid;

            /*
             * If moving to a remote node, retry but allow
             * fragmenting fallbacks. Locality is more important
             * than fragmentation avoidance.
             */
            local_nid = zone_to_nid(ac-&gt;preferred_zoneref-&gt;zone);
            if (zone_to_nid(zone) != local_nid) &#123;
                alloc_flags &amp;= ~ALLOC_NOFRAGMENT;
                goto retry;
            &#125;
        &#125;

        mark = wmark_pages(zone, alloc_flags &amp; ALLOC_WMARK_MASK);
        if (!zone_watermark_fast(zone, order, mark,
                       ac-&gt;highest_zoneidx, alloc_flags,
                       gfp_mask)) &#123;
            int ret;

#ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT
            /*
             * Watermark failed for this zone, but see if we can
             * grow this zone if it contains deferred pages.
             */
            if (static_branch_unlikely(&amp;deferred_pages)) &#123;
                if (_deferred_grow_zone(zone, order))
                    goto try_this_zone;
            &#125;
#endif
            /* Checked here to keep the fast path fast */
            BUILD_BUG_ON(ALLOC_NO_WATERMARKS &lt; NR_WMARK);
            if (alloc_flags &amp; ALLOC_NO_WATERMARKS)
                goto try_this_zone;

            if (node_reclaim_mode == 0 ||
                !zone_allows_reclaim(ac-&gt;preferred_zoneref-&gt;zone, zone))
                continue;

            ret = node_reclaim(zone-&gt;zone_pgdat, gfp_mask, order);
            switch (ret) &#123;
            case NODE_RECLAIM_NOSCAN:
                /* did not scan */
                continue;
            case NODE_RECLAIM_FULL:
                /* scanned but unreclaimable */
                continue;
            default:
                /* did we reclaim enough */
                if (zone_watermark_ok(zone, order, mark,
                    ac-&gt;highest_zoneidx, alloc_flags))
                    goto try_this_zone;

                continue;
            &#125;
        &#125;

try_this_zone:   	//æœ¬zoneæ­£å¸¸æ°´ä½
        page = rmqueue(ac-&gt;preferred_zoneref-&gt;zone, zone, order,
                gfp_mask, alloc_flags, ac-&gt;migratetype);
        if (page) &#123;
            prep_new_page(page, order, gfp_mask, alloc_flags);

            /*
             * If this is a high-order atomic allocation then check
             * if the pageblock should be reserved for the future
             */
            if (unlikely(order &amp;&amp; (alloc_flags &amp; ALLOC_HARDER)))
                reserve_highatomic_pageblock(page, zone, order);

            return page;
        &#125; else &#123;
#ifdef CONFIG_DEFERRED_STRUCT_PAGE_INIT
            /* Try again if zone has deferred pages */
            if (static_branch_unlikely(&amp;deferred_pages)) &#123;
                if (_deferred_grow_zone(zone, order))
                    goto try_this_zone;
            &#125;
#endif
        &#125;
    &#125;

    /*
     * It&#39;s possible on a UMA machine to get through all zones that are
     * fragmented. If avoiding fragmentation, reset and try again.
     */
    if (no_fallback) &#123;
        alloc_flags &amp;= ~ALLOC_NOFRAGMENT;
        goto retry;
    &#125;

    return NULL;
&#125;
</code></pre>
<p>å…¶åŠŸèƒ½å°±æ˜¯é¦–å…ˆéå†å½“å‰çš„<code>zone</code>ï¼Œåˆ¤æ–­å½“å‰<code>zone</code>æ˜¯å¦æ»¡è¶³low water markæ°´ä½ï¼Œè‹¥ä¸æ»¡è¶³åˆ™è¿›è¡Œä¸€æ¬¡å¿«é€Ÿå›æ”¶æ“ä½œï¼Œå†æ¬¡æ£€æµ‹æ°´ä½æƒ…å†µï¼Œè‹¥è¿˜æ˜¯ä¸èƒ½æ»¡è¶³ï¼Œåˆ™éå†ä¸‹ä¸€ä¸ª<code>zone</code>ï¼Œç„¶åé‡‡å–åŒæ ·çš„æ­¥éª¤ï¼Œæœ€åè¿›å…¥<code>rmqueue</code>å‡½æ•°ï¼Œè¿™å°±æ˜¯<code>buddy system</code>çš„æ ¸å¿ƒï¼Œè¿‡ç¨‹å¯ä»¥ç®€åŒ–çœ‹ä¸‹å›¾ï¼š</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/11385343fbf2b211d43468878f8065380dd78ee5.jpg" srcset="/img/loading.gif" lazyload></p>
<p>ç›¸æ¯”äºä»£ç ï¼Œä¸‹å›¾æ›´åŠ ç›´è§‚ï¼Œä¹‹åæˆ‘ä»¬æ¥æŸ¥çœ‹å…³é”®å‡½æ•°<code>rmqueue()</code>,å®ƒä½äº<code>/mm/page_alloc.c</code></p>
<pre><code class="hljs">/*
 * ä»æ‰€ç»™zoneä¸­è·å–é¡µ. å½“orderä¸º0çš„æ—¶å€™ï¼Œä½¿ç”¨pcplists.
 */
static inline
struct page *rmqueue(struct zone *preferred_zone,
            struct zone *zone, unsigned int order,
            gfp_t gfp_flags, unsigned int alloc_flags,
            int migratetype)
&#123;
    unsigned long flags;
    struct page *page;

    if (likely(order == 0)) &#123;
        /*
          * è‹¥æ²¡æœ‰å¼€å¯`CMA`|è®¾ç½®`ALLOC_CMA`|è¿ç§»ç±»å‹ä¸ºMIGRATE_MOVABLEï¼Œåˆ™å…ˆä»pcplistä¸Šåˆ†é…
         */
        if (!IS_ENABLED(CONFIG_CMA) || alloc_flags &amp; ALLOC_CMA ||
                migratetype != MIGRATE_MOVABLE) &#123;
            page = rmqueue_pcplist(preferred_zone, zone, gfp_flags,
                    migratetype, alloc_flags);
            goto out;
        &#125;
    &#125;

    /*
     * We most definitely don&#39;t want callers attempting to
     * allocate greater than order-1 page units with __GFP_NOFAIL.
     */
    WARN_ON_ONCE((gfp_flags &amp; __GFP_NOFAIL) &amp;&amp; (order &gt; 1));
    spin_lock_irqsave(&amp;zone-&gt;lock, flags);

    do &#123;
        page = NULL;
        /*
         * order-0 request can reach here when the pcplist is skipped
         * due to non-CMA allocation context. HIGHATOMIC area is
         * reserved for high-order atomic allocation, so order-0
         * request should skip it.
         */
        if (order &gt; 0 &amp;&amp; alloc_flags &amp; ALLOC_HARDER) &#123; //orderå¤§äº0ä¸”å¸¦æœ‰ALLOC_HARDERï¼Œä½¿ç”¨__rmqueue_smalleståˆ†é…
            page = __rmqueue_smallest(zone, order, MIGRATE_HIGHATOMIC);
            if (page)
                trace_mm_page_alloc_zone_locked(page, order, migratetype);
        &#125;
        /*
         * æ‰§è¡Œåˆ°è¿™é‡Œè¯´æ˜order&gt;0,æˆ‘ä»¬é‡‡ç”¨__rmqueueå‡½æ•°ï¼Œè¿™æ˜¯çœŸæ­£çš„å…„å¼Ÿç³»ç»Ÿæ ¸å¿ƒåˆ†é…å‡½æ•°
         */
        if (!page)
            page = __rmqueue(zone, order, migratetype, alloc_flags);
    &#125; while (page &amp;&amp; check_new_pages(page, order));
    spin_unlock(&amp;zone-&gt;lock);
    if (!page)
        goto failed;
    __mod_zone_freepage_state(zone, -(1 &lt;&lt; order),
                  get_pcppage_migratetype(page));

    __count_zid_vm_events(PGALLOC, page_zonenum(page), 1 &lt;&lt; order);
    zone_statistics(preferred_zone, zone);
    local_irq_restore(flags);

out:
    /* Separate test+clear to avoid unnecessary atomics */
    if (test_bit(ZONE_BOOSTED_WATERMARK, &amp;zone-&gt;flags)) &#123;
        clear_bit(ZONE_BOOSTED_WATERMARK, &amp;zone-&gt;flags);
        wakeup_kswapd(zone, 0, 0, zone_idx(zone));
    &#125;

    VM_BUG_ON_PAGE(page &amp;&amp; bad_range(zone, page), page);
    return page;

failed:
    local_irq_restore(flags);
    return NULL;
&#125;
</code></pre>
<p>æœ‰éƒ¨åˆ†æ³¨é‡Šï¼Œæˆ‘åœ¨ä¸Šé¢ä¸­è¥¿åˆç’§æ ‡æ³¨äº†ä¸€ä¸‹ï¼Œæ¥ä¸‹æ¥å…ˆæé†’å¤§å®¶ä¼™ï¼Œä¹‹å‰å’±ä»¬è®²è§£<code>zone</code>ä¸Šçš„ä¸€ä¸ªå­—æ®µ<code>per-cpu pageset</code>,ä»–æ˜¯ä¸ºäº†æ”¾ç½®æ¡ä»¶ç«äº‰çš„é—®é¢˜ï¼Œä¸ºæ¯ä¸ªcpuå•ç‹¬è®¾ç½®ä¸€ä¸ªä»“åº“ç”¨æ¥ä¸º<code>buddy system</code>è¿›è¡Œè¿…é€Ÿçš„åˆ†é…ï¼Œè¿™é‡Œå°±æ˜¯ç»™å‡ºäº†<code>buddy system</code>å…ˆä»ä»–é‡Œé¢è°ƒç”¨çš„å‡½æ•°ä»£ç ï¼Œæ€»ç»“ä¸ºä¸€ä¸‹æµç¨‹</p>
<ol>
<li>è‹¥<code>order</code>ä¸º0ï¼Œè‹¥æ²¡æœ‰å¼€å¯<code>CMA</code>|è®¾ç½®<code>ALLOC_CMA</code>|è¿ç§»ç±»å‹ä¸ºMIGRATE_MOVABLEï¼Œåˆ™å…ˆä»per-cpu pageset ä¸­åˆ†é…å¹¶ä¸”è¿”å›</li>
<li>order &gt;0 è°ƒç”¨<code>__rmqueue_smallest()</code>åˆ†é…</li>
<li>è‹¥æœªåˆ†é…æˆåŠŸï¼Œè¿™é‡Œä¸ç®¡orderæ˜¯å¦ä¸º0ï¼Œè°ƒç”¨<code>__rmqueue()</code>åˆ†é…</li>
<li>ç»“æœæ£€æŸ¥ï¼Œè°ƒç”¨<code>check_new_pages()</code>ï¼Œæœªé€šè¿‡åˆ™å¾ªç¯è·³åˆ°ç¬¬äºŒæ­¥</li>
</ol>
<p>æˆ‘ä»¬ä¸€ä¸ªä¸€ä¸ªå…³é”®å‡½æ•°æ¥æŸ¥çœ‹ï¼Œé¦–å…ˆæ˜¯åˆ†é…<code>per_cpu_pageset</code>,ä¹Ÿå°±æ˜¯å¦‚ä¸‹å‡½æ•°</p>
<p><strong>rmqueue_pcplist()</strong></p>
<pre><code class="hljs">/* Lock and remove page from the per-cpu list */
static struct page *rmqueue_pcplist(struct zone *preferred_zone,
            struct zone *zone, gfp_t gfp_flags,
            int migratetype, unsigned int alloc_flags)
&#123;
    struct per_cpu_pages *pcp;
    struct list_head *list;
    struct page *page;
    unsigned long flags;

    local_irq_save(flags); // å…³ä¸­æ–­
    pcp = &amp;this_cpu_ptr(zone-&gt;pageset)-&gt;pcp;
    list = &amp;pcp-&gt;lists[migratetype]; // è·å–è¿ç§»ç±»å‹é“¾è¡¨
    page = __rmqueue_pcplist(zone,  migratetype, alloc_flags, pcp, list); // åˆ†é…
    if (page) &#123;
        __count_zid_vm_events(PGALLOC, page_zonenum(page), 1);
        zone_statistics(preferred_zone, zone);
    &#125;
    local_irq_restore(flags); // å¼€ä¸­æ–­
    return page;
&#125;
</code></pre>
<p>ä¸»è¦æ˜¯è¿›è¡Œäº†ä¸€äº›åŒæ­¥äº’æ–¥æ“ä½œï¼ˆå¼€å…³ä¸­æ–­ï¼‰ï¼Œç„¶åè°ƒç”¨å‡½æ•°<code>__rmqueue_pcplist</code></p>
<pre><code class="hljs">/* ä» per-cpu é“¾è¡¨ä¸Šå–å‡º page, è°ƒç”¨è€…å¿…é¡»ä¿æŠ¤é“¾è¡¨ */
static struct page *__rmqueue_pcplist(struct zone *zone, int migratetype,
            unsigned int alloc_flags,
            struct per_cpu_pages *pcp,
            struct list_head *list)
&#123;
    struct page *page;

    do &#123;
        if (list_empty(list)) &#123; // list æ˜¯ç©ºçš„
            // 
            pcp-&gt;count += rmqueue_bulk(zone, 0,
                    READ_ONCE(pcp-&gt;batch), list,
                    migratetype, alloc_flags);
            if (unlikely(list_empty(list)))
                return NULL;
        &#125;

        // é“¾è¡¨è„±é“¾
        page = list_first_entry(list, struct page, lru);
        list_del(&amp;page-&gt;lru);
        pcp-&gt;count--;
    &#125; while (check_new_pcp(page));

    return page;
&#125;
</code></pre>
<p>è¿™é‡Œå…ˆåˆ¤å®šé“¾è¡¨ï¼Œè‹¥ä¸ºç©ºï¼Œåˆ™è°ƒç”¨<code>rmqueue_bulk()</code>å‡½æ•°ï¼Œä»<code>zone</code>ä¸Šæ‹¿åˆ°pagesä¹‹åå†è¿›è¡Œ<code>unlink</code>ï¼Œè€Œ<code>rmqueue_bulk()</code>å‡½æ•°æœ€ç»ˆä¼šè°ƒç”¨<code>__rmqueue()</code></p>
<pre><code class="hljs">/*
 * ä¸ºäº†é«˜æ•ˆç‡ï¼Œä» buddy åˆ†é…å™¨è·å¾—æŒ‡å®šæ•°é‡çš„å…ƒç´ , 
 * æ‰€æœ‰çš„å•ä¸ªå…ƒç´ éƒ½åœ¨æŒæœ‰é”çš„æƒ…å†µä¸‹è¿›è¡Œ.  å°†å…¶æ·»åŠ åˆ°æä¾›çš„é“¾è¡¨ä¸­.
 * è¿”å›æ”¾ç½®åœ¨ *list é“¾è¡¨ä¸Šçš„ pages æ•°é‡.
 */
static int rmqueue_bulk(struct zone *zone, unsigned int order,
            unsigned long count, struct list_head *list,
            int migratetype, unsigned int alloc_flags)
&#123;
    int i, alloced = 0;

    spin_lock(&amp;zone-&gt;lock);
    for (i = 0; i &lt; count; ++i) &#123;
        struct page *page = __rmqueue(zone, order, migratetype,
                                alloc_flags);
        if (unlikely(page == NULL))
            break;

        if (unlikely(check_pcp_refill(page)))
            continue;

        /*
         * ç”± expand() è¿”å›çš„åˆ†å‰² buddy é¡µé¢åœ¨æ­¤å¤„ä»¥ç‰©ç†é¡µæ¡†é¡ºåºæ¥æ”¶ã€‚
         * é¡µé¢è¢«æ·»åŠ åˆ° caller çš„é“¾è¡¨å°¾éƒ¨ã€‚ä» caller çš„è§’åº¦çœ‹ï¼Œé“¾è¡¨åœ¨
         * æŸäº›æƒ…å†µä¸‹æ˜¯æŒ‰ç…§é¡µç æ’åºçš„ã€‚è¿™å¯¹ä¸€äº›å¯ä»¥ä»å¤´éƒ¨å‰å‘çš„IOè®¾å¤‡æ˜¯æœ‰ç”¨çš„ï¼Œ
         * å› ä¸ºé“¾è¡¨ä¹Ÿæ˜¯åœ¨ç‰©ç†é¡µçš„é¡ºåºä¸Šçš„ã€‚è¿™å¯¹äºå¯ä»¥åœ¨ç‰©ç†é¡µåˆç†æ’åºçš„æƒ…å†µä¸‹
         * åˆå¹¶IOè¯·æ±‚çš„IOè®¾å¤‡æ˜¯æœ‰ç”¨çš„ã€‚
         */
        list_add_tail(&amp;page-&gt;lru, list);
        alloced++;
        if (is_migrate_cma(get_pcppage_migratetype(page)))
            __mod_zone_page_state(zone, NR_FREE_CMA_PAGES,
                          -(1 &lt;&lt; order));
    &#125;

    /*
     * i pages were removed from the buddy list even if some leak due
     * to check_pcp_refill failing so adjust NR_FREE_PAGES based
     * on i. Do not confuse with &#39;alloced&#39; which is the number of
     * pages added to the pcp list.
     */
    __mod_zone_page_state(zone, NR_FREE_PAGES, -(i &lt;&lt; order));
    spin_unlock(&amp;zone-&gt;lock);
    return alloced;
&#125;
</code></pre>
<p><strong>__rmqueue_smallest</strong><br>è¯¥å‡½æ•°å°±æ˜¯ç”±orderå¯¹åº”çš„<code>free_area</code>ä¸­ç±»å‹ä¸º<code>migration type</code>çš„é“¾è¡¨ä¸Šè¿›è¡Œåˆ†é…ï¼Œå¦‚æœä¸å¤Ÿåˆ™å‘é«˜orderå¤„è¯·æ±‚ï¼Œç”±äºè¿™é‡Œéƒ½æ˜¯ä»¥2^orderæ¥è¿›è¡Œåˆ†é…ï¼Œå› æ­¤å¦‚æœè¯´æˆ‘orderä¸º1ï¼Œä¸”è¿™é‡Œä¸å¤Ÿçš„è¯ï¼Œæˆ‘ä»¬å°±è½¬è€Œorderä¸º2çš„é“¾è¡¨ï¼Œå°†å…¶ä¸­çš„å—å¯¹åŠæ‹†ä¸‹åˆ°ä½orderä¸­ï¼Œå…¶ä¸­å‘æ›´é«˜orderåˆ†é…æ˜¯é€šè¿‡å¾ªç¯å’Œè„±é“¾å®Œæˆï¼Œè€Œæ‹†é«˜é˜¶çš„pageæ˜¯é€šè¿‡<code>expand()</code>å‡½æ•°æ¥è¿›è¡Œçš„</p>
<pre><code class="hljs">/*
 * å¯¹ç»™å®šçš„ migrationtype éå† free lists 
 * å¹¶ä» freelists ä¸Šç§»é™¤æœ€å°å¯ç”¨çš„é¡µé¢
 */
static __always_inline
struct page *__rmqueue_smallest(struct zone *zone, unsigned int order,
                        int migratetype)
&#123;
    unsigned int current_order;
    struct free_area *area;
    struct page *page;

    /* åœ¨ preferred list ä¸Šå¯»æ‰¾ä¸€ä¸ªåˆé€‚ size çš„ page */
    for (current_order = order; current_order &lt; MAX_ORDER; ++current_order) &#123;
        area = &amp;(zone-&gt;free_area[current_order]);
        page = get_page_from_free_area(area, migratetype);
        if (!page)
            continue;
        del_page_from_free_list(page, zone, current_order);
        expand(zone, page, order, current_order, migratetype);
        set_pcppage_migratetype(page, migratetype);
        return page;
    &#125;

    return NULL;
&#125;
</code></pre>
<p>è€Œæ‹†åˆ†å‡½æ•°<code>expand</code>ä¹Ÿæ¯”è¾ƒç®€å•</p>
<pre><code class="hljs">/*
 * æ­¤å¤„å†åˆ†å‰²çš„é¡ºåºå¯¹ IO subsystem è€Œè¨€æ˜¯ååˆ†é‡è¦çš„.
 * è¯·ä¸è¦åœ¨æœ‰å¥½çš„ç†ç”±åŠå›å½’æµ‹è¯•å‰æ”¹å˜è¿™ä¸ªé¡ºåºã€‚
 * ç‰¹åˆ«åœ°ï¼Œå½“å¤§å—çš„å†…å­˜è¢«åˆ†å‰²ï¼Œæ›´å°å—ï¼ˆå†…å­˜ï¼‰è¢«ä¼ é€’çš„é¡ºåº
 * åˆ™ç”±ä»–ä»¬åœ¨è¯¥å‡½æ•°ä¸­è¢«åˆ†å‰²çš„é¡ºåºå†³å®šã€‚
 * æ ¹æ®å®é™…æµ‹è¯•ï¼Œè¿™æ˜¯å½±å“ä¼ é€’ç»™IOå­ç³»ç»Ÿçš„ pages é¡ºåºçš„ä¸»è¦å› ç´ ï¼Œ
 * è€ƒè™‘åˆ°åŒ…å«ä¸€ä¸ªå†…å­˜å¤§å—ï¼ˆç”±ä¸€ç³»åˆ—å°çš„åˆ†é…ä½œç”¨ï¼‰çš„ buddy system çš„è¡Œä¸ºï¼Œ
 * è¿™ä¹Ÿæ˜¯åˆç†çš„ã€‚è¿™ç§è¡Œä¸ºæ˜¯ sglist åˆå¹¶æˆåŠŸçš„å…³é”®å› ç´ ã€‚
 *
 * -- nyc
 */
static inline void expand(struct zone *zone, struct page *page,
    int low, int high, int migratetype)
&#123;
    unsigned long size = 1 &lt;&lt; high;

    while (high &gt; low) &#123;
        high--;
        size &gt;&gt;= 1;
        VM_BUG_ON_PAGE(bad_range(zone, &amp;page[size]), &amp;page[size]);

        /*
         * æ ‡è®°ä¸º guard pages (æˆ– page), è¿™å°†å…è®¸åœ¨ buddy å°†è¢«
         * é‡Šæ”¾æ—¶åˆå¹¶å›åˆ†é…å™¨.å¯¹åº”çš„é¡µè¡¨é¡¹ä¸ä¼šè¢«åˆ›å»ºï¼Œ
         * pages åœ¨ è™šæ‹Ÿåœ°å€ç©ºé—´ä¸Šä»å°†ä¿æŒä¸å­˜åœ¨ã€‚
         */
        if (set_page_guard(zone, &amp;page[size], high, migratetype))
            continue;

        add_to_free_list(&amp;page[size], zone, high, migratetype);
        set_buddy_order(&amp;page[size], high);
    &#125;
&#125;
</code></pre>
<p><strong>__rmqueue()</strong></p>
<p>æœ€å¼€å§‹æˆ‘ä»¥ä¸ºè¿™ä¸ªæ‰æ˜¯æœ€ç»ˆå‡½æ•°ï¼Œä½†å…¶å®ä»–ä¸æ˜¯ï¼Œä»–åè€Œè¿˜ä¼šè°ƒç”¨<code>__rmqueue_smallest()</code></p>
<pre><code class="hljs">/*
 * ä» buddy allocator ä¸Šç§»é™¤ä¸€ä¸ªå…ƒç´ .
 * åœ¨æŒæœ‰ zone-&gt;lock æ—¶è°ƒç”¨.
 */
static __always_inline struct page *
__rmqueue(struct zone *zone, unsigned int order, int migratetype,
                        unsigned int alloc_flags)
&#123;
    struct page *page;

    if (IS_ENABLED(CONFIG_CMA)) &#123;
        /*
         * é€šè¿‡å½“åŠæ•°ç©ºé—²å†…å­˜åœ¨ CMA åŒºåŸŸæ—¶ä» CMA ä¸­åˆ†é…
         * ä»¥å¹³è¡¡å¸¸è§„çš„ä¸CMAåŒºåŸŸçš„å¯è¿ç§»çš„åˆ†é…ã€‚
         */
        if (alloc_flags &amp; ALLOC_CMA &amp;&amp;
            zone_page_state(zone, NR_FREE_CMA_PAGES) &gt;
            zone_page_state(zone, NR_FREE_PAGES) / 2) &#123;
            page = __rmqueue_cma_fallback(zone, order);
            if (page)
                goto out;
        &#125;
    &#125;
retry:
    page = __rmqueue_smallest(zone, order, migratetype);
    if (unlikely(!page)) &#123;
        if (alloc_flags &amp; ALLOC_CMA)
            page = __rmqueue_cma_fallback(zone, order);

        if (!page &amp;&amp; __rmqueue_fallback(zone, order, migratetype,
                                alloc_flags))
            goto retry;
    &#125;
out:
    if (page)
        trace_mm_page_alloc_zone_locked(page, order, migratetype);
    return page;
&#125;
</code></pre>
<p>æ•´ä½“å¿«é€Ÿåˆ†é…å¯ä»¥çœ‹ä¸‹é¢è¿™å¼ å›¾</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/a6efce1b9d16fdfadde22b27f18f8c5495ee7b69.jpg" srcset="/img/loading.gif" lazyload></p>
<p>æˆ‘ä»¬äº†è§£å®Œäº†å¿«é€Ÿåˆ†é…ï¼Œæ¥ä¸‹æ¥å°±æ˜¯æ…¢é€Ÿåˆ†é…äº†ï¼Œå…¶ä¸­ä»–çš„åŠŸèƒ½åŒ…æ‹¬äº†å†…å­˜ç¢ç‰‡åŒ–çš„æ•´ç†å’Œå›æ”¶ï¼Œä»–çš„ä»£ç å¤ªé•¿ï¼Œæˆ‘å°±ä¹Ÿåªè´´ä¸€éƒ¨åˆ†ï¼Œå¦‚ä¸‹ï¼š</p>
<pre><code class="hljs">static inline struct page *
__alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,
      struct alloc_context *ac)
&#123;
  page = __alloc_pages_direct_compact(gfp_mask, order, 
      alloc_flags, ac,
      INIT_COMPACT_PRIORITY,
      &amp;compact_result);
  ......
  page = __alloc_pages_direct_reclaim(gfp_mask, order, alloc_flags, ac, 
       &amp;did_some_progress);
  ......
&#125;
</code></pre>
<p>å…¶ä¸­å†…å­˜ç¢ç‰‡åŒ–ä¹Ÿå³æ˜¯åˆ©ç”¨åˆ°è¿ç§»çš„çŸ¥è¯†ï¼Œè¿™é‡Œæœ‰ä¸¤ä¸ªå…³é”®å‡½æ•°ï¼Œå…¶ä¸­ä¹‹ä¸€å°±æ˜¯<code>__alloc_pages_direct_compact</code></p>
<pre><code class="hljs">static struct page *
__alloc_pages_direct_compact(gfp_t gfp_mask, unsigned int order,
  unsigned int alloc_flags, const struct alloc_context *ac,
  enum compact_priority prio, enum compact_result *compact_result)
&#123;
 struct page *page;
 unsigned int noreclaim_flag;
 
 if (!order)
  return NULL;
 
 noreclaim_flag = memalloc_noreclaim_save();
 *compact_result = try_to_compact_pages(gfp_mask, order, alloc_flags, ac,
         prio);
 memalloc_noreclaim_restore(noreclaim_flag);
 
 if (*compact_result &lt;= COMPACT_INACTIVE)
  return NULL;
 
 count_vm_event(COMPACTSTALL);
 
 page = get_page_from_freelist(gfp_mask, order, alloc_flags, ac);
 
 if (page) &#123;
  struct zone *zone = page_zone(page);
 
  zone-&gt;compact_blockskip_flush = false;
  compaction_defer_reset(zone, order, true);
  count_vm_event(COMPACTSUCCESS);
  return page;
 &#125;
 
 count_vm_event(COMPACTFAIL);
 
 cond_resched();
 
 return NULL;
&#125;
</code></pre>
<p>è¿™é‡Œçš„å‡½æ•°ä¹Ÿæ˜¯è¿ç§»ç®—æ³•<code>memory compaction</code>çš„ä»£ç å®ç°ï¼Œè¯¥ç®—æ³•å¯ä»¥ç®€åŒ–ä¸ºä¸‹é¢çš„æµç¨‹</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/242dd42a2834349b34c1834c8cea15ce37d3be30.jpg" srcset="/img/loading.gif" lazyload></p>
<p>ä¹Ÿå°±æ˜¯åˆ†ä¸ºä¸¤ä¸ªé“¾è¡¨ï¼Œä¸€ä¸ªä¸“é—¨éå†ç©ºé—²é¡µï¼Œä¸€ä¸ªä¸“é—¨éå†ä½¿ç”¨é¡µï¼Œæ³¨æ„è¿™ä¿©è¦åˆ†åˆ«ç»´æŒé“¾è¡¨ï¼Œç„¶åæœ€åè¿›è¡Œäº¤æ¢æ“ä½œå°±å®ç°äº†è¿ç§»è¿‡ç¨‹ï¼Œä¸”è®°ä½è¿™ä¸ªè¿ç§»æ˜¯éœ€è¦<code>page</code>æœ¬èº«æ˜¯å…è®¸çš„æ‰è¡Œ,</p>
<p>åœ¨å®Œæˆä¸Šè¿°è¿ç§»æ“ä½œåä¼šå†æ¬¡å°è¯•å¿«é€Ÿåˆ†é…ï¼Œè¿™é‡Œçš„ç¢ç‰‡åŒ–æ•´ç†è¿˜æœ‰å…¶ä»–æ–¹å¼ï¼Œä½†æ˜¯æˆ‘è¿™é‡Œæš‚ä¸åŒºæ·±ç©¶ï¼Œå…ˆè®°å½•ä¸ªå›¾ç­‰æˆ‘å“ªå¤©æƒ³èµ·æ¥äº†å†æ¢ç´¢</p>
<p><img src="http://imgsrc.baidu.com/forum/pic/item/e4dde71190ef76c6cae717e2d816fdfaae5167c6.jpg" srcset="/img/loading.gif" lazyload></p>
<p>è€Œå…³äºæ…¢é€Ÿåˆ†é…è¿˜æœ‰ä¸ªå‡½æ•°æ˜¯<code>__alloc_pages_direct_reclaim()</code>ï¼Œä»–çš„ä½œç”¨ä¸»è¦æ˜¯å›æ”¶ï¼Œè€Œä¸æ˜¯ç¢ç‰‡æ•´ç†</p>
<p>æœ€åæ¥ä¸ªæ•´ä½“åˆ†é…é¡µæ¡†çš„å‡½æ•°æµç¨‹å›¾<br><img src="http://imgsrc.baidu.com/forum/pic/item/810a19d8bc3eb135a3e35b72e31ea8d3fc1f44d7.jpg" srcset="/img/loading.gif" lazyload></p>
<h1 id="æš‚æœªå®Œå·¥"><a href="#æš‚æœªå®Œå·¥" class="headerlink" title="æš‚æœªå®Œå·¥"></a>æš‚æœªå®Œå·¥</h1><p>ä¸€å¤©ä¸‹æ¥æ€ä¹ˆç¡•å‘¢ï¼Œæ„Ÿè§‰éƒ½æ˜¯å‡ ä½å¸ˆå‚…çš„åšå®¢ä¸€å£ä¸€å£çš„å–‚é¥­ï¼Œè™½è¯´è‡ªå·±ç†è§£äº†å¤§è‡´è¿‡ç¨‹ï¼Œä½†æ˜¯å¯¹äºæºç çš„è§£è¯»è¿˜æ˜¯å¤ªç²—äº†ï¼Œè¿™ä¸ªç³»åˆ—è¿˜æœ‰é‡Šæ”¾é¡µæ¡†å’Œslubç®—æ³•çš„æºç å®ç°ï¼Œslubç®—æ³•æˆ‘å†ä¸Šä¸€ç¯‡åšå®¢ä¸­å·²ç»è®²è§£äº†å¤§è‡´åŸç†äº†å“¦ï¼Œè¿™é‡Œè¿˜å·®ä¸€éƒ¨åˆ†ï¼Œ</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Linux-Kernel/" class="category-chain-item">Linux Kernel</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Linux/">#Linux</a>
      
        <a href="/tags/kernel/">#kernel</a>
      
        <a href="/tags/source/">#source</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Linux_memory_manegement</div>
      <div>https://peiandhao.github.io/2023/06/17/Linux-memory-manegement/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>ä½œè€…</div>
          <div>peiwithhao</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>å‘å¸ƒäº</div>
          <div>2023å¹´6æœˆ17æ—¥</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>è®¸å¯åè®®</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - ç½²å">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/06/17/Malloc-Free/" title="Malloc_Free">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Malloc_Free</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/06/17/CVE-2010-2883%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/" title="CVE-2010-2883æ¼æ´å¤ç°">
                        <span class="hidden-mobile">CVE-2010-2883æ¼æ´å¤ç°</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"Afm6UeM0VL6RfMOLAgwtyxs8-gzGzoHsz","appKey":"Vr60qrZIptqhJaXqWvDEknkH","path":"window.location.pathname","placeholder":"é”è¯„ä¸€ä¸‹","avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>ç›®å½•</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <div> <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Pei</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Hao</span></a> <span id="timeDate">è½½å…¥å¤©æ•°...</span> <span id="times">è½½å…¥æ—¶åˆ†ç§’...</span> <script src="/js/duration.js"></script> </div> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        æ€»è®¿é—®é‡ 
        <span id="leancloud-site-pv"></span>
         æ¬¡
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        æ€»è®¿å®¢æ•° 
        <span id="leancloud-site-uv"></span>
         äºº
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/js/DynamicLine.js"></script>



<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div>
  </noscript>
</body>
</html>
